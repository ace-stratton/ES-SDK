var __index = {"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Home","text":"<p>DISCLAIMER</p> <p>THE INFORMATION CONTAINED IN THIS DOCUMENTATION IS CONFIDENTIAL IN NATURE AND IS SUBJECT TO THE NON-DISCLOSURE AGREEMENT BETWEEN ENDUROSAT AD AND THE INSTITUTION IT WAS SENT TO. IT IS INTENDED SOLELY FOR THE ENTITY/INSTITUTION TO WHICH IT WAS SENT PERSUANT TO THIS NDA AND SHOULD NOT BE DISSEMINATED, COPIED OR REPRODUCED FOR EXTERNAL INSTITUTIONS WITHOUT THE PRIOR CONSENT OF ENDUROSAT.</p>"},{"location":"index.html#introduction","title":"Introduction","text":"<p>The OBC SDK is an example SW framework designed specifically for the EnduroSat On-board Computer HW module which can be used as:</p> <ul> <li> <p>A template for custom development to enable integration of the OBC HW module in your own inspiring CubeSat.</p> <p>Using this guide you can tailor the implementation to your needs and remove anything that you do not need or feel you can improve.</p> </li> <li> <p>A ready-to-use implementation which can easily be extended to integrate with your own payload(s).</p> <p>In such a setup you still need to configure your system build and implement a few bits-n-things but hopefully you can spare the full effort of heavyweight programming if you are happy with the standard features of this package.</p> </li> </ul> <p>This documentation aims to:</p> <ul> <li>Provide a general overview on how to use the OBC SDK framework, debug it and extend it with user-specific modules.</li> <li>Describe the OBC SDK SW architecture and build organization.</li> <li>Give recommended development recipes on the most common operations the users will need to perform.</li> <li>List any additional reference documentation which is needed to make full use of the SDK (e.g. detailed source code documentation, code generators and protocol references, etc.).</li> </ul>"},{"location":"index.html#target-audience","title":"Target audience","text":"<p>The intended users of this documentation are engineering personnel involved in:</p> <ul> <li>Flight SW development</li> <li>SW architecture</li> <li>SW integration</li> <li>SW testing</li> </ul> <p>For best understanding, readers shall have a good command of the C programming language, some experience with the CMake toolkit and at least basic familiarity with RTOS concepts such as scheduling and thread synchronization. To understand low-level drivers operation, users shall be comfortable with embedded programming concepts such as memory organization, interrupt management, registers and similar. Some basic understanding of digital electronics would also help.</p>"},{"location":"change_history.html","title":"Change history","text":"Date Revision Modified By Change description 08/12/2023 1.17 Data Handling Added a chapter about assertions 20/11/2023 1.16 Data Handling OBC SDK version build information 07/11/2023 1.15 Data Handling/AOCS Added a chapter about Performance monitor 10/11/2023 1.14 Data Handling/AOCS Combine all operations related information under single chapter, add CubeADCS Gen2 service chapter 03/11/2023 1.13 Data Handling Added chapter on CPU exception fault handling 12/10/2023 1.12 Data Handling Added a chapter about Attitude and Orbit Control 09/10/2023 1.11 Data Handling Some features marked as experimental 03/10/2023 1.10 Data Handling STM32CubeIDE version compatibility disclaimer 11/09/2023 1.9 Data Handling More information on bootloader and application flashing procedures 07/09/2023 1.8 Data Handling Updated runtime configuration 24/07/2023 1.7 Data Handling Updated trace documentation 31/05/2023 1.6 SW Platform Added User Payloads chapter in Developer's Guide 14/11/2022 1.5 SW Platform Added CubeADCS documentation 02/11/2022 1.4 SW Platform Overall updates for SDK 3.0.2 08/09/2022 1.3 SW Platform General review 08/09/2022 1.2 SW Platform EPS I drivers updated 18/08/2022 1.1 SW Platform Updates for EPS Control service 15/09/2021 1.0 SW Platform First official release of the documentation"},{"location":"contacts.html","title":"Contacts","text":"<p>  If you need assistance with the topics described in this documentation, have questions or just want to provide some feedback, do not hesitate to reach out to our technical support team.</p>"},{"location":"quickstart.html","title":"Installation","text":"<p>In order to build and use the OBC SDK, you will need to install a few SW tools which are not part of this SDK. The latest versions of those packages will work for you unless explicitly noted otherwise. Use the links below to find detailed installation instructions for each of the tools.</p> <ul> <li>Python 3</li> <li>Ninja build system</li> <li>CMake - Cross Platform Makefile Generator</li> </ul> <p>Note</p> <p>You shall check if your CMake installation supports the Ninja-Multi-Config generator by typing the following command in the system console (it is assumed that CMake is already on your environment path): <pre><code>cmake --help\n</code></pre> Look for the following line in the list of supported Generators somewhere at the end of the printed output:</p> <pre><code>Ninja Multi-Config           = Generates build-&lt;Config&gt;.ninja files.\n</code></pre> <ul> <li>STM32CubeIDE</li> </ul> <p>Warning</p> <p>The OBC SDK code is only compatible with STM32CubeIDE versions up to 1.12.1. Make sure to select a compatible version when dowloading the software: .</p> <p>As a final step, please add all the tools above to the system path so that they can be accessed directly by the OBC SDK build wrapper script.</p> <p>Warning</p> <p>Please also ensure that the ARM compilation tools <code>bin</code> folder (which is part of the STM32CubeIDE package) is also in your system path. You can find that here:</p> <pre><code>&lt;STM32 install folder&gt;\\plugins\\com.st.stm32cube.ide.mcu.externaltools.gnu-tools-for-stm32.10.3-2021.10.win32_1.0.0.202111181127\\tools\\bin\n</code></pre> <p> Please note that the folder name above is just an example and verion numbers may differ depending on your downloaded package.</p> <p>Once this is done, the version of the compiler can be checked by typing:</p> <pre><code>&gt; arm-none-eabi-gcc.exe --version\narm-none-eabi-gcc.exe (GNU Tools for STM32 10.3-2021.10.20211105-1100) 10.3.1 20210824 (release)\nCopyright (C) 2020 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n</code></pre>"},{"location":"quickstart.html#connecting-your-obc-hardware","title":"Connecting your OBC hardware","text":"<p>The OBC development setup consists of the following HW items:</p> <ul> <li>EnduroSat On-board Computer module</li> <li>ST-Link JTAG programmer</li> <li>ST-Link adapter board for connecting the ST-Link programmer to the OBC debug port</li> <li>USB-C cable</li> <li>EnduroSat MAC dongle (for ESPS I communication with the OBC)</li> </ul> <p>Follow the installation instructions for each HW module and make sure your connections are working fine before attempting to execute any of the following steps in this chapter.</p> <p> OBC hardware setup for debugging </p> <p>Important</p> <p>The EnduroSat MAC dongle, which is not present in the picture, provides communication with the PC using the RS-485 connection on the OBC. The RS-485 pins of the OBC are accessible in the PC104 header. For more information refer to the OBC I User Manual.</p>"},{"location":"quickstart.html#importing-the-obc-sdk-project-to-the-stm32cubeide","title":"Importing the OBC SDK project to the STM32CubeIDE","text":"<ol> <li>Unzip the <code>x.y.z.sdk.7z</code> archive in a folder of your choice (<code>x.y.z</code> corresponds to a particular SDK version, e.g. 3.0.2).</li> <li>Start the STM32CubeIDE</li> <li>Create a workspace</li> <li>Import the OBC project by selecting the folder where you unzipped the SDK (make sure that <code>Search for nested projects</code> check box is on)</li> </ol>"},{"location":"quickstart.html#building-an-sdk-image","title":"Building an SDK image","text":"<p>In order to build an SDK-based application, you can directly use any of the provided build targets. To quickly check if your environment is setup correctly, you can use the <code>debug_noboot</code> build target because it produces an application image which you can directly flash on the OBC module without the need to pre-install a bootloader. For more details on the other build targets, please refer to the Build configurations chapter.</p> <ol> <li>Open the <code>Project Explorer</code> Eclipse view if not already activated.</li> <li>Unfold the <code>OBC_STDPF/build/Build Targets</code> folder.</li> <li>Double click on <code>debug_noboot</code> target.</li> <li>Wait for the build process to finish (see <code>Console</code> tab for more details).</li> </ol> <p>If everything runs smoothly you should observe a similar result (please note that in the following animation, the build is incremental because it was already built - building for the first time takes longer to finish):</p> <p> Activating the noboot_debug build target </p> <p>Tip</p> <p>As the OBC SDK build is not managed by the STM32CubeIDE, inactive code highlighting may not work as expected because the IDE does not know which preprocessor symbols are defined by the build system.</p> <p></p> <p>However, there is a simple workaround. The OBC CMake build process generates a file called <code>build_options.h</code> under the <code>&lt;OBC SDK&gt;/build</code> folder. This file contains all CMake build options with their correct state as defined in the <code>CMakeLists.txt</code> file. This allows you to import the file in the STM32CubeIDE as a built-in header enabling the IDE to properly reflect any changes in the build options directly in the code editor.</p> <p>Here is a short demonstration how to do this: </p>"},{"location":"quickstart.html#debugging-the-sdk-image","title":"Debugging the SDK image","text":"<p>After you have successfully built an SDK image, you can upload that image on the OBC module and check the execution flow by using the ST-Link debugger. Fortunately, there is a debug configuration project created particularly for the OBC which you can use directly.</p> <p>Follow these simple steps:</p> <ol> <li>Open the <code>Debug configurations</code> dialog (either by clicking on the arrow next to the bug icon ) or choosing the <code>Run</code> -&gt; <code>Debug Configurations...</code> from the main menu).</li> <li>Select the <code>debug_configurations Debug</code> item under <code>STM32 C/C++ Application</code> category to open the project settings.</li> <li>Provide the following location in the <code>C/C++ Application</code> edit box for our currently built image: <code>${project_loc:debug_configurations}/../build/NoBoot_Debug/OBC_STDPF_STM32H.elf</code></li> <li>You can review the debug settings in the <code>Debugger</code> tab if you want but in most cases you can directly start debugging with the defaults.</li> <li>Click the <code>Apply</code> button to save the configuration.</li> <li>Click the <code>Debug</code> button to upload the configured application to the OBC board and start debugging (by default, <code>Startup</code> tab -&gt; <code>Set breakpoint at:</code> main checkbox is set, thus code execution will stop at the C code <code>main</code> function entry point as soon as the MCU programming completes).</li> </ol> <p>Important</p> <p>The <code>debug_configuration</code> project refers to the <code>release_noboot</code> executable image by default but since we just built the <code>debug_noboot</code> image we have to change the .elf file path directly or browse for the new .elf file before starting the debug session. Make sure the name in the debug configuration matches the generated binaries for your project.</p> <p></p> <p>After pressing the Debug button, the STM32CubeIDE flashes the built image to the OBC module's program memory and the debugger hits the default <code>main</code> entrypoint. This indicates that your build environment and related HW is correctly prepared for use. Following this step, you can either continue debugging the code step-by-step or just let the image execute directly by pressing the Run button.</p> <p>At this point, any changes that you make to the SDK project source code, can be updated on the OBC module by following the same steps you just performed.</p> <p>Tip</p> <p>As the STM32CubeIDE actually updates the flash memory of your OBC module, if you reboot your OBC without a connected debugger, it will continue to execute the image that you last debugged.</p>"},{"location":"reference_docs.html","title":"Reference documents","text":"Document Description Link Macchiato User Manual User manual for EnduroSat's code generator Macchiato macchiato_user_guide ESPS I User Manual Description of the ESPS I communication stack ESPS_I_User_Manual.pdf OBC I User Manual Hardware description of the EnduroSat module OBC type I OBC_I_User_Manual.pdf CMake Reference Documentation Syntax of CMake, tutorials and examples cmake.org CMSIS-RTOS API v2 Reference for the CMSIS layer using FreeRTOS for Cortex-M/A5/A7/A9 keil.com FatFs Generic FAT Filesystem Module FatFs <p>Note</p> <p>All EnduroSat manuals from the list are at your disposal. Please, contact us if you haven't received your copy yet.</p>"},{"location":"devguide/devguide_aocs.html","title":"Attitude and Orbit Control","text":""},{"location":"devguide/devguide_aocs.html#overview","title":"Overview","text":"<p>Attitude and Orbit Control of the satellite is performed in the following basic use cases:</p> <ul> <li>Some scheduled payload has specific orientation requirements</li> <li>The system needs to go to a safe pointing state, e.g. at nadir</li> <li>Tumbling is detected and automatic detumbling needs to be performed</li> <li>The mission operator needs to change the satellite's orientation</li> </ul> <p>Tip</p> <p>This chapter assumes that the reader is already familiar with the Concept of Operations and handling of User Payloads. If this is not the case, the reader is strongly advised to read these chapters first.</p> <p>The diagram below describes the major participants in the Attitude and Orbit Control of the satellite. </p> <ul> <li> <p><code>payload_scheduler</code> (espf/core/services/payload_scheduler)</p> <ul> <li>The Payload Scheduler is responsible for passing the pointing requirements of the payload to the ConOps. These requirements include control and estimation modes (combined in the single AOCS state identifier) as well as optional parameters like coordinates (typically geocentric), roll/pitch/yaw angles, etc.</li> </ul> </li> <li> <p><code>conops</code> (espf/app/conops)</p> <ul> <li>The ConOps is responsible for triggering the payload controller and at the same time passing the pointing requirements.</li> </ul> </li> <li> <p><code>payload_ctrl</code> (espf/core/services/payload_ctrl)</p> <ul> <li>The Payload Controller is responsible for requesting AOCS state with pointing parameters from the AOCS service. The payload controller also monitors the completion status of the request so that it can proceed with payload activation when the pointing requirements for the payload are satisfied.</li> </ul> </li> <li> <p><code>aocs_cntrl</code> (espf/core/services/aocs/aocs_cntrl)</p> <ul> <li>The AOCS service provides a centralized way of controlling the operation mode of the satellite\u2019s ADCS module. The user is given a simple interface which abstracts the specifics of the underlying ADCS thus enabling the uniform use of ADCS modules with different interfaces. </li> <li> <p>Main functions of the AOCS service are:</p> <ul> <li>Managing requests for new operation modes of the ADCS</li> <li>Providing interfaces to read/update the commissioning status of the satellite</li> <li>Providing translation of the AOCS state to specific sub-modes (control, estimation, etc.) of the underlying ADCS module</li> </ul> </li> </ul> </li> <li> <p><code>es_adcs</code> (espf/core/services/es_adcs)</p> <ul> <li>The EnduroSat ADCS service is responsible for issuing commands to and providing status information about the EnduroSat ADCS module.</li> </ul> </li> <li> <p><code>cubeadcs</code> (espf/arch/stm32h753iit/drivers/positioning/libcubeadcs)</p> <ul> <li>The CubeADCS driver is responsible for issuing commands to and providing status information about the CubeADCS Gen1 module supplied by CubeSpace.</li> </ul> </li> <li> <p><code>cubeadcs_gen2</code> (espf/core/services/aocs/cubeadcs_gen2)</p> <ul> <li>The CubeADCS Gen2 service developed by EnduroSat is responsible for managing mode transitions of the CubeADCS Gen2 module supplied by CubeSpace. It also offers download functionality for event logs of the ADCS. </li> </ul> </li> <li> <p><code>libcubeobc</code> (espf/core/middlewares/external/libcubeobc)</p> <ul> <li>The CubeObc driver library developed by CubeSpace provides interfaces for issuing commands to and providing status information about the CubeADCS Gen2 module.</li> </ul> </li> </ul> <p>Tip</p> <p>Operation and integration details for each specific ADCS driver/service are provided in its implementation headers (for EnduroSat components) or reference documentation (for 3<sup>rd</sup> party components).</p> <p>Note</p> <p>Currently, AOCS service cannot interface with multiple ADCS modules at the same time.</p>"},{"location":"devguide/devguide_aocs.html#general-sequence","title":"General sequence","text":"<p>The diagram below shows the general sequence of API calls between the components involved in the attitude and orbit control.</p> <p> The <code>aocs_client</code> in the diagram may be one of the following:</p> <ul> <li>Payload Controller preparing for activation of a payload</li> <li>Mission Operator issuing commands from GS</li> <li>ConOps reacting to detected tumbling or safe state conditions</li> </ul> <p>Note</p> <p>You may wonder why DataCache is used to store the AOCS state requests. This is done for two purposes:</p> <ul> <li>To use the built-in concurrent data access protection of the DataCache</li> <li>To allow easier testing of the AOCS functionality by using the DataCache FIDL</li> </ul>"},{"location":"devguide/devguide_aocs.html#aocs-state","title":"AOCS state","text":"<p>To support different ADCS modules, the AOCS abstracts the specifics of control and estimation algorithms of the ADCS behind a single identifier called AOCS state. This state translates to a combination of control and estimation algorithms for each type of ADCS. Depending on the specific ADCS module, the mapping between AOCS state and ADCS algorithms is either hard-coded or configurable in NVM. The AOCS state can be one of the following:</p>"},{"location":"devguide/devguide_aocs.html#undefined","title":"UNDEFINED","text":"<p>On OBC startup the AOCS service requests information from the ADCS module whether there is an active control mode. Until the response is received AOCS state shall be set to Undefined.</p> <p>Note</p> <p>This state cannot be requested by the user. It can only be reported by the AOCS service.</p>"},{"location":"devguide/devguide_aocs.html#existing_control","title":"EXISTING_CONTROL","text":"<p>The AOCS service has determined that the ADCS module is running some control algorithm. This state should be considered by the mission operator when commanding a new control mode via a new AOCS state. Existing control detection occurs in the unlikely case that the OBC undergoes a reset while the ADCS keeps running and retains its last commanded control mode.</p> <p>Note</p> <p>This state cannot be requested by the user. It can only be reported by the AOCS service.</p>"},{"location":"devguide/devguide_aocs.html#no_control","title":"NO_CONTROL","text":"<p>This state is automatically set when the AOCS service has determined that the ADCS module is not running any control algorithm. In addition, this state can be requested by the user when they want to disable the current control algorithm currently run by the ADCS module.</p> <p>Note</p> <p>While there is no control algorithm running, there is always an active estimator used to provide information on angular velocity.</p>"},{"location":"devguide/devguide_aocs.html#normal_detumbling","title":"NORMAL_DETUMBLING","text":""},{"location":"devguide/devguide_aocs.html#y_thomson_spin","title":"Y_THOMSON_SPIN","text":""},{"location":"devguide/devguide_aocs.html#y_thomson_spin_with_mems_rate","title":"Y_THOMSON_SPIN_WITH_MEMS_RATE","text":""},{"location":"devguide/devguide_aocs.html#fast_detumbling","title":"FAST_DETUMBLING","text":""},{"location":"devguide/devguide_aocs.html#very_fast_detumbling","title":"VERY_FAST_DETUMBLING","text":""},{"location":"devguide/devguide_aocs.html#y_momentum","title":"Y_MOMENTUM","text":""},{"location":"devguide/devguide_aocs.html#y_momentum_full_state_ekf","title":"Y_MOMENTUM_FULL_STATE_EKF","text":""},{"location":"devguide/devguide_aocs.html#three_axis_control","title":"THREE_AXIS_CONTROL","text":""},{"location":"devguide/devguide_aocs.html#sun_tracking","title":"SUN_TRACKING","text":""},{"location":"devguide/devguide_aocs.html#target_tracking","title":"TARGET_TRACKING","text":""},{"location":"devguide/devguide_aocs.html#user_13","title":"USER_1..3","text":"<p>In case the preconfigured AOCS states do not match fully the mission requirements, the user is allowed to define up to 3 configurations of their own. </p> <p>Warn</p> <p>It is not advisable to modify the non-user AOCS state configurations, be they hardcoded or in NVM. EnduroSat cannot guarantee proper AOCS control if this is done.</p>"},{"location":"devguide/devguide_aocs.html#requesting-aocs-state","title":"Requesting AOCS state","text":"<p>ADCS modules are rarely able to change control and estimation algorithms and their parameters immediately. By extension, the AOCS state cannot be simply set, but has to be requested and the user is advised to monitor the status of the request. In code, the interface aocs_cntrl_request_aocs_state can be used. It is also possible to request the AOCS state from the GS via the FIDL interface method OBC_AOCS_CNTRL::setAocsState. Status of the AOCS state request can be monitored via the interfaces aocs_cntrl_get_aocs_state (in C code) and OBC_AOCS_CNTRL::getAocsState (in FIDL). Possible states of the request are:</p> <ul> <li>COMPLETED \u2013 the underlying ADCS module has successfully finished applying the requested change in control and/or estimation modes.</li> <li>NEW \u2013 the change has been requested from the AOCS service, but the ADCS module has not started processing it yet.</li> <li>IN_PROGRESS \u2013 the ADCS module is still processing the request.</li> <li>FAILED \u2013 the ADCS module has failed to process the request.</li> </ul> <p>Tip</p> <p>OBC_AOCS_CNTRL.fidl can be found at espf/core/fidl/obc.</p>"},{"location":"devguide/devguide_aocs.html#limitations","title":"Limitations","text":"<p>Warn</p> <p>Since DataCache doesn't offer queue functionality, requests to change the AOCS state cannot be queued. If the AOCS is still processing a request, any new requests will be rejected. Calls to aocs_cntrl_request_aocs_state will return error status BUSY.</p>"},{"location":"devguide/devguide_assertions.html","title":"Assertions","text":"<p>During development there are occasions when the outcome of a conditional check is of such a great importance that it deserves a halt in the program execution. In programming, such a halt can be achieved through an assertion. Such functionality is provided in the OBC SDK through the <code>assertions</code> library.</p>"},{"location":"devguide/devguide_assertions.html#use-cases","title":"Use cases","text":"<p>There are two typical use cases for assertions:</p> <ul> <li> <p>to halt program execution in case of an abnormal situation so that a developer can look at the context and identify the cause of the anomaly.</p> </li> <li> <p>to deliberately crash the program to prevent it from further executing code which is dangerous to the device or the mission objectives. In development builds it is a good idea to have the option of halting the system before the crash, thus entering the previous use case.</p> </li> </ul>"},{"location":"devguide/devguide_assertions.html#interfaces","title":"Interfaces","text":"<p>There are two interfaces, accessed through macros and defined in file <code>&lt;OBC SDK&gt;/espf/core/lib/assertions/inc/assertions.h</code>. Each of them provides the respective mechanism for the use cases described above:</p> <ul> <li> <p><code>BREAK_ASSERT(condition)</code> - execution stops at a breakpoint in debug configurations, but nothing is done in release ones. Behaviour between configuration types is switched via preprocessor definition.</p> </li> <li> <p><code>CRIT_ASSERT(condition)</code> - execution stops at a breakpoint in debug configurations, but the system is restarted via its respective SW reset mechanism.</p> </li> </ul>"},{"location":"devguide/devguide_assertions.html#integration","title":"Integration","text":"<p>A programming assertion consists of two parts - condition checking and reaction. The <code>assertions</code> library contains the code for checking conditions and invokes configurable reactions. Condition checking logic is considered independent of operating system, HW platform and mission specifics. Reactions can be freely implemented according to specific requirements and constraints. The recommended place to do so is the <code>assertions</code> library's configuration found in <code>&lt;OBC SDK&gt;/espf/config/assertions/assertions_cfg.h</code> and <code>&lt;OBC SDK&gt;/espf/config/assertions/assertions_cfg.c</code>.</p>"},{"location":"devguide/devguide_assertions.html#usage-guidelines","title":"Usage guidelines","text":"<ul> <li> <p>All SW should use only <code>BREAK_ASSERT</code> and <code>CRIT_ASSERT</code> or macros/functions that ultimately resolve to these interfaces. Third-party assertions (e.g. configASSERT in FreeRTOS) should be mapped, if possible, to the <code>assertions</code> interfaces.</p> </li> <li> <p><code>CRIT_ASSERT</code> should not be used in public functions, which usually represent component interfaces. These functions should check their arguments for validity and apply protective measures that prevent the errors from propagating to nested calls. Public functions should report any detected errors via their return value.</p> </li> <li> <p><code>BREAK_ASSERT</code> can be used to check the arguments of public functions to verify during development that the component interfaces are being called in a proper way. Example: <pre><code>bool my_public_method(uint8_t * p_result)\n{\n  bool status = false; // Initialize status reporting assuming that the operation will fail\n  BREAK_ASSERT(NULL != p_result); // There is an explicit protection, but we want to check if the\n                                  // function is really called with such an argument\n\n  // Explicitly check the argument\n  if (NULL != p_result)\n  {\n    *p_result = do_action(...);\n    status = true;               // Status reporting shall report success \n  }\n  return status; // Report status to caller\n}\n</code></pre></p> </li> <li> <p><code>CRIT_ASSERT</code> can be used in static function to verify the arguments. No explicit checks are needed in this case. This usage follows the principle of Design by Contract. Example: <pre><code>static void my_static_method(uint8_t * p_result)\n{\n  CRIT_ASSERT(NULL != p_result);\n\n  *p_result = 1;\n}\n</code></pre></p> </li> </ul> <p>Warning</p> <p><code>CRIT_ASSERT</code> must be used with caution. In development phase it is meant to detect and \u201creport\u201c bugs loudly. When the system is deployed it is meant to protect against critical failures. If the system is not thoroughly tested to expose design bugs during development, these can manifest post-deployment as resets. Therefore, CRIT_ASSERT should be used only when a system reset is the most appropriate reaction to a failing condition.</p> <p>Note</p> <p>Most static code analyzers will complain about unchecked pointers. If you are going to use <code>CRIT_ASSERT</code> for design-by-contract purposes, be prepared to justify issues from the analyzers.</p>"},{"location":"devguide/devguide_buildcfg.html","title":"Build-time configuration","text":"<p>Build configurations provide the possibility to use different configuration options for the OBC SDK project and thus produce different executables in the end. This is usually used to differentiate between Debug or Release builds of your implementation but it could serve any other purpose such as eliminating certain features of the program or adding new profiling features for that specialized testing build you are preparing for QA department, for example.</p> <p>There are several options for building the SDK-based application and each option has a preconfigured CMake build target as explained below:</p> Build target Action debug Produces a regular Application image using the project <code>Debug</code> configuration which requires a pre-flashed Bootloader image to run. debug_noboot Same as <code>debug</code> build target but creates an image which can run stand-alone without a Bootloader in place release Produces a regular Application image using the project <code>Release</code> configuration which requires a pre-flashed Bootloader image to run. release_noboot Same as <code>release</code> build target but creates an image which can run stand-alone without a Bootloader in place clean This build target does not produce an image. It is only used to clean up all build artifacts produced by any of the other build targets. Usually the build process is incremental to save time but after a <code>clean</code>, the build process triggered by any of the other build targets starts from scratch and takes more time to execute. <p>You can consider the listed configurations as templates and adapt them as necessary. You can also remove some of them if you don't want to support different configuration flavors.</p> <p>Keeping a smaller number of build configurations makes maintenance much easier after all.</p>"},{"location":"devguide/devguide_buildcfg.html#additional-notes","title":"Additional notes","text":""},{"location":"devguide/devguide_buildcfg.html#debug-configurations","title":"Debug configurations","text":"<p>All Debug configurations have the <code>DEBUG_ENABLED</code> pre-processor symbol defined. Based on that you can enable certain features which will only exist in the debug version of your builds, e.g.</p> <pre><code>#ifdef DEBUG_ENABLED\n    // code available only in debug configurations\n#endif\n</code></pre> <p>Tip</p> <p>Search in the source code for the above pre-processor check to identify how debug builds differ compared to release builds.</p> <p>The main difference is that debug builds usually end up in the <code>main.c::Error_Handler()</code> function when an error cannot be handled by the normal application logic. There is also a <code>bkpt</code> instruction in this handler which (in a running debug session) causes the debugger to automatically stop on a breakpoint at the location of the instruction which allows you to move up the stack and locate what triggered the error initially.</p>"},{"location":"devguide/devguide_buildcfg.html#debug-and-release-configurations","title":"debug and release configurations","text":"<p>The debug and release build configurations produce an application image which requires an EnduroSat Bootloader to run it. It cannot start on its own because code execution from FLASH starts at address <code>0x08000000</code> while the image produced by a release build is set to start at address <code>0x08100000</code>.</p> <p>Therefore, in order to debug regular application builds, you shall:</p> <ol> <li>Flash an EnduroSat Bootloader image.</li> <li>Use the Bootloader to perform the regular application update which ensures that the application image CRC is updated in FLASH ROM.</li> <li>Load the application image via the debugger and you should be able to use breakpoints in the IDE.</li> </ol> <p>Tip</p> <p> Situation</p> <ul> <li>the OBC seems to be operating normally (e.g. LED is flashing, UART communication is running)</li> <li>debugger won't stop on any breakpoint that you set</li> </ul> <p> Hypothesis If you have you board flashed with a Bootloader, it may have refused to jump to your application due to a failed integrity check for the Application image, hence staying in Bootloader mode. As you are loading the application image via the debugger, it seems that this is the actual image running but in fact you are running the Bootloader image from another location in FLASH ROM and that is why your application breakpoints do not get hit.</p> <p>Note that the LED will blink significantly slower when it is in the bootloader application.</p>"},{"location":"devguide/devguide_buildcfg.html#noboot-configurations","title":"noboot configurations","text":"<p>These build variants are intended for prototyping of the application. The main difference to the regular application configurations is that the full FLASH ROM is available to the application and it is configured to start from address <code>0x08000000</code> where the Bootloader normally starts. This enables immediate debugging of your code without the need to flash a Bootloader to bootstrap your application.</p> <p>When you finish new implementation and testing though, it is preferrable to switch to the regular app configuration and test your application by flashing it via the Bootloader image. This is how you will be operating in space eventually.</p>"},{"location":"devguide/devguide_buildcfg.html#additional-boot-configuration-options","title":"Additional boot configuration options","text":"<p>The OBC SDK provides different build-time configuration options which completely enable or disable certain behaviors and functions in the SDK. This is usually done if you need more FLASH/RAM memory and you want to strip off certain functionalities you don't want to use so that they are not included in the final executable.  For more details on the supported options, please refer directly to the root <code>CMakeLists.txt</code> file and search for the <code>ADD_OPTION</code> function calls.</p> <p>Example CMake option format</p> <p><pre><code>ADD_OPTION(DEBUG_TRACE_LIBHSM_ENABLED \"Enable LIBHSM debug tracing\" OFF ROOT_COMPILE_DEFS)\n                      |                               |              |\n                      1                               2              3\n</code></pre> <code>1</code> - option pre-processor symbol which can be used in the source code to check if the option is ON or OFF, e.g. <pre><code>#if defined(DEBUG_TRACE_LIBHSM_ENABLED)\n...\n#endif\n</code></pre> <code>2</code> - option description  <code>3</code> - option state (valid choices are <code>ON</code> or <code>OFF</code>)</p> <p>If you want to modify a certain option, just change parameter <code>3</code> to the state you desire and make re-build of the SDK.</p>"},{"location":"devguide/devguide_buildcfg.html#eclipse-ide-indexer-configuration","title":"Eclipse IDE indexer configuration","text":"<p>To provide easy code browsing function which is absolutely in line with the configuration built(macros, includes, etc) for managed builds(as the one OBC is using) it is possible to configure the Eclipse IDE to use \"compile_commands.json\" file. It was found that indexing with this option enabled takes Eclipse IDE about 3 minutes each time this \"compile_commands.json\" is changed. Because of that what EnduroSat provides is a different configuration of the project in the Eclipse IDE which enables this option. The configuration which can be used to provide this code browsing functionality is called \"ProperIndex\".</p> <p>Follow the installation instructions for each HW module and make sure your connections are working fine before attempting to execute any of the following steps in this chapter.</p> <p> Choose Eclipse IDE configuration </p> <p>Tip</p> <p>It is recommended to use \"Default\" configuration, because the time lost in indexing is far less, but in case the code browsing functionality is needed \"ProperIndex\" configuration can be used temporary!</p>"},{"location":"devguide/devguide_cmake.html","title":"Build structure","text":"<p>The OBC SDK build is orchestrated by several tools each being responsible to generate specific build products. A short overview is presented below:</p> <p></p> Tool Build location Description macaron build wrapper <code>build/macaron.py</code> A Python script which performs high-level build orchestration and specific side-tasks which are difficult to manage with CMake alone. This script also provides a front-end for CMake to call the macchiato code generator in an easier and more streamlined way. CMake user system dependent CMake is an open-source, cross-platform family of tools designed to build, test and package software. CMake is used to control the software compilation process using simple platform and compiler independent configuration files, and generate native makefiles and workspaces that can be used in the compiler environment of your choice. ninja user system dependent Ninja is a small build system with a focus on speed. It differs from other build systems in two major respects: it is designed to have its input files generated by a higher-level build system, and it is designed to run builds as fast as possible. macchiato <code>other/scripts/gen/macchiato/macchiato.jar</code> This is a code-generation Xtend-based framework used by EnduroSat to facilitate generation of source code and documentation from Franca IDL files (a.k.a. FIDL). This is the standard EnduroSat way of describing inter-module communication APIs. FIDLs are also used to generate certain parts of the OBC SDK in order to streamline development and enable faster configuration of the system. macchiato usage is documented in detail in a separate package. Please check with your EnduroSat support team on how to obtain the latest reference."},{"location":"devguide/devguide_cmake.html#building-obc-sdk-from-the-console-via-macaron","title":"Building OBC SDK from the console via macaron","text":"<p>If you checked the Quick-start guide already, you know how to build the OBC SDK from the STM32CubeIDE. However, there are times when you would like to automate your builds for easier testing and perhaps call your build process from a CI/CD pipeline. In such scenarios, you should opt for building the OBC SDK from a console using the macaron build wrapper.</p> <p>As a first step, you shall ensure that you have a correctly setup environment with all necessary tooling in your system path. That would be:</p> <ul> <li>Python 3+ interpreter</li> <li>CMake executable</li> <li>ninja executable</li> <li>Java Runtime Environment</li> </ul> <p>Now to trigger the build process:</p> <ol> <li>Open a system console</li> <li>Change your working folder by typing <code>cd &lt;OBC SDK&gt;/build</code> ( replace <code>&lt;OBC SDK&gt;</code> with the actual path where you extracted the OBC SDK sources)</li> <li>Start a clean build of the <code>noboot_debug</code> target by typing <code>python macaron.py -b noboot_debug -c -rl</code></li> <li>If everything is correctly setup, you should observe the same output as the one printed in the STM32CubeIDE console:</li> </ol> <pre><code>2022-10-17 10:36:49,885 | INFO     | &lt;module&gt;:404 | EnduroSat -macaron- build front-end [v0.2]\n2022-10-17 10:36:49,886 | DEBUG    | &lt;module&gt;:407 | macaron.py started with args: Namespace(build='noboot_debug', release_ver=None, clean=False, clean_gen_content=WindowsPath('.'), fp_gen=False, datacache_gen=False, fp_gen_all=False, depl_config='', fp_merge_root=WindowsPath('.'), verbose=True, error_out_only=False, reset_log=True)\n2022-10-17 10:36:49,886 | WARNING  | get_build_root_path:84 | ESPF_ROOT_BUILD_PATH environment variable not set. Using default path setting resolving to \"C:\\Projects\\OBC\\demo\\3.0.2.sdk\".\n2022-10-17 10:36:49,892 | INFO     | print_cmd_info:130 | &gt;  starting command: \"cmake . -G Ninja Multi-Config -DCMAKE_TOOLCHAIN_FILE=arm_toolchain.cmake\"...\n2022-10-17 10:36:50,619 | DEBUG    | run_cmd:153 |  -- The C compiler identification is GNU 10.3.1\n2022-10-17 10:36:51,066 | DEBUG    | run_cmd:153 |  -- The ASM compiler identification is GNU\n2022-10-17 10:36:51,198 | DEBUG    | run_cmd:153 |  -- Found assembler: C:/ST/STM32CubeIDE_1.4.0/STM32CubeIDE/plugins/com.st.stm32cube.ide.mcu.externaltools.gnu-tools-for-stm32.10.3-2021.10.win32_1.0.0.202111181127/tools/bin/arm-none-eabi-gcc.exe\n2022-10-17 10:36:51,242 | DEBUG    | run_cmd:153 |  -- Detecting C compiler ABI info\n2022-10-17 10:36:52,001 | DEBUG    | run_cmd:153 |  -- Detecting C compiler ABI info - done\n2022-10-17 10:36:52,043 | DEBUG    | run_cmd:153 |  -- Check for working C compiler: C:/ST/STM32CubeIDE_1.4.0/STM32CubeIDE/plugins/com.st.stm32cube.ide.mcu.externaltools.gnu-tools-for-stm32.10.3-2021.10.win32_1.0.0.202111181127/tools/bin/arm-none-eabi-gcc.exe - skipped\n2022-10-17 10:36:52,044 | DEBUG    | run_cmd:153 |  -- Detecting C compile features\n2022-10-17 10:36:52,045 | DEBUG    | run_cmd:153 |  -- Detecting C compile features - done\n2022-10-17 10:36:52,093 | DEBUG    | run_cmd:153 |  -- &gt;&gt; Active build configuration: noboot_debug\n2022-10-17 10:36:52,256 | DEBUG    | run_cmd:153 |  -- looking for pre-built library 'C:/Projects/OBC/demo/3.0.2.sdk/build/../lib/noboot_debug/libespsi_drv.a'\n2022-10-17 10:36:52,256 | DEBUG    | run_cmd:153 |  -- looking for pre-built library 'C:/Projects/OBC/demo/3.0.2.sdk/build/../lib/noboot_debug/libespsi_drv.a' - not found - will attempt to build from source\n2022-10-17 10:36:52,259 | DEBUG    | run_cmd:153 |  -- looking for pre-built library 'C:/Projects/OBC/demo/3.0.2.sdk/build/../lib/noboot_debug/libESPSI.a'\n2022-10-17 10:36:52,259 | DEBUG    | run_cmd:153 |  -- looking for pre-built library 'C:/Projects/OBC/demo/3.0.2.sdk/build/../lib/noboot_debug/libESPSI.a' - found - will perform a direct linkage\n2022-10-17 10:36:52,260 | DEBUG    | run_cmd:153 |  -- looking for pre-built library 'C:/Projects/OBC/demo/3.0.2.sdk/build/../lib/noboot_debug/libespf_sub.a'\n2022-10-17 10:36:52,260 | DEBUG    | run_cmd:153 |  -- looking for pre-built library 'C:/Projects/OBC/demo/3.0.2.sdk/build/../lib/noboot_debug/libespf_sub.a' - not found - will attempt to build from source\n2022-10-17 10:36:52,485 | DEBUG    | run_cmd:153 |  -- Configuring done\n2022-10-17 10:36:54,306 | DEBUG    | run_cmd:153 |  -- Generating done\n2022-10-17 10:36:54,494 | DEBUG    | run_cmd:153 |  -- Build files have been written to: C:/Projects/OBC/demo/3.0.2.sdk/build\n2022-10-17 10:36:54,506 | INFO     | print_cmd_info:130 | &gt;  command finished successfully!\n2022-10-17 10:36:54,506 | INFO     | print_cmd_info:130 | &gt;  starting command: \"cmake --build . --config noboot_debug\"...\n2022-10-17 10:36:56,598 | DEBUG    | run_cmd:153 |  [1/328] Building C object libespsi_drv/CMakeFiles/espsi_drv.dir/noboot_debug/src/esps_drv_stats.c.obj\n2022-10-17 10:36:56,598 | DEBUG    | run_cmd:153 |  [2/328] Building C object libespsi_drv/CMakeFiles/espsi_drv.dir/noboot_debug/src/esps_drv_pool.c.obj\n2022-10-17 10:36:56,598 | DEBUG    | run_cmd:153 |  [3/328] Building C object libespsi_drv/CMakeFiles/espsi_drv.dir/noboot_debug/src/esps_drv_queue.c.obj\n2022-10-17 10:36:56,598 | DEBUG    | run_cmd:153 |  [4/328] Building C object libespsi_drv/CMakeFiles/espsi_drv.dir/noboot_debug/src/esps_drv_dispatcher.c.obj\n2022-10-17 10:36:56,598 | DEBUG    | run_cmd:153 |  [5/328] Building C object libespsi_drv/CMakeFiles/espsi_drv.dir/noboot_debug/src/esps_drv.c.obj\n.\n.\n.\n2022-10-17 10:39:03,323 | DEBUG    | run_cmd:153 |  [324/328] Building C object libespf_sub/payload_ctrl/CMakeFiles/payload_ctrl.dir/noboot_debug/src/payload_ctrl.c.obj\n2022-10-17 10:39:03,324 | DEBUG    | run_cmd:153 |  [325/328] Building C object libespf_sub/payload_ctrl/CMakeFiles/payload_ctrl.dir/noboot_debug/fp/Payload_Control/v0.1/Payload_Control_server/FP_Payload_ControlServerApp.c.obj\n2022-10-17 10:39:03,324 | DEBUG    | run_cmd:153 |  [326/328] Linking C static library libespf_sub\\payload_ctrl\\noboot_debug\\libpayload_ctrl.a\n2022-10-17 10:39:10,456 | DEBUG    | run_cmd:153 |  [327/328] Linking C static library libespf_sub\\noboot_debug\\libespf_sub.a\n2022-10-17 10:39:10,456 | DEBUG    | run_cmd:153 |  [328/328] Linking C executable noboot_debug\\OBC_STDPF_STM32H.elf\n2022-10-17 10:39:10,456 | DEBUG    | run_cmd:153 |     text    data     bss     dec     hex filename\n2022-10-17 10:39:10,456 | DEBUG    | run_cmd:153 |   334752   26080  127160  487992   77238 C:/Projects/OBC/demo/3.0.2.sdk/build/noboot_debug/OBC_STDPF_STM32H.elf\n2022-10-17 10:39:10,457 | DEBUG    | run_cmd:153 |  EnduroSat -macaron- build front-end [v0.2]\n2022-10-17 10:39:10,457 | DEBUG    | run_cmd:153 |  macaron.py started with args: Namespace(build=None, release_ver=None, clean=False, clean_gen_content=WindowsPath('C:/Projects/OBC/demo/3.0.2.sdk/build/../espf'), fp_gen=False, datacache_gen=False, fp_gen_all=False, depl_config='', fp_merge_root=WindowsPath('.'), verbose=False, error_out_only=False, reset_log=False)\n2022-10-17 10:39:10,457 | DEBUG    | run_cmd:153 |  ESPF_ROOT_BUILD_PATH environment variable not set. Using default path setting resolving to \"C:\\Projects\\OBC\\demo\\3.0.2.sdk\".\n2022-10-17 10:39:10,457 | DEBUG    | run_cmd:153 |  cleaning up all directories with name \"src-gen-c\" under \"C:\\Projects\\OBC\\demo\\3.0.2.sdk\\espf\"...\n2022-10-17 10:39:10,485 | INFO     | print_cmd_info:130 | &gt;  command finished successfully!\n2022-10-17 10:39:10,485 | INFO     | &lt;module&gt;:463 | &gt;&gt;&gt; BUILD OK (140.60 sec) &lt;&lt;&lt;\n2022-10-17 10:39:10,486 | INFO     | clean_directories_by_name:115 | cleaning up all directories with name \"src-gen-c\" under \"C:\\Projects\\OBC\\demo\\3.0.2.sdk\\build\"...\n</code></pre> <p>Tip</p> <p>If you start <code>macaron.py</code> without any options, you will see a list of all options available. Feel free to experiment with those.</p> <p>Finding build errors more easily...</p> <p>If something goes wrong with the build, you can pass the <code>-v</code> option to macaron to get even more details printed.   Also, macaron stores a full log of the build process in a file called <code>build/macaron.log</code>. You can open it with any text editor (best viewed with Visual Studio Code due to highglighting support for log files) and inspect what went wrong by searching for <code>error</code> or <code>warn</code> keywords.</p>"},{"location":"devguide/devguide_cmake.html#cmake-build-organization","title":"CMake build organization","text":"<p>The OBC SDK CMake build is organized in a multi-level hierarchy to promote modularity and enable code reuse at different levels. The overall build structure can be presented in the following way:</p> <p> OBC SDK CMake files hierarchy<sup>1</sup></p> <p>Each <code>CMakeLists.txt</code> file (apart from the top-most) in the build produces a static library and those libraries get linked together to form the final executable image.</p> <p>Note</p> <p>Not all parts of the OBC SDK source code are implemented as static libraries. It makes sense to do this for implementations which are reusable between multiple projects or which do not change often, thus decreasing the compilation time required for the whole project.</p> <p>Tip</p> <p>For a detailed information on the <code>CMakeLists.txt</code> file for the OBC SDK documentation, please check the comments inside that file. This document does not aim to repeat this information here to ensure the information is always up-to-date.</p>"},{"location":"devguide/devguide_cmake.html#build-version","title":"Build version","text":"<p>The build tool, macaron, gives the option to set the release version of the code which is going to be passed to CMake which will define the version and the description of the build. The format macaron expects is:</p> <p>Mayor.minor.patch-label (<code>MM.mm.pp[-label]</code>)</p> <p>The label is going to be added to the build description reported by the OBC, which by default will be <code>\"STDPF-STM32H_&lt;label&gt;\"</code>. The maximum length of this field is 30 chars and a longer string will be truncated.</p> <p>The version string will be written in a file, <code>&lt;OBC SDK&gt;/version</code>, and CMake will use that file to define the version variables that are going to be used for building the code. If CMake can't read a valid version string from the file, it will use a default version.</p>"},{"location":"devguide/devguide_cmake.html#default-build-version","title":"Default build version","text":"<p>When the build is triggered without specifying the release version (<code>--release-ver</code> option), macaron will then get the latest tag it can find using git, and use that as a version. The version is obtained by using the command <code>git describe</code> (more info about it in the official git documentation).</p> <p>Important</p> <p>If the OBC SDK is not part of a git respository or no tags are found, macaron will set a default version: <code>99.99.99-dev</code>.</p> <p>Warning</p> <p>It is not recommended to leave the default version value <code>99.99.99-dev</code>. The user should use the SDK version instead.</p> <ol> <li> <p>This is only an illustration how the build is structured and may not exactly match the real structure of this project.\u00a0\u21a9</p> </li> </ol>"},{"location":"devguide/devguide_conops.html","title":"Concept of Operations","text":"<p>The Concept of Operations (ConOps) provides the backbone for automated spacecraft control and operations. It consists of three main component:</p> <ul> <li>Logic controlling the transitions between the different ConOps modes</li> <li>Automated recovery to Sun-Tracking (or Nadir Pointing)</li> <li>Configuration</li> </ul> <p>Note</p> <p>The implementation details of the presented ConOps are documented in the Code Reference section, under <code>Files/File List/espf/app/conops</code>.</p>"},{"location":"devguide/devguide_conops.html#operational-modes","title":"Operational Modes","text":"<p>There are four different main modes in the ConOps.</p>"},{"location":"devguide/devguide_conops.html#safe","title":"SAFE","text":"<p>This is the default mode after power-up of the OBC. When this mode is activated all payloads are powered-off and all internally used logical flags are cleared.</p> <p>This mode is used in several ways:</p> <ul> <li>To commission the platform and more specifically the used ADCS (AOCS) subsystem</li> <li>To automatically control the satellite to Sun-Tracking mode (STT) or Nadir pointing</li> <li>As the SAFE place to return to when an error in the platform is detected</li> </ul>"},{"location":"devguide/devguide_conops.html#detumbling","title":"DETUMBLING","text":"<p>This mode is entered once the platform detumbling needs are not met. This can happen when:</p> <ul> <li>The angular velocity norm exceeds a user configurable threshold</li> <li>The angular velocity per axis is not within a user configurable threshold</li> <li>A specific AOCS State has been activated (for example, by the FDIR logic of the used ADCS or during STT transitions)</li> <li>Non-nominal behaviour detected, which has introduced large angular velocity in the platform (such as sudden stop of the reaction wheels)</li> </ul> <p>The embedded logic will execute until either the angular velocity norm is brought below the user configured threshold or the angular velocity per axis is contained within the user configured thresholds.</p>"},{"location":"devguide/devguide_conops.html#idle","title":"IDLE","text":"<p>IDLE mode is the standard mode of operation once the platform has been successfully commissioned. It is accessible only via a command initiated from ground and it is the only mode from which any payload can be activated.</p>"},{"location":"devguide/devguide_conops.html#payload-modes","title":"Payload Modes","text":"<p>The Payload Modes can be activated once the platform is in IDLE mode. The payload modes can be anything - from downlink, file transfer, inertial pointing or specific payload operation. It is up to the user to define these.</p>"},{"location":"devguide/devguide_conops.html#mode-transitions","title":"Mode Transitions","text":"<p>Transitions are based on parameters, which are fed to the ConOps. The thresholds which dictate the transitions are based on the input parameters after applying user-configurable multipliers.</p> <p>The multipliers, parameters and the transitions (high-level and detailed) are depicted further down.</p>"},{"location":"devguide/devguide_conops.html#used-physical-parameters","title":"Used Physical Parameters","text":"Physical Parameter Description Units <code>C_batt</code> Measured battery capacity [mWh] <code>C_Safe</code> Battery capacity threshold for entrance into Safe mode [mWh] <code>S_safe</code> Multiplier, used to configure the battery capacity threshold in SAFE mode after which the OBC can transition back into IDLE mode [mWh] <code>S_Det</code> Multiplier, used to configure the battery capacity threshold in SAFE mode after which the OBC can transition into Detumbling mode [mWh] <code>S_Pay[i]</code> Multiplier, used to configure the battery capacity threshold in IDLE mode after which the OBC can transition into Pay[i] mode [mWh] <code>\u03a9</code> Measured norm of the angular velocity vector as measured in the satellite body-frame [mrad/s] <code>\u03a9_max</code> Angular rate threshold above which the platform will automatically transition to Detumbling mode [mrad/s]"},{"location":"devguide/devguide_conops.html#used-logical-parameters","title":"Used Logical Parameters","text":"Logical Parameter Description <code>IDLE_Flag</code> Logical variable which indicates whether we can go from SAFE mode to IDLE mode <code>Error_Flags</code> Logical variable which indicates whether an error occurred and if SAFE mode or IDLE mode has to be entered <code>Detumbled_Flag</code> Logical variable which indicates that detumbling has been completed and we can transition back to SAFE mode <code>Pay_Flag[i]</code> Logical variable which indicates that we can transition from IDLE to Pay[i] mode <code>Timeout[i]</code> Logical variable which indicates the timeout for the operation of the corresponding Pay[i] mode"},{"location":"devguide/devguide_conops.html#general-transitions","title":"General Transitions","text":"<p>The following table gives the high-level transitions used in the ConOps.</p> FROM MODE / TO MODE SAFE IDLE DETUMBLING Pay[i] Mode <code>SAFE</code> N/A (IDLE_Flag) AND (C_batt &gt; S_Safe * C_Safe) (C_batt &gt; S_Det * C_Safe) AND (\u03a9 &gt; \u03a9_max) <code>IDLE</code> (C_batt &lt; C_Safe) OR (Error_Flag) N/A (C_batt &gt; S_pay[ i ] * C_Safe) AND (Pay_Flag[ i ]) <code>DETUMBLING</code> (C_batt &lt; C_Safe) OR (Error_Flag) OR (Detumbled_Flag) N/A <code>Pay[i] Mode</code> (C_batt &lt; C_Safe) OR (Error_Flag) (!Pay_Flag[ i ]) OR (Timeout[ i ]) N/A"},{"location":"devguide/devguide_conops.html#detailed-transitions","title":"Detailed Transitions","text":""},{"location":"devguide/devguide_conops.html#safe-to-detumbling","title":"SAFE to DETUMBLING","text":"<p>This section describes in a table view the conditions and changes in the ADCS system state when the ConOps transitions from SAFE mode to DETUMBLING mode</p>"},{"location":"devguide/devguide_conops.html#guard-condition","title":"Guard Condition","text":"Begin State Batt_Cap &gt; Thresh Angular Rate &gt; Thresh ADCS_State == DETUMB<sup>1</sup> ADCS_State == FAST_DETUMB<sup>2</sup> Commissioning Status End State <code>SAFE</code> <code>-</code> <code>-</code>   &gt; 1 <code>DETUMBLING</code> <code>SAFE</code> <code>-</code> <code>-</code> <code>-</code>   &gt; 1 <code>DETUMBLING</code> <code>SAFE</code> <code>-</code> <code>-</code> <code>-</code> <code>-</code> <code>DETUMBLING</code> <p>Note</p> <p><code>-</code> indicates that the condition is don't care</p>"},{"location":"devguide/devguide_conops.html#on-entering-detumbling","title":"On entering DETUMBLING","text":"Begin ADCS_State ADCS_STATE == PWR_UP End ADCS State <code>PWR_UP</code> <code>NORMAL_DETUMBLING</code> <code>NORMAL_DETUMBLING</code> <code>-</code> <code>NORMAL_DETUMBLING</code> <code>FAST_DETUMBLING</code> <code>-</code> <code>FAST_DETUMBLING</code> <code>VERY_FAST_DETUMBLING</code> <code>-</code> <code>VERY_FAST_DETUMBLING</code>"},{"location":"devguide/devguide_conops.html#detumbling-to-safe","title":"DETUMBLING to SAFE","text":"<p>This section describes in a table view the conditions and changes in the ADCS system state when the ConOps transitions from DETUMBLING mode to SAFE mode</p>"},{"location":"devguide/devguide_conops.html#guard-condition_1","title":"Guard Condition","text":"Begin State Batt_Cap &lt; Thresh Error Flag Detumb Completed End State <code>DETUMBLING</code> <code>-</code> <code>-</code> <code>SAFE</code> <code>DETUMBLING</code> <code>-</code> <code>SAFE</code> <code>DETUMBLING</code> <code>SAFE</code>"},{"location":"devguide/devguide_conops.html#on-exiting-detumbling","title":"On exiting DETUMBLING","text":"Begin ADCS_State Detumb Completed ADCS_STATE == FAST_DETUMBLING ADCS_STATE == VERY_FAST_DETUMBLING Commissioning Status End ADCS State <code>-</code> <code>-</code> <code>-</code> <code>-</code> <code>PWR_UP</code> <code>FAST_DETUMBLING</code>  &gt; 1 <code>Y_THOMSON_MEMS_RATE</code> <code>VERY_FAST_DETUMBLING</code>  &gt; 1 <code>Y_THOMSON_MEMS_RATE</code> <code>FAST_DETUMBLING</code>  &gt; 1 <code>PWR_UP</code> <code>VERY_FAST_DETUMBLING</code>  &gt; 1 <code>PWR_UP</code> <code>-</code> <code>-</code> <code>Y_THOMSON</code>"},{"location":"devguide/devguide_conops.html#safe-to-idle","title":"SAFE to IDLE","text":""},{"location":"devguide/devguide_conops.html#guard-condition_2","title":"Guard Condition","text":"Begin State Batt_Cap &gt; Thresh ADCS_STATE == SUN_TRACKING ADCS_STATE == Y_MOMENTUM ADCS_STATE == Y_MOMENTUM_FULL_STATE_EKF ADCS_STATE == 3AXIS End State <code>SAFE</code> <code>IDLE</code> <code>SAFE</code> <code>IDLE</code> <code>SAFE</code> <code>IDLE</code> <code>SAFE</code> <code>IDLE</code>"},{"location":"devguide/devguide_conops.html#idle-to-safe","title":"IDLE to SAFE","text":""},{"location":"devguide/devguide_conops.html#guard-condition_3","title":"Guard Condition","text":"Begin State Batt_Cap &lt; Thresh Error Flag ADCS_STATE != SUN_TRACKING ADCS_STATE != Y_MOMENTUM ADCS_STATE != Y_MOMENTUM_FULL_STATE_EKF ADCS_STATE != 3AXIS Angular Rate &lt; Thresh* 3-Axis ADCS<sup>3</sup> End State End ADCS State <code>IDLE</code> <code>-</code> <code>-</code> <code>-</code> <code>-</code> <code>SAFE</code> <code>SUN_TRACKING</code> <code>IDLE</code> <code>-</code> <code>-</code> <code>-</code> <code>-</code> <code>SAFE</code> <code>Y_MOMENTUM</code> <code>IDLE</code> <code>-</code> <code>-</code> <code>-</code> <code>-</code> <code>-</code> <code>SAFE</code> <code>NORMAL_DETUMBLING</code> <code>IDLE</code> <code>-</code> <code>-</code> <code>-</code> <code>-</code> <code>-</code> <code>-</code> <code>SAFE</code> <code>NORMAL_DETUMBLING</code> <code>IDLE</code> <code>-</code> <code>-</code> <code>-</code> <code>-</code> <code>-</code> <code>SAFE</code> <code>NORMAL_DETUMBLING</code> <code>IDLE</code> <code>-</code> <code>-</code> <code>-</code> <code>-</code> <code>-</code> <code>SAFE</code> <code>NORMAL_DETUMBLING</code> <code>IDLE</code> <code>SAFE</code> <code>SUN_TRACKING</code> <code>IDLE</code> <code>SAFE</code> <code>Y_MOMENTUM</code> <code>IDLE</code> <code>-</code> <code>SAFE</code> <code>NORMAL_DETUMBLING</code> <p>Note</p> <p>3-Axis ADCS indicates that the ADCS subsystem is capable of 3-axis maneuvres. This is a configuration that the user must update based on the used ADCS.</p>"},{"location":"devguide/devguide_conops.html#idle-to-payload","title":"IDLE to PAYLOAD","text":""},{"location":"devguide/devguide_conops.html#guard-condition_4","title":"Guard Condition","text":"Begin State Batt_Cap &gt; Thresh End State <code>IDLE</code> <code>PAYLOAD</code>"},{"location":"devguide/devguide_conops.html#payload-to-safe","title":"PAYLOAD to SAFE","text":""},{"location":"devguide/devguide_conops.html#guard-condition_5","title":"Guard Condition","text":"Begin State Batt_Cap &lt; Thresh Error Flag End State <code>PAYLOAD</code> <code>-</code> <code>SAFE</code> <code>PAYLOAD</code> <code>SAFE</code>"},{"location":"devguide/devguide_conops.html#on-exiting-payload","title":"On exiting PAYLOAD","text":"Begin ADCS_State Angular Rate &lt; Thresh<sup>3</sup> 3-Axis ADCS End ADCS State <code>-</code> <code>SUN_TRACKING</code> <code>-</code> <code>Y_MOMENTUM</code> <code>-</code> <code>-</code> <code>NORMAL_DETUMBLING</code>"},{"location":"devguide/devguide_conops.html#using-the-conops-interface","title":"Using the ConOps interface","text":"<p>Note</p> <p>This section assumes that the reader is already familiar with the ConOps description presented up to this point.</p> <p>The following section gives an overview of some typical use cases of the Concept of Operations.</p>"},{"location":"devguide/devguide_conops.html#changing-the-mode","title":"Changing the mode","text":"<p>The user can request to change the ConOps state machine mode at any moment by issuing the <code>ConOps.fidl::sendNewEvent</code> command from the <code>&lt;OBC SDK&gt;/espf/core/fidl/obc/fp/ConOps.fidl</code> interface (from now on referred to as the ConOps interface). The user will have to specify the requested mode, as well as the parameters, which can be used by that mode. In reality, only the payload modes make use of these parameters and the other modes just ignore them. The change to the new mode may or may not happen. The transition will depend on the state machine allowed transitions and on the guard conditions evaluation.</p> <p>The user can check if a commanded transtion has been successful, by requesting the currently active mode from the <code>ConOps.fidl::getOpMode</code> command.</p> <p>Note</p> <p>Details regarding the state machine as well as supporting logic can be found in the Code Reference section.</p>"},{"location":"devguide/devguide_conops.html#configurations","title":"Configurations","text":"<p>The ConOps behaviour can be tuned based on the mission requirements through the modification of several thresholds. These are persistent configurations and as such are stored in non-volatile memory. The user can modify these at any point and the effect is immediate.</p>"},{"location":"devguide/devguide_conops.html#thresholds-of-the-physical-parameters","title":"Thresholds of the physical parameters","text":"<p>These thresholds correspond to the ones described under the used physical parameters here. The user can opt to change these one by one, by issuing the <code>ConOps.fidl::setThreshVal</code> command or to change all of them at once by issuing the <code>ConOps.fidl::setAllThreshVal</code> command. Respectively, one can check a single threshold value or all threshold values by issuing <code>ConOps.fidl::getThreshVal</code> and <code>ConOps.fidl::getAllThreshVal</code>.</p> <p>Note</p> <p>The SDK is provided with preset threshold values. However, these may be very different for the different mission scenarios (and can typically change during the mission lifetime). The user must analyse the mission requirements and change these thresholds accordingly.</p>"},{"location":"devguide/devguide_conops.html#sun-tracking-flag","title":"Sun-tracking flag","text":"<p>This is again a persistent configuration. Typically, the user will need to set this only once as it reflects the type of the ADCS hardware interfacing to the OBC. The two envisioned cases are:</p> <ul> <li>A 3-axis stabilised ADCS</li> <li>Y-Momentum ADCS (a one wheel solution)</li> </ul> <p>The flag value dictates the default AOCS State when the ConOps is in IDLE mode. For example, if the used ADCS hardware is 3-axis stabilised and the flag value is set to indicate this, each time the ConOps makes a switch from PAYLOAD mode to IDLE mode, the SUN_TRACKING AOCS State will be triggered. If, however, the flag value is not set, then the default AOCS State will be Y_MOMENTUM.</p> <p>Note</p> <p>Some missions may prefer nadir pointing as the default control mode. In this case, the user can modify the ConOps respectively, by changing SUN_TRACKING control to THREE_AXIS_CONTROL in the code.</p>"},{"location":"devguide/devguide_conops.html#scheduling","title":"Scheduling","text":"<p>The activation and deactivation of payloads is orchestrated by the Payload Scheduler, first introduced in Payload Operations.</p> <p>Two commands associated to scheduling are part of the ConOps.fidl interface. These are:</p> <ul> <li><code>ConOps.fidl::addNewScheduleRecord</code>, which can be used to add a new entry to the first empty slot (if such is present).</li> <li><code>ConOps.fidl::clearScheduleRecords</code>, which clears all scheduled entries.</li> </ul>"},{"location":"devguide/devguide_conops.html#using-the-conops-from-other-software-modules","title":"Using the ConOps from other software modules","text":"<p>Most of the methods described in the <code>ConOps.fidl</code> interface make use of the ConOps's public interface <code>&lt;OBC SDK&gt;/espf/app/conops/conops.h</code>. For example, <code>ConOps.fidl::sendNewEvent</code> makes use of <code>conops_trigger_hsm(const uint32_t event_id, const sConOps_pay_cfg_t *const pay_cfg)</code>, which in turn is also used by different software modules from within the SDK.</p> <p>Likewise, the user can use the public interface to achieve the same functionality as the one described in the dedicated interface.</p> <ol> <li> <p>When the ADCS_State equals DETUMB this means that the ADCS subsystem is either in Normal Detumbling or Y-Thomson Detumbling \u21a9</p> </li> <li> <p>When the ADCS_State equals FAST_DETUMB the ADCS subsystem can either be in Very Fast Detumbling or Fast Detumbling \u21a9</p> </li> <li> <p>Angular Rate &lt; Thresh here indicates that the measured angular rate should be contained in [-39:39] mrad/s\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"devguide/devguide_cubeadcs_gen2_service.html","title":"CubeADCS Gen2 Service","text":"<p>This section introduces the CubeADCS Generation 2 integration (also referred to as the Gen2 Service) in EnduroSat's Onboard Computer.</p>"},{"location":"devguide/devguide_cubeadcs_gen2_service.html#interfaces","title":"Interfaces","text":"<p>The Gen2 Service makes use of one FP interface: <code>&lt;OBC SDK&gt;/espf/core/fidl/obc/fp/OBC_CUBEADCS_GEN2.fidl</code>. Most commands are introduced in this page, along with the related functionality. The rest are documented directly in the interface.</p>"},{"location":"devguide/devguide_cubeadcs_gen2_service.html#software-decomposition","title":"Software decomposition","text":"<p>The Gen2 Service is a software component put together using several software sub-components each having a dedicated purpose (note that arrows in the diagram depict information exchange):</p> <p></p>"},{"location":"devguide/devguide_cubeadcs_gen2_service.html#cubeadcs_gen2_int","title":"cubeadcs_gen2_int","text":"<p>This sub-component is the interface adapter between the AOCS control service and the Gen2 Service. It implements the interface provided by the AOCS control service, mitigating the differences between the control service and the used ADCS. The integration code is located in <code>&lt;OBC SDK&gt;/espf/config/aocs/aocs_cntrl</code>.</p>"},{"location":"devguide/devguide_cubeadcs_gen2_service.html#cubeadcs_cp","title":"cubeadcs_cp","text":"<p>This is the command protocol level command implementation dedicated to the Gen2 ADCS. It exposes all available telecommand and telemetry commands (as per CubeSpace's documentation) to the user and gives the user the capability to control the CubeCore as well as any sensor or actuator directly.</p> <p>The FIDL files that can be used with this command protocol command are located in <code>&lt;OBC SDK&gt;/espf/core/fidl/obc/cp/cubeadcs_gen2</code>.</p> <p>The fidls can be used with the following configuration in SpaceDev:</p> <p></p> <p>where </p> <ul> <li>The Gateway Command (that is, the command protocol command) has to be set to 2000 DEC</li> <li>The FP Header checkbox must be checked</li> <li>The module address must be set to the MAC address of the OBC (51 DEC)</li> <li>The ESPS protocol type must be CP - command protocol</li> </ul> <p>Note</p> <p>Some of the other fields may vary according to the user's setup.</p>"},{"location":"devguide/devguide_cubeadcs_gen2_service.html#cubeadcs_gw","title":"cubeadcs_gw","text":"<p>This sub-component provides wrappers of the CubeSpace API (delivered with the libcubeobc library from CubeSpace) that provide protection of concurrent access to the ADCS as well as transparency of pass-through setup (refer to CubeSpace's documentation for information on the pass-through). In some rare occasions it could be beneficial to use the CubeSpace API with settings different than default, but we generally discourage that. Any usage of the API passes through this sub-component. It is located in <code>&lt;OBC SDK&gt;/espf/core/services/aocs/cubeadcs_gen2</code></p>"},{"location":"devguide/devguide_cubeadcs_gen2_service.html#cubeadcs_gen2_state_machine","title":"cubeadcs_gen2_state_machine","text":"<p>The Gen2 state machine is at the core of the service (<code>&lt;OBC SDK&gt;/espf/core/services/aocs/cubeadcs_gen2</code>). It is tasked with keeping track of the health status of the ADCS, downloading telemetry, checking for critical conditions that may have occured in the ADCS, FDIR and changing the control of the ADCS. The state machine is depicted further down the chapter where the different states are discussed in detail.</p>"},{"location":"devguide/devguide_cubeadcs_gen2_service.html#libcubeobc","title":"libcubeobc","text":"<p>This library is provided by CubeSpace. It provides the API to the ADCS including methods for serialisation and deserialisation of data. EnduroSat has integrated the library as part of the Gen2 Service. The library is located in <code>&lt;OBC SDK&gt;/espf/core/middlewares/external/libcubeobc</code></p>"},{"location":"devguide/devguide_cubeadcs_gen2_service.html#es_custom","title":"es_custom","text":"<p>This is custom logic developed in order to integrate CubeSpace's library. It contains locks, initialisation, deinitialisation functions as well as custom logic for performing file transfers.</p> <p>The relevant code can be located in <code>&lt;OBC SDK&gt;/espf/espf/arch/stm32h753iit/drivers/positioning/cubeobc</code>.</p>"},{"location":"devguide/devguide_cubeadcs_gen2_service.html#driver","title":"driver","text":"<p>This is the low-level driver used to initialise and handle the used interfaces.</p> <p>The relevant code can be located in <code>&lt;OBC SDK&gt;/espf/espf/arch/stm32h753iit/drivers/positioning/cubeobc</code>.</p>"},{"location":"devguide/devguide_cubeadcs_gen2_service.html#the-gen2-service-state-machine","title":"The Gen2 Service state machine","text":"<p>The state machine, with applicable transitions and guards, is depicted in the following figure:</p> <p></p> <p>It is a Hirarchical State Machine making use of the HSM engine located in <code>&lt;OBC SDK&gt;/espf/lib/libhsm/</code>. Implementation details are discussed in the Code Reference section of the SDK documentation and the code is located in <code>&lt;OBC SDK&gt;/espf/core/services/aocs/cubeadcs_gen2</code>.</p>"},{"location":"devguide/devguide_cubeadcs_gen2_service.html#backoff-state","title":"Backoff State","text":"<p>This is the initial state of the state machine. At power-up of the OBC, the state machine is initialised in this state and any reset of the state machine puts the state machine back in this state.</p> <p>The purpose of the state is two-fold:</p> <ul> <li>First, it provides the necessary back-off time of several seconds, necessary for the boot process of the ADCS.</li> <li>Second, once the back-off time has expired, it requests from the ADCS any configuration that is essential for its correct operation. The state continues requesting this information until it manages to successfully read it, after which it caches this value. By doing this, Gen2 Service confirms that communication with the ADCS is possible and it also receives, among other things, the connected nodes map, vital for the operation of cubeadcs_cp sub-component.</li> </ul>"},{"location":"devguide/devguide_cubeadcs_gen2_service.html#eventmarkeracquisition-state","title":"EventMarkerAcquisition State","text":"<p>The Gen2 ADCS keeps an internal log of events, each having a different severity level (refer to Gen2's documentation for further details). Some of these events indicate serious reduction in the ADCS control capabilities. Therefore, the Gen2 service periodically requests the events and analyses these looking for serious failures of the ADCS. At each event download cycle, only the events that have occured since the previous download are pulled from the ADCS.</p> <p>Note</p> <p>After the OBC powers-up, the Gen2 Service will read the last event that can compromise the ADCS, and store this to be used as the reference event for the next time we download events.</p>"},{"location":"devguide/devguide_cubeadcs_gen2_service.html#check-state","title":"Check State","text":"<p>The periodic check performs two tasks. First, it collects important telemetry data and aggregates it into a single ADCS operational state (not to be confused with the state machine states). This facilitates mission operations as the full state of the ADCS can be read using a single telecommand.</p> <p>Assuming the ADCS is in application mode, the second task of the Check State is to collect all the loggable telemetry (loggable in the sense that it is the same telemetry that the ADCS is logging to its internal memory) from the ADCS and to put it in the Data Cache. The benefit of doing this is that this data can now be used directly by the Telemetry and beacons services or by a user defined custom service. This also reduces the need to download telemetry files from the ADCS.</p> <p>Note</p> <p>The user can decide to download all loggable telemetry or a subset of it. This is configurable and the configuration is persistent, stored in the NVM.</p>"},{"location":"devguide/devguide_cubeadcs_gen2_service.html#relevant-commands","title":"Relevant commands","text":"<ul> <li><code>OBC_CUBEADCS_GEN2.fidl::getOpStatus</code> - used to return the ADCS operational state (aggregated important telemetry data)</li> <li><code>OBC_CUBEADCS_GEN2.fidl::get_tlm_cfg</code> - used to return the loggable telemetry configuration</li> <li><code>OBC_CUBEADCS_GEN2.fidl::set_tlm_cfg</code> - used to set the loggable telemetry configuration </li> </ul>"},{"location":"devguide/devguide_cubeadcs_gen2_service.html#idle-state","title":"Idle State","text":"<p>This is a do-nothing state. The state machine only listens for events here.</p>"},{"location":"devguide/devguide_cubeadcs_gen2_service.html#eventdownload-state","title":"EventDownload State","text":"<p>In this state, the logic will download the events that have occurred since the last execution of the EventDownload state and which have a certain severity. The amount of events that will be downloaded at each iteration is limited to 20. The reasoning is that it is not expected to have many events occuring between two executions of the EventDownload State.</p> <p>If any events were downloaded, then the FDIR State will be requested. Before the state is left, the last read event is cached and is used as the marker.</p> <p>Note</p> <p>The first time this state is executed, the event marker is the one set by the EventMarkerAcquisition State </p>"},{"location":"devguide/devguide_cubeadcs_gen2_service.html#statechange-state","title":"StateChange State","text":"<p>This state machine state is used to change the AOCS State described in Attitude and Orbit Control. The change follows a sequence of steps, but first, the combination of estimation modes and control mode is verified to be compatible with respect to Table 6: Valid estimation and control combinations, p.56 of CS-DEV.UM.CA-01 CubeADCS User Manual Ver.1.0x.pdf. If this is not the case the request will return ERROR. If the combination is valid, the rest of the StateChange State is characterized by sequential identical actions being a check action and a set action. The two actions are always executed one after the other, up to three times, after which the FDIR State is invoked. This is depicted in the following diagram, for one step:</p> <p></p> <p>The sequence of steps is:</p> <ol> <li> <p>Changing the power states (it indicates if a component is powered-on/off) of the ADCS external components (actuators and sensors). Each AOCS State can require different estimators and control mode. This means that a different set of actuators and sensors has to be activated prior to changing the used estimators and controllers. This step makes sure that the required sensors and actuators are active before moving to changing the estimation and control modes. As indicated above, this is done by two consecutive actions:</p> <ul> <li>A check action, where the currenly set power states are compared to the requested ones. If these match, the current step is considered completed and the the next step is prepared to be executed. If these don't, the set action is invoked.</li> <li>A set action where the necessary power states are set</li> </ul> </li> <li> <p>Next, the service will check if the currently active estimators match the ones from the new request.</p> </li> <li> <p>If these are also valid, the service will perform the same sequence for the control mode.</p> </li> <li> <p>The final step is applying the reference commands or open-loop commands for the controllers.</p> </li> </ol> <p>In the end, if all of these steps are successful, the ADCS will have transitioned to the new AOCS State. </p> <p>All AOCS States for Gen2 are described in the NVM. When a request for a StateChange is received, it is the description in the NVM that is read and passed to the state change logic. This offers the user the flexibility to modify which sensors/actuators should be active or to create a fully custom AOCS State. </p>"},{"location":"devguide/devguide_cubeadcs_gen2_service.html#relevant-commands_1","title":"Relevant commands","text":"<ul> <li><code>OBC_CUBEADCS_GEN2.fidl::reqStateMachineStateChange</code> is used to send a new event to the state machine (see state machine figure). Coupled with the command arguments, the user can instruct the ADCS to perform a state change. </li> </ul> <p>Tip</p> <p>When a new AOCS State is requested by the Attitude and Orbit Control, the same event is sent to the state machine, but with a different set of arguments</p> <ul> <li><code>OBC_CUBEADCS_GEN2.fidl::get_nvm_system_states_cfg</code> - used to return the AOCS State configurations for Gen2</li> <li><code>OBC_CUBEADCS_GEN2.fidl::set_nvm_system_states_cfg</code> - used to set the AOCS State configurations for Gen2</li> </ul>"},{"location":"devguide/devguide_cubeadcs_gen2_service.html#fdir-state","title":"FDIR State","text":"<p>As the name suggests, this modules performs failure detection, isolation and recovery. In reality, failure detection is performed in one of several other states, but isolation and recovery can be performed by the FDIR state only.</p> <p>The FDIR State is activated: </p> <ul> <li>When an event has been logged by the ADCS, which is an error compromising the control capabilities of the system (this is the incoming transition from EventDownload State)</li> <li>When an attempt to switch to a new AOCS State fails (this is the incoming transition from StateChange State)</li> </ul> <p>Note</p> <p>Information on the exact events that are considered by the FDIR is located in <code>&lt;OBC SDK&gt;/espf/core/services/aocs/cubeadcs_gen2/inc/cubeadcs_gen2_events_types.h</code> and Code Reference.</p> <p>The last incoming transition is from:</p> <ul> <li>Check State, but is currently not implemented.</li> </ul> <p>The information about the failure is passed to the FDIR State upon entry. The state itself is organised as a small framework, allowing the user to implement custom handlers per failure or common to all failures. By default, all failures have one of only two handlers attached:</p> <ul> <li>A critical error handler - called when the detected failure compromises the control capabilities of the system</li> <li>A non-critical error handler - called when the detected failure does not compromise the control capabiltiies of the system</li> </ul> <p>At current, the handlers are just proto-handlers, as they don't perform any real handling, but just report failure to perform recovery. Therefore, ANY failure reported by the ADCS will be reported by the service as an error compromising the control capabilities. The service reports this as a 32-bit value, which is used by the higher level service Attitude and Orbit Control to notify the ConOps logic of a serious ADCS problem.</p> <p>Note</p> <p>Details on how to configure and extend the FDIR State can be located in the Code Reference section.</p>"},{"location":"devguide/devguide_cubeadcs_gen2_service.html#relevant-commands_2","title":"Relevant commands","text":"<p>There are four commands related to the FDIR State:</p> <ul> <li><code>OBC_CUBEADCS_GEN2.fidl::get_fdir_unrecovarable_errors</code> can be used to read out the 32 bit value, reported by the service</li> <li><code>OBC_CUBEADCS_GEN2.fidl::clear_fdir_unrecovarable_errors</code> can be used to clear this value</li> <li><code>OBC_CUBEADCS_GEN2.fidl::get_fdir_stats</code> can be used to read out information regarding the execution of an error handler linked to a specific error</li> <li><code>OBC_CUBEADCS_GEN2.fidl::clear_fdir_stats</code> can be used to clear this information</li> </ul>"},{"location":"devguide/devguide_datacache.html","title":"Data Cache","text":"<p>The Data Cache (or DC in short) provided as part of the OBC SDK is a simple RAM data store which enables data producers and consumers in the system to exchange typed data without introducing tight coupling between them. The data exchange is implemented in a thread-safe way and can be used by all parts of the system, e.g. drivers, services, application components, etc. The main benefits of using DC compared to direct coupling between components are the following:</p> <ul> <li>The possibility to easily change the data producer's code without this affecting data consumer's code. The change remains transparent for data readers in the system as long as the data type doesn't change.</li> <li>No need for explicit synchronization mechanisms between the data producers and consumers - the data store is always available for use (even before data production has started - you simply read data which is marked as <code>not initialized</code> yet).</li> <li>Data which is part of DC is described via FIDL files and the corresponding code is fully auto-generated (it is part of the CMake build process and just editing the FIDL file, produces the necessary code automatically the next time you build the SDK).</li> <li>The code generation also produces a special get/set FIDL interface which can be used to enable data simulation externally either from SDE or from a Python script - this makes testing your code in the system a breeze.</li> <li>DC data is assigned an additional status field which can be used by data consumers to decide whether the data is fresh (e.g. regularly being updated by any producer) and whether it has been updated at all since system start.</li> </ul> <p>When you should not use DC?</p> <p>DC is designed around a simple polling mechanism - data producers and consumers are not synchronized and any side can call DC at any time. That means consumers may miss some changes in the data depending on how often they are sampling the DC for changes.</p> <p>For that reason, you may want to implement custom mechanisms for data exchange if:</p> <ul> <li>You cannot afford to miss even a single sample of the data produced.</li> <li>You need to be directly notified when the data changes.</li> <li>You need to exchange bigger amounts of data and you want to avoid data copy operations.</li> </ul> <p> An example of a typical usage scenario - one producer with multiple consumers</p>"},{"location":"devguide/devguide_datacache.html#which-files-to-edit-if-i-want-to-modify-the-dc","title":"Which files to edit if I want to modify the DC?","text":"<p>As already mentioned, the process of changing the DC items and their format is automated as part of the CMake build of the OBC SDK. The DC is fully generated out of a FIDL description. We will use a short example to illustrate how to add a new data item and start using it from other components in the system. But, before that, let's have a look at the structure of the FIDL files used for DC macchiato generation:</p> <p></p> <p>Info</p> <p>Data items in DC are named <code>attributes</code> after the Franca IDL syntactic elements used to describe them in the FIDL files.</p> <p>As visible on the diagram, there are two files which describe the DC content:</p> <ul> <li><code>DataCache.fidl</code> - defines the list of DC attributes (or data entries), their unique attribute ID and corresponding data type. <code>Attributes</code> can have any valid Franca IDL type.</li> <li><code>DataCache_Types.fidl</code> - defines all Franca data types which are used for <code>attribute</code> definition. This file is directly imported by <code>DataCache.fidl</code>.</li> <li><code>deploy_dc.fdepl</code> - this is the specification for the actual code generation (it enables altering of specific generation parameters for the whole DC interface or only for specific attributes).</li> </ul>"},{"location":"devguide/devguide_datacache.html#describing-dc-attributes","title":"Describing DC attributes","text":"<p>The DC-specific FIDL files are actually regular FIDL files describing interfaces. What makes them special is how macchiato DC generator handles them and also the fact that they use Franca <code>attributes</code> as part of a Franca interface to describe data. This kind of description is not supported by other macchiato generators for the moment and such FIDL files can only be used with the <code>-gen-dc</code> macchiato option.</p> <p>Let's now describe a single data type which we will assign to a DC attribute.</p> <ul> <li>Open <code>DataCacheTypes.fidl</code> and paste the following code somewhere in the <code>typeCollection DataCacheTypes</code> block (e.g. in the end): <pre><code>    struct foo_general_data\n    {\n        UInt8 foo_index\n        UInt32 foo_speed\n    }\n</code></pre></li> <li>Now open <code>DataCache.fidl</code> and create a new attribute at the end of the <code>interface data_cache</code> section using the <code>foo_general_data</code> type we already defined: <pre><code>    &lt;** @description: Onboard Computer General Telemetry Package\n        @details: id = &lt;unique id&gt;\n    **&gt;\n    attribute foo_general_data foo_info\n</code></pre></li> </ul> <p>Note</p> <p>Make sure that you replace the <code>&lt;unique id&gt;</code> value on line <code>2</code> before trying to generate from the modified FIDL files. It doesn't matter what value that is as long as it is unique in the same file.</p> <p>That's it! You just created a new data <code>foo_info</code> containing the items described in the <code>foo_general_data</code> type. Now comes generation time!</p>"},{"location":"devguide/devguide_datacache.html#generating-code","title":"Generating code","text":"<p>One way to generate DC code is to call macchiato manually:</p> <ol> <li>Open a system console</li> <li>Change the working directory to <code>&lt;OBC SDK&gt;/espf/config/datacache</code></li> <li>Run <code>java -jar ../../../other/scripts/gen/macchiato/macchiato.jar --gen-dc deploy_dc.fdepl ./</code></li> </ol> <p>Your generated code will appear in the <code>src-gen-dc</code> subfolder and you have to replce the datacache code in the build with the new one manually.</p> <p>There is an easier way though, if you base your changes on the existing OBC SDK:</p> <ol> <li>Edit the FIDL descriptions for the DC</li> <li>Trigger a new OBC SDK build for your DC changes to be automatically generated and the corresponding code to be built.</li> </ol> <p>You should see a similar output as part of your build log: <pre><code>[1/39] Generating C:/Projects/SWP/GitRepo/obc-stdpf-hw-1.x/espf/config/datacache/datacache.c, C:/Projects/SWP/GitRepo/obc-stdpf-hw-1.x/espf/config/datacache/datacache.h, C:/Projects/SWP/GitRepo/obc-stdpf-hw-1.x/espf/config/datacache/datacache_io.fidl\nEnduroSat -macaron- build front-end [v0.2]\nmacaron.py started with args: Namespace(build=None, release_ver=None, clean=False, clean_gen_content=WindowsPath('.'), fp_gen=False, datacache_gen=True, fp_gen_all=False, depl_config='C:/Projects/SWP/GitRepo/obc-stdpf-hw-1.x/espf/config/datacache/deploy_dc.fdepl', fp_merge_root=WindowsPath('.'), verbose=False, error_out_only=False, reset_log=False)\nESPF_ROOT_BUILD_PATH environment variable not set. Using default path setting resolving to \"C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\".\nWARN: ignoring -datacache option in combination with -fp option!\ngenerating sources...\n    ... EnduroSat ...\n                                  __    _       __\n       ____ ___  ____ ___________/ /_  (_)___ _/ /_____\n      / __ `__ \\/ __ `/ ___/ ___/ __ \\/ / __ `/ __/ __ \\\n     / / / / / / /_/ / /__/ /__/ / / / / /_/ / /_/ /_/ /\n    /_/ /_/ /_/\\__,_/\\___/\\___/_/ /_/_/\\__,_/\\__/\\____/ v1.0.18\n    please wait...\n      --gen-dc: FIDL C DataCache source code generator [v0.7]\n    &gt;&gt;&gt; loading C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\espf\\config\\datacache\\deploy_dc.fdepl\n    0    [main] INFO  generators.macchiato.binders.Gen_DC  - ==&gt; Found 0 issues in file:/C:/Projects/SWP/GitRepo/obc-stdpf-hw-1.x/espf/config/datacache/deploy_dc.fdepl\n    3    [main] INFO  generators.macchiato.binders.Gen_DC  - ==&gt; Found 1 interfaces in file:/C:/Projects/SWP/GitRepo/obc-stdpf-hw-1.x/espf/config/datacache/deploy_dc.fdepl\n    12   [main] INFO  generators.macchiato.binders.Gen_DC  - =&gt; [Generating interfaces for DataCache]\n    35   [main] INFO  generators.macchiato.binders.Gen_DC  - Calling DataCache_Types_Header_Generator\n     for interface data_cache...\n    Created file C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\espf\\config\\datacache\\src-gen-dc\\data_cache\\v0.1\\datacache.h\n    49   [main] INFO  generators.macchiato.binders.Gen_DC  -    ==&gt; datacache.h\n    54   [main] INFO  generators.macchiato.binders.Gen_DC  - Calling DataCache_C_Generator\n     for interface data_cache...\n    Created file C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\espf\\config\\datacache\\src-gen-dc\\data_cache\\v0.1\\datacache.c\n    64   [main] INFO  generators.macchiato.binders.Gen_DC  -    ==&gt; datacache.c\n    64   [main] INFO  generators.macchiato.binders.Gen_DC  - Calling DataCache_Cfg_Header_Generator\n     for interface data_cache...\n    Created file C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\espf\\config\\datacache\\src-gen-dc\\data_cache\\v0.1\\datacache_cfg.h.template\n    71   [main] INFO  generators.macchiato.binders.Gen_DC  -    ==&gt; datacache_cfg.h.template\n    72   [main] INFO  generators.macchiato.binders.Gen_DC  - Calling DataCache_IO_FIDL_Generator\n     for interface data_cache...\n    Created file C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\espf\\config\\datacache\\src-gen-dc\\data_cache\\v0.1\\datacache_io.fidl\n    80   [main] INFO  generators.macchiato.binders.Gen_DC  -    ==&gt; datacache_io.fidl\n    102  [main] INFO  generators.macchiato.binders.Gen_DC  - Calling DataCache_Python_Types_Generator\n     for interface data_cache...\n    Created file C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\espf\\config\\datacache\\src-gen-dc\\data_cache\\v0.1\\datacache.py\n    117  [main] INFO  generators.macchiato.binders.Gen_DC  -    ==&gt; datacache.py\n    118  [main] INFO  generators.macchiato.binders.Gen_DC  - =&gt; [done]\n    118  [main] INFO  generators.macchiato.binders.Gen_DC  - All done, just remember me when you are flying in space!\n    ==========================================================================================\n                                     Summary\n    ==========================================================================================\n                  Interface |   ver |         ID | Deployed as |   Duplicated?\n    ==========================================================================================\n                   data_cache     0.1    UNDEFINED server          no\n&gt;  command finished successfully!\ncleaning up all directories with name \"src-gen-c\" under \"C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\build\\libespf_sub\\datacache\"...\n[2/39] Generating C:/Projects/SWP/GitRepo/obc-stdpf-hw-1.x/espf/config/datacache/fp/data_cache/v0.1/data_cache_server/FP_data_cacheProtocolServer.c, C:/Projects/SWP/GitRepo/obc-stdpf-hw-1.x/espf/config/datacache/fp/data_cache/v0.1/data_cache_server/FP_data_cacheProtocolServer.h, C:/Projects/SWP/GitRepo/obc-stdpf-hw-1.x/espf/config/datacache/fp/data_cache/v0.1/data_cache_server/FP_data_cacheProtocolTypes.h, C:/Projects/SWP/GitRepo/obc-stdpf-hw-1.x/espf/config/datacache/fp/data_cache/v0.1/data_cache_server/FP_data_cacheServerApp.c, C:/Projects/SWP/GitRepo/obc-stdpf-hw-1.x/espf/config/datacache/fp/data_cache/v0.1/data_cache_server/FP_data_cacheServerApp.h\nEnduroSat -macaron- build front-end [v0.2]\nmacaron.py started with args: Namespace(build=None, release_ver=None, clean=False, clean_gen_content=WindowsPath('.'), fp_gen=True, datacache_gen=False, fp_gen_all=False, depl_config='C:/Projects/SWP/GitRepo/obc-stdpf-hw-1.x/espf/config/datacache/deploy_dc_io.fdepl', fp_merge_root=WindowsPath('C:/Projects/SWP/GitRepo/obc-stdpf-hw-1.x/espf/config/datacache/fp'), verbose=False, error_out_only=False, reset_log=False)\nESPF_ROOT_BUILD_PATH environment variable not set. Using default path setting resolving to \"C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\".\n    ... EnduroSat ...\n                                  __    _       __\n       ____ ___  ____ ___________/ /_  (_)___ _/ /_____\n      / __ `__ \\/ __ `/ ___/ ___/ __ \\/ / __ `/ __/ __ \\\n     / / / / / / /_/ / /__/ /__/ / / / / /_/ / /_/ /_/ /\n    /_/ /_/ /_/\\__,_/\\___/\\___/_/ /_/_/\\__,_/\\__/\\____/ v1.0.18\n    please wait...\n      --gen-c: ESPSI C source code generator (client/server bindings) [v2.11]\n    &gt;&gt;&gt; loading C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\espf\\config\\datacache\\deploy_dc_io.fdepl\n    0    [main] INFO  .generators.macchiato.binders.Gen_C  - ==&gt; Found 0 issues in file:/C:/Projects/SWP/GitRepo/obc-stdpf-hw-1.x/espf/config/datacache/deploy_dc_io.fdepl\n    0    [main] INFO  .generators.macchiato.binders.Gen_C  - ==&gt; Found 1 interfaces in file:/C:/Projects/SWP/GitRepo/obc-stdpf-hw-1.x/espf/config/datacache/deploy_dc_io.fdepl\n    12   [main] INFO  .generators.macchiato.binders.Gen_C  - =&gt; [Generating interfaces for C]\n    29   [main] INFO  .generators.macchiato.binders.Gen_C  - Calling Protocol_Types_Header_Generator\n     for interface data_cache...\n    Created file C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\espf\\config\\datacache\\src-gen-c\\data_cache\\v0.1\\data_cache_server\\FP_data_cacheProtocolTypes.h\n    47   [main] INFO  .generators.macchiato.binders.Gen_C  -    ==&gt; FP_data_cacheProtocolTypes.h\n    49   [main] INFO  .generators.macchiato.binders.Gen_C  - Calling Protocol_Server_Header_Generator\n     for interface data_cache...\n    Created file C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\espf\\config\\datacache\\src-gen-c\\data_cache\\v0.1\\data_cache_server\\FP_data_cacheProtocolServer.h\n    59   [main] INFO  .generators.macchiato.binders.Gen_C  -    ==&gt; FP_data_cacheProtocolServer.h\n    81   [main] INFO  .generators.macchiato.binders.Gen_C  - Calling Protocol_Server_Implementation_Generator\n     for interface data_cache...\n    Created file C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\espf\\config\\datacache\\src-gen-c\\data_cache\\v0.1\\data_cache_server\\FP_data_cacheProtocolServer.c\n    100  [main] INFO  .generators.macchiato.binders.Gen_C  -    ==&gt; FP_data_cacheProtocolServer.c\n    100  [main] INFO  .generators.macchiato.binders.Gen_C  - Calling ServerApp_Header_Generator\n     for interface data_cache...\n    Created file C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\espf\\config\\datacache\\src-gen-c\\data_cache\\v0.1\\data_cache_server\\FP_data_cacheServerApp.h\n    108  [main] INFO  .generators.macchiato.binders.Gen_C  -    ==&gt; FP_data_cacheServerApp.h\n    115  [main] INFO  .generators.macchiato.binders.Gen_C  - Calling Protocol_Types_Header_Generator\n     for interface data_cache...\n    Created file C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\espf\\config\\datacache\\src-gen-c\\data_cache\\v0.1\\data_cache_server\\FP_data_cacheProtocolTypes.h\n    124  [main] INFO  .generators.macchiato.binders.Gen_C  -    ==&gt; FP_data_cacheProtocolTypes.h\n    126  [main] INFO  .generators.macchiato.binders.Gen_C  - Calling Protocol_BaseTypes_Header_Generator\n     for interface data_cache...\n    Created file C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\espf\\config\\datacache\\src-gen-c\\data_cache\\v0.1\\FP_common\\FP_BaseProtocolTypes.h\n    134  [main] INFO  .generators.macchiato.binders.Gen_C  -    ==&gt; FP_BaseProtocolTypes.h\n    134  [main] INFO  .generators.macchiato.binders.Gen_C  - Calling Protocol_Server_Common_Implementation_Generator\n     for interface data_cache...\n    Created file C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\espf\\config\\datacache\\src-gen-c\\data_cache\\v0.1\\FP_common\\FP_ProtocolServerCommon.c\n    144  [main] INFO  .generators.macchiato.binders.Gen_C  -    ==&gt; FP_ProtocolServerCommon.c\n    144  [main] INFO  .generators.macchiato.binders.Gen_C  - Calling Protocol_Server_Common_Header_Generator\n     for interface data_cache...\n    Created file C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\espf\\config\\datacache\\src-gen-c\\data_cache\\v0.1\\FP_common\\FP_ProtocolServerCommon.h\n    152  [main] INFO  .generators.macchiato.binders.Gen_C  -    ==&gt; FP_ProtocolServerCommon.h\n    152  [main] INFO  .generators.macchiato.binders.Gen_C  - Calling Protocol_Helpers_Header_Generator\n     for interface data_cache...\n    Created file C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\espf\\config\\datacache\\src-gen-c\\data_cache\\v0.1\\FP_common\\FP_Helpers.h\n    158  [main] INFO  .generators.macchiato.binders.Gen_C  -    ==&gt; FP_Helpers.h\n    158  [main] INFO  .generators.macchiato.binders.Gen_C  - Calling Protocol_Helpers_C_Generator\n     for interface data_cache...\n    Created file C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\espf\\config\\datacache\\src-gen-c\\data_cache\\v0.1\\FP_common\\FP_Helpers.c\n    165  [main] INFO  .generators.macchiato.binders.Gen_C  -    ==&gt; FP_Helpers.c\n    171  [main] INFO  .generators.macchiato.binders.Gen_C  - Calling ServerApp_Implementation_Generator\n     for interface data_cache...\n    Created file C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\espf\\config\\datacache\\src-gen-c\\data_cache\\v0.1\\data_cache_server\\FP_data_cacheServerApp.c\n    178  [main] INFO  .generators.macchiato.binders.Gen_C  -    ==&gt; FP_data_cacheServerApp.c\n    179  [main] INFO  .generators.macchiato.binders.Gen_C  - =&gt; [done]\n    179  [main] INFO  .generators.macchiato.binders.Gen_C  - I am done. Give me more like this one!\n    ==========================================================================================\n                                     Summary\n    ==========================================================================================\n                  Interface |   ver |         ID | Deployed as |   Duplicated?\n    ==========================================================================================\n                   data_cache     0.1   0x00000088 server          no\n    Sorry but I could not find the user file: C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\espf\\config\\datacache\\fp\\.\\data_cache\\v0.1\\FP_common\\FP_BaseProtocolTypes.h\n    Sorry but I could not find the user file: C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\espf\\config\\datacache\\fp\\.\\data_cache\\v0.1\\FP_common\\FP_ProtocolServerCommon.c\n    Sorry but I could not find the user file: C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\espf\\config\\datacache\\fp\\.\\data_cache\\v0.1\\FP_common\\FP_ProtocolServerCommon.h\n    Sorry but I could not find the user file: C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\espf\\config\\datacache\\fp\\.\\data_cache\\v0.1\\FP_common\\FP_Helpers.h\n    Sorry but I could not find the user file: C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\espf\\config\\datacache\\fp\\.\\data_cache\\v0.1\\FP_common\\FP_Helpers.c\n    Created file C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\espf\\config\\datacache\\fp\\.\\data_cache\\v0.1\\data_cache_server\\FP_data_cacheServerApp.c\n    ===============================================================\n    |                           Summary                           |\n    ===============================================================\n    |               File Name              | Replaced | User Tags |\n    ===============================================================\n    | FP_data_cacheProtocolTypes.h        |       Yes |      None |\n    | FP_data_cacheProtocolServer.h       |       Yes |      None |\n    | FP_data_cacheProtocolServer.c       |       Yes |      None |\n    | FP_data_cacheServerApp.h            |       Yes |      None |\n    | FP_data_cacheProtocolTypes.h        |       Yes |      None |\n    | FP_BaseProtocolTypes.h              | Not found |      None |\n    | FP_ProtocolServerCommon.c           | Not found |      None |\n    | FP_ProtocolServerCommon.h           | Not found |      None |\n    | FP_Helpers.h                        | Not found |      None |\n    | FP_Helpers.c                        | Not found |      None |\n    | FP_data_cacheServerApp.c            |       Yes |        38 |\n&gt;  command finished successfully!\ncleaning up all directories with name \"src-gen-c\" under \"C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x\\build\\libespf_sub\\datacache\"...\n</code></pre></p> <p>Note</p> <p>You probably noticed that the macchiato generator is called twice - the first generation stage produces the actual DC code while the second produces the DC get/set code based on the generated <code>datacache_io.fidl</code> file. This FIDL gives you a direct SDE or Python-based interface for reading and updating DC items externally, e.g. in testing or simulation scenarios.</p> <p>Note</p> <p>The DC code build step is omitted from the trace provided here but if you inspect more closely the <code>&lt;OBC SDK/build/macaron.log</code> file produced during the build, you will notice that the generated C source files are also built after the generation step is complete.</p>"},{"location":"devguide/devguide_datacache.html#using-your-new-dc-data","title":"Using your new DC data","text":"<p>Now that we defined the <code>foo_info</code> attribute, we need to start using this entry. If you check the additions to your <code>&lt;OBC SDK&gt;/espf/config/datacache/datacache.h</code> file after generation, you will notice the following new items:</p> <p><pre><code>// ...\n#define DC_ATTR_ID_FOO_INFO 0x00000022\n\ntypedef struct {\n    uint8_t u8Foo_index;\n    uint32_t u32Foo_speed;\n} PACKED_STRUCT DATA_CACHE_foo_general_data_t;\n\n// ...\n\ndc_data_status_t dc_get_foo_info(DATA_CACHE_foo_general_data_t * const p_data);\nvoid dc_set_foo_info(DATA_CACHE_foo_general_data_t * const p_new_data);\n</code></pre> You have your new <code>foo_general_data</code> data type and two public API functions for accessing the data. You also have the <code>DC_ATTR_ID_FOO_INFO</code> define which can be used with the static DC APIs (see below).</p> <p>Let's now modify the entry in DC by using the following code in your data producer component: <pre><code>#include \"datacache.h\"\n\n// define your data values\nDATA_CACHE_foo_general_data_t temp_foo_data =\n{\n    .u8Foo_index = 5U,\n    .u32Foo_speed = 2500U\n}\n\n// set the value in DC\ndc_set_foo_info(&amp;temp_foo_data);\n</code></pre></p> <p>There is another way to access data in DC which can be more useful in loops when you have to process multiple blocks using a single configuration. Here is an example:</p> <pre><code>#include \"datacache.h\"\n\n// obtain the internal DID handle by using the generated attribute ID\ndc_did_id my_did_id = dc_get_index_by_data_id(DC_ATTR_ID_FOO_INFO);\n\n// allocate storage for the data to be read\nDATA_CACHE_foo_general_data_t temp_foo_data;\n\n// use the internal handle with the raw DC APIs to update the data\nmy_did_id = dc_set_raw_data(my_did_id, &amp;temp_foo_data, sizeof(temp_foo_data));\n</code></pre> <p>Finally, we can read our new DC attribute from any data consumer component via the following code: <pre><code>#include \"datacache.h\"\n\n// define your data values\nDATA_CACHE_foo_general_data_t temp_foo_data;\n\ndc_data_status_t foo_info_status = dc_get_foo_info(&amp;temp_foo_data);\n\n// check foo_info_status\nif (DC_DATA_STATUS_OK == foo_info_status)\n{\n    // use the data if status is ok\n}\n</code></pre></p>"},{"location":"devguide/devguide_datacache.html#knowing-if-your-dc-data-is-published-regularly","title":"Knowing if your DC data is published regularly","text":"<p>When inspecting the generated <code>datacache.h</code> public interface, you probably already noticed that DC attributes are assigned an additional status value automatically. The status is returned by the <code>dc_get_&lt;data name&gt;()</code> API and can be used by consumers to evaluate how fit the data is. In a decoupled data exchange mechanism like DC, it may happen that data is read by a component when the component responsible to produce it was never started or it has crashed. If such data is part of an algorithm taking important decisions about the system, it may turn up that your algorithm works with uninitialized data. Here comes the role of the DC as an intermediary. Since it hosts all the data itself, it is also in the position to track the data life time and also to know when data gets modified and at what intervals. If certain data is expected to be updated at least every 5 seconds, the DC can detect if the data is not modified on time and it will flag this through the status field letting data consumers know that something may be wrong with this data.</p>"},{"location":"devguide/devguide_datacache.html#specifying-the-data-timeout-interval","title":"Specifying the data timeout interval","text":"<p>By default, macchiato code generator will assume that data which is updated at least 5 seconds is ok to use and will not set the <code>DC_DATA_STATUS_TOUT</code> value for the data status. Although, there is a way to customize this value for every DC attribute. You can do this by modifying the <code>deploy_dc.fdepl</code> file passed to the macchiato generator. To demonstrate this, let's change the timeout configuration for our new <code>foo_info</code> attribute to <code>1200</code> ms:</p> <ul> <li>open <code>&lt;OBC SDK&gt;/espf/config/datacache/deploy_dc.fdepl</code></li> <li>add this code at the end of the file: <pre><code>define org.endurosat.spec.PlatformSpec for interface endurosat.pf.DataCache.data_cache\n{\n    attribute foo_info { Status_timeout = 1200  }\n}\n</code></pre></li> </ul>"},{"location":"devguide/devguide_debugtrace.html","title":"Debug and trace","text":"<p>In the course of using or modifying the OBC SDK, you will definitely need some ways to investigate what happens to the system in order to pinpoint bugs and fix them. While you have the debugger as the main tool for such activity, sometimes program behavior changes if breakpoints are used or HW tracing is performed, and bugs can only be reproduced when the program flow doesn't get interrupted every now and then.</p> <p>For that purpose, there are some very basic ways of tracing information in the OBC SDK which should be explained here to give you a headstart.</p>"},{"location":"devguide/devguide_debugtrace.html#trace-instrumentation-for-your-modules","title":"Trace instrumentation for your modules","text":"<p>If you want to introduce configurable serial tracing for your modules, you can perform the following steps:</p> <ul> <li>include <code>espf/core/lib/trace/inc/trace.h</code> in your implementation;</li> <li>use the <code>ES_TRACE_&lt;LEVEL&gt;(formatString, ...)</code> macros in order to trace information to various outputs.</li> </ul> <p>Info</p> <ul> <li><code>ES_TRACE_&lt;LEVEL&gt;(...)</code> calls will not have any effect unless the <code>ES_TRACE_ENABLED</code> CMake option is set to ON;</li> <li> <p>These debug macros can output formatted data similar to <code>printf(...)</code>, e.g.     <pre><code>ES_TRACE_DEBUG(\"system started successfully!\");\n</code></pre>     produces     <pre><code>system started successfully!\n</code></pre></p> <p>And another example... <pre><code>uint8_t errCode = 5;\nES_TRACE_ERROR(\"system error: [%d]\", errCode);\n</code></pre> produces <pre><code>system error: [5]\n</code></pre></p> </li> </ul> <p>Tip</p> <p>In case you want to introduce tracing in your implementation, it may be preferrable to make a wrapper macro over <code>ES_TRACE_&lt;LEVEL&gt;()</code> since the output channel may be only one and you probably don't want to flood it with traces from all components in your system but rather be able to turn on/off certain tracers.</p> <p>In your public header file, you can define: <pre><code>#include \"espf/core/lib/trace/inc/trace.h\"\n\n#if defined(ENABLE_MODULE_FOO_DEBUG_TRACE)\n    #define MODULE_FOO_DBG_PRINT(formatStr, ...)   ES_TRACE_DEBUG(formatStr OPT_VA_ARGS(__VA_ARGS__));\n#else\n    #define MODULE_FOO_DBG_PRINT(fmtString, ...)   asm(\"nop\");\n#endif\n</code></pre></p> <p>In your module sources, use only the <code>MODULE_FOO_DBG_PRINT()</code> macro. This way you have the option to disable the traces for this module separately and thus limit the output only to the traces that you are currently interested in.</p>"},{"location":"devguide/devguide_debugtrace.html#severity-levels-of-traces","title":"Severity levels of traces","text":"<p>There are five severity levels defined for trace entries:</p> <ul> <li>ERROR - any fault which prevents the proper execution of a functionality, but doesn't necessarily affect the system as a whole. Usually not recoverable without user intervention.</li> <li>WARNING - any anomaly that may affect the proper execution of a functionality, but is recoverable.</li> <li>INFO - any piece of information that is useful to be available all the time.</li> <li>FATAL - any error which prevents the whole system from operating correclty (or at all). Recoverable only through reset.</li> <li>DEBUG - any details that provide insight into the operation of the system but are not expected to be available all the time. Used mainly during development and defect analysis.</li> </ul>"},{"location":"devguide/devguide_debugtrace.html#trace-output","title":"Trace output","text":"<p>Currently there are three types of channels you can use as sinks for the trace output - debugger, UART and file. The default trace configuration has one of each type configured. You can add more trace outputs by modifying the implementation in file <code>espf/config/trace_config/src/trace_config.c</code>.</p>"},{"location":"devguide/devguide_debugtrace.html#debugger","title":"Debugger","text":"<p>Trace data is output directly to the ARM trace cell output which can be captured in the STM32CubeIDE in the following way:</p> <ol> <li>Instrument your code with <code>ES_TRACE_&lt;LEVEL&gt;</code> macro calls.</li> <li>Make sure that the STM32_SWV_SUPPORT CMake option is set to ON and DEBUG_ENABLED is defined (available by default in debug builds).</li> <li>Build your code.</li> <li>Open the debug configuration dialog -&gt; <code>Debugger</code> tab and make sure to select the <code>Enable</code> checkbox in the <code>Serial Wire Viewer (SWV)</code> group.</li> <li>Set <code>Core Clock (MHz):</code> edit box value to <code>108.0</code><sup>1</sup> and click the <code>Apply</code> button.</li> <li>Start a debugging session with your code by clicking on the <code>Debug</code> button.</li> <li>When you first hit the default <code>main</code> function breakpoint, open the <code>Window</code> -&gt; <code>Show View</code> -&gt; <code>SWV</code> -&gt; <code>SWV ITM Data Console</code> view from the Eclipse main menu.</li> <li>Click on the <code>Configure trace</code>  icon and click on the <code>Enable port:</code> check box <code>0</code> inside the <code>ITM Stimulus Ports</code> group confirming the choice with the <code>OK</code> button.</li> <li>Click on the <code>Start Trace</code>  icon to arm the recording of trace data in the data console.</li> <li>Run the program image by pressing F8 key on your keyboard.</li> </ol> <p>If everything is setup correctly, you should see the instrumented traces being printed in the <code>Port 0</code> tab of the <code>SWV ITM Data Console</code>.</p> <p></p> <p>Info</p> <p>By default, all severity levels are output through the debugger. This can be changed in <code>trace_config.c</code> through the <code>.levels</code> attribute of the <code>fs_channel_list</code> element corresponding to the debugger output.</p>"},{"location":"devguide/devguide_debugtrace.html#uart","title":"UART","text":"<p>Trace data is output via an available UART. Default implementation checks three UART channels for availability - UART5 (not available when GNSS is used), UART7 (not available when EPS M is used) and UART8 (not available when CSP or SLIP are enabled). In the rare case when all three UARTs are unavaliable due to specific module usage, you have to rely on the debugger and/or file outputs.</p> <p>Tip</p> <p>All trace output going to the UART port can be captured outside of the STM32CubeIDE by using a serial emulator SW such as Putty However, we suggest the use of EnduroSat Trace Decoder for better user experience.</p> <p>Info</p> <p>By default, all severity levels are output via UART. This can be changed in <code>trace_config.c</code> through the <code>.levels</code> attribute of the <code>fs_channel_list</code> element corresponding to the UART output.</p>"},{"location":"devguide/devguide_debugtrace.html#file","title":"File","text":"<p>Trace data is output to a rolling file on the SD card. Current implementation works with 10 instances of the rolling file, but this number can be adjusted in <code>espf/config/trace_config/src/trace_config.c</code>. The active instance, i.e. the one that trace is currently working with is named <code>trace_log.doN</code> where N is a number between zero and the maximum number of instances minus 1. The inactive instances are named <code>trace_log.dxN</code> where N is again an index number.</p> <p>Info</p> <p>By default, all severity levels except DEBUG and INFO are output to file. This is done to reduce wear of the SD card storage by reducing output only to critical information. This setting can be changed in <code>trace_config.c</code> through the <code>.levels</code> attribute of the <code>fs_channel_list</code> element corresponding to the file output.</p>"},{"location":"devguide/devguide_debugtrace.html#trace-decoder","title":"Trace Decoder","text":"<p>The EnduroSat Trace Decoder is a tool for presenting the output of UART and file traces in a convenient format with limited filtering capability. What makes it better than serial emulators (for UART) or text editors (for files) are features like:</p> <ul> <li>Decoding of timestamps set on OBC side for each entry</li> <li>Filtering by file and severity level</li> <li>CRC16 check on the trace data. Entries with failed CRC check are not displayed.</li> </ul> <p>The Trace Decoder is a Python script that can be found in folder <code>other/scripts/trace_decode/</code> of the SDK delivery. You don't need to install it, just run: <pre><code>python trace_decode.py [OPTIONS]\n</code></pre> For a summary of its usage call the script with <code>--help</code> or no options at all.</p>"},{"location":"devguide/devguide_debugtrace.html#exception-tracing","title":"Exception tracing","text":"<p>For basic exception tracing out-of-the-box, there is a dedicated service implemented in the OBC SDK called <code>exeh</code>. Please refer to its doxygen documentation for details on how to use the service and what it can do for you to help with debugging your software.</p>"},{"location":"devguide/devguide_debugtrace.html#cpu-exception-fault-handling","title":"CPU exception fault handling","text":"<p>OBC is based on an ARM Cortex-M7 CPU core which provides some useful HW exception handling mechanisms. The OBC SDK ships with drivers and services working together to detect and persist the fault information so that if something happens in the field, there will be a trace in the system and end-users will be able to analyze what actually happened. This chapter gives more insight on what information gets stored by the OBC in case of HW failure and how it can be obtained and interpreted.</p> <p>Before delving deeper into the storage data format, let's briefly see which modules are involved in the CPU exception fault handling:</p> <p> <pre><code>classDiagram\n    direction TB\n    class fault_persistor { &lt;&lt;Service&gt;&gt; }\n    class nvm { &lt;&lt;Service&gt;&gt; }\n    class arm_fault_handler {\n        &lt;&lt;Driver&gt;&gt;\n        +void MemManage_Handler()\n        +void BusFault_Handler()\n        +void UsageFault_Handler()\n        +void HardFault_Handler()\n    }\n\n    fault_persistor ..&gt; arm_fault_handler : get fault data\n    fault_persistor ..&gt; nvm : store fault persistently</code></pre> </p> <p>The <code>fault_persistor</code> module is a high-level service which provides:</p> <ul> <li>sequential and random access to the last <code>5</code> captured exceptions</li> <li>management of the NVM fault storage (in FRAM)</li> <li>export of the available exception entries to a binary file for offline analysis<sup>2</sup></li> </ul> <p>The <code>arm_fault_handler</code> is a CPU-specific driver module which implements the detection and capture of dedicated CPU register data at the time of the fault. Its whole responsibility is to store the last captured exception to a dedicated no-init region in RAM. <code>arm_fault_handler</code> implements the ARM exception handlers called by the CPU in case of exception (interrupting any other activity at this time).</p>"},{"location":"devguide/devguide_debugtrace.html#information-collected-by-arm_fault_handler","title":"Information collected by <code>arm_fault_handler</code>","text":"<p>The ARMv7-M Architecture Reference Manual provides very detailed information on how the CPU handles exceptions in general and which registers can be inspected when an exception occurs. Here the registers will only be briefly listed for general reference:</p> Register name Size (bytes) Description <code>CFSR</code> 4 Configurable Fault Status Register32-bit register which contains a summary of the faults leading to the HW exceptionComprises the following registers: <code>UFSR</code> (Usage Fault Status Register)<code>BFSR</code> (BusFault Status Register)<code>MMFSR</code> (MemManage Status Register) <code>ABFSR</code> 4 Auxiliary Bus Fault Status RegisterIt gives an indication of the memory bus on which a fault occurred <code>HFSR</code> 4 HardFault Status Register <code>MMFAR</code> 4 MemManage Fault Address RegisterProvides the address of the memory location that caused an MPU fault (in case MPU is used) <code>BFAR</code> 4 BusFault Address Register <p><code>arm_fault_handler</code> also captures the active <code>SP</code> (Stack Pointer) at the time of the fault.</p>"},{"location":"devguide/devguide_debugtrace.html#exception-stack-frame-format","title":"Exception stack frame format","text":"<p>According to the ARMv7-M Architecture Reference Manual there are two exception stack frame types based on the availability of the CPU FP extension:</p> <ul> <li> <p>Basic stack frame (8 words / 32 bytes)</p> <ul> <li><code>R0</code></li> <li><code>R1</code></li> <li><code>R2</code></li> <li><code>R3</code></li> <li><code>R12</code></li> <li><code>PC</code> (Program Counter)</li> <li><code>LR</code> (Link Register) (the address to which execution returns after the CPU has handled the exception)</li> <li><code>xPSR</code></li> </ul> </li> <li> <p>Extended stack frame (26 words / 104 bytes)</p> <ul> <li>Includes a basic stack frame (see above)\u2026</li> <li><code>S0</code> .. <code>S15</code> (FP extension registers - 16 32-bit registers)</li> <li><code>FPSCR</code> (Floating Point Status and Control Register)</li> </ul> </li> </ul> <p>There are two stack types supported by the CPU - main stack <code>MSP</code> and process stack <code>PSP</code> (determined by bit <code>2</code> of the <code>LR</code> at the time of the exception). If the bit is set, <code>PSP</code> was active prior to the exception entry, else - the <code>MSP</code> was active.</p>"},{"location":"devguide/devguide_debugtrace.html#persistent-fault-storage","title":"Persistent fault storage","text":"<p>When a HW exception occurs, any complicated processing such as writing to files or external memory should be avoided because those operations may be unreliable in an exception context. While some exceptions may be recoverable, it is most recommended that the CPU is reset if any exception occurs to avoid potential side effects caused by incorrect attempts to recover from the exception. Therefore the exception stack frame is temporarily stored in a RAM memory region which is not initialized during reset so that it can be processed as soon as the application restarts and detects the HW exception. The RAM region which holds information on the last active exception is protected via a 32-bit CRC to ensure that correct data will be persisted eventually.</p>"},{"location":"devguide/devguide_debugtrace.html#storage-format","title":"Storage format","text":"<p>Apart from the register values described in the previous sections, the persisted fault data includes also other fields which represent the frame context and come from the OBC environment (i.e. they are not handled by the HW automatically but by the accompanying stack frame capture routine). For a detailed list of all items included in the persisted exception frame, you should refer to the <code>arm_fault_handler.h::persisted_ram_x_frame_t</code> type.</p>"},{"location":"devguide/devguide_debugtrace.html#how-to-retrieve-the-fault-data-from-obc","title":"How to retrieve the fault data from OBC?","text":"<p>Persisted fault data can be retrieved from the system for offline inspection.</p> <p>There are several ways to do this<sup>3</sup>:</p> <ul> <li>collect all stored fault records in one shot via a CP command<ul> <li><code>espf/core/fidl/obc/cp/cp_fault_ops.fidl</code></li> </ul> </li> <li>get (and manage) individual fault records via FP commands<ul> <li><code>espf/core/fidl/obc/fp/fault_ops.fidl</code></li> </ul> </li> <li>download the fault dump file<sup>2</sup> from the OBC SD card</li> </ul>"},{"location":"devguide/devguide_debugtrace.html#how-to-interpret-the-captured-fault-data","title":"How to interpret the captured fault data?","text":"<p>If you just want to inspect a single fault, you can directly use the <code>fault_ops.fidl::read_fault_by_index</code> method<sup>3</sup>.</p> <p>The best way to get information for all the faults is to use the provided Python script for obtaining a high-level interpretation of the data using the fault dump file<sup>2</sup> stored on the OBC SD card.</p> <p>Download the file and run <code>espf/core/services/fault_persistor/scripts/parse_faults.py</code> as shown below:</p> <pre><code>python parse_faults.py -in fault.dmp\n</code></pre> <p>Tip</p> <p>Now we will look into the most useful information stored in such a fault record. Here is an example result from the operation above:</p> <pre><code>exception: '0' =&gt;\n    rec_type: b'A\\x00\\x00\\x00' \"A   \"\n    reserved: 0\n    RTC timestamp: 2023-10-30 12:52:13\n    uptime (ms): 1133072\n    CFSR: 0x00008200 =&gt;\n        MFSR: {'IACCVIOL': 0, 'DACCVIOL': 0, 'MUNSTKERR': 0, 'MSTKERR': 0, 'MLSPERR': 0, 'MMARVALID': 0}\n        BFSR: {'IBUSERR': 0, 'PRECISERR': 1, 'IMPRECISERR': 0, 'UNSTKERR': 0, 'STKERR': 0, 'LSPERR': 0, 'BFARVALID': 1}\n        UFSR: {'UNDEFINSTR': 0, 'INVSTATE': 0, 'INVPC': 0, 'NOCP': 0, 'UNALIGNED': 0, 'DIVBYZERO': 0}\n    HFSR: 0x00000000 =&gt; {'VECTTBL': 0, 'FORCED': 0, 'DEBUGEVT': 0}\n    MMFAR: 0x0badcafe\n    BFAR: 0x0badcafe\n    ABFSR: 0x00000000 =&gt; {'ITCM': 0, 'DTCM': 0, 'AHBP': 0, 'AXIM': 0, 'EPPB': 0, 'AXIMTYPE': 0} / AXIMTYPE status =&gt;\n'OKAY'\n    SP: 0x2403ee40\n    VTOR: 0x08000000\n    stack frame len: 32 bytes\n    STACK FRAME (\n        R0 :   0x2403eec0\n        R1 :   0x00000001\n        R2 :   0x240007b4\n        R3 :   0x0badc000\n        R12:   0x08057358\n        LR :   0x0802fa73\n        PC :   0x0802f882\n        PSR:   0x61000000 =&gt; {'ISR_NUMBER': 0, 'ICI/IT[15:10]': 0, 'GE[3:0]': 0, 'T': 1, 'IC/IT[26:25]': 0, 'Q': 0,\n'V': 0, 'C': 1, 'Z': 1, 'N': 0, 'ISR_NAME': 'Thread mode'}\n        fp_ext_reg_s[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n        FPSCR: 0x00000000 =&gt; {'IOC': 0, 'DZC': 0, 'OFC': 0, 'UFC': 0, 'IXC': 0, 'IDC': 0, 'RMode': 0, 'FZ': 0, 'DN': 0,\n'AHP': 0, 'V': 0, 'C': 0, 'Z': 0, 'N': 0}\n    )\n    frame crc: 0x45730d16 OK\n</code></pre> <p>From this excerpt, you can see that the <code>frame crc</code> at the end is <code>OK</code> which means this is a valid fault record. Now to pinpoint the location where the fault most probably occurred, check the following values:</p> <ul> <li><code>PC</code> (Program Counter) - gives you the address of the executed instruction when the fault occurred</li> <li><code>LR</code> (Link Register) - gives you the address of the instruction to which the CPU will return after servicing the fault exception</li> </ul> <p>In the OBC case, these are FLASH addresses which can be checked in the generated lst file by the linker. You can find this file in the <code>&lt;OBC build folder&gt;/&lt;build configuration name&gt;</code> (e.g. <code>build/noboot_debug</code>). By searching those addresses in the lst file you can pinpoint the fault location but you must be certain that the fault was generated by the same SW build which matches the produced lst file.</p> <p>Another way to check those addresses is to load the SW image via <code>STM32CubeIDE</code> and connect an ST-Link debugger. Run the SW and pause the execution or just put a breakpoint at the <code>main()</code> function to stop immediately after running. Open the <code>Disassembly</code> view and enter the <code>PC</code>- or <code>LR</code>-reported address in the address box shown on the image below:</p> <p></p> <p>The information captured by the fault mechanism is actually the same as given in the <code>STM32CubeIDE</code> <code>Fault Analyzer</code> view: </p> <p>So you can also use that view to read a high-level description of the individual bits for the captured registers. The names are exactly the same as reported by the Python script referred here.</p>"},{"location":"devguide/devguide_debugtrace.html#how-to-test-the-fault-persistence-mechanism","title":"How to test the fault persistence mechanism?","text":"<p>Since, it is difficult to test HW exceptions which should usually not happen in your system, an injection fault command is provded in <code>espf/core/fidl/obc/fp/fault_ops.fidl</code> called <code>simulate_fault</code>. You can use it to trigger several common HW exceptions and see how the system would react.</p>"},{"location":"devguide/devguide_debugtrace.html#can-i-use-the-fault-persistence-mechanism-to-handle-pure-sw-faults","title":"Can I use the fault persistence mechanism to handle pure SW faults?","text":"<p>Yes, indeed. This is supported via the <code>arm_fault_handler::arm_fault_handler_generic()</code> method. The generic handling can store a binary buffer of arbitrary content in place of the HW register capture data. The length of this buffer must match the regular HW frame length (you should refer to the <code>arm_fault_handler.h::persisted_ram_generic_frame_t</code> type for details). This would usually be a string describing the exception but it could also be any other relevant context data.</p> <p>Here is an example on how this can be used to capture stack overflow errors which are detected by the RTOS via a configurable <code>vApplicationStackOverflowHook</code> callback function:</p> <p><pre><code>void vApplicationStackOverflowHook(TaskHandle_t xTask, char *pcTaskName)\n{\n    const char msg[] = \"STKOVFL\";\n    char buf[configMAX_TASK_NAME_LEN + sizeof(msg)] = { '\\0' };\n    snprintf(buf, sizeof(buf), \"%s:%s\", msg, pcTaskName);\n\n    // Call the generic fault handler which will store the fault in memory for later processing by the\n    // fault_persistor module (contextual information such as RTC timestamp will be captured along with the trace).\n    //\n    // In this case, the stored fault contains an ASCII string of the following format:\n    // \"STKOVFL:&lt;name of the task which triggered the stack overflow event&gt;\"\n    arm_fault_handler_generic((uint8_t *) buf, strlen(buf));\n\n    // This is called because we want the system to process this fault as if it is a HW fault (usually resulting in OBC reset).\n    Error_Handler();\n}\n</code></pre> When generic fault frames are captured, the provided Python script will display them in the following way:</p> <p><pre><code>exception: '3' =&gt;\n    rec_type: b'AG\\x00\\x00' \"AG  \"\n    reserved: 0\n    RTC timestamp: 2000-01-01 01:06:57\n    uptime (ms): 1006\n---------------\nraw frame dump:\n---------------\n000000: 53 54 4B 4F 56 46 4C 3A 53 74 61 72 74 41 70 70 | STKOVFL:StartApp\n000010: 54 61 73 6B 00 00 00 00 00 00 00 00 00 00 00 00 | Task............\n000020: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 | ................\n000030: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 | ................\n000040: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 | ................\n000050: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 | ................\n000060: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 | ................\n000070: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 | ................\n000080: 00 00 00 00 2B F4 06 B7                         | ....+...\n</code></pre>  The script will not interpret the data stored in this frame.</p> <p>Fault behavior during an active debug session</p> <p>If a debugger is connected to the OBC MCU at the time of the exception, you will end up in a breakpoint instruction in the fault handler. This is the standard behavior so that you can inspect the fault directly via the debugger if you need to.</p> <p>If the debugger is disconnected, the system will store the fault and perform an OBC reset.</p> <ol> <li> <p>This setting depends on the MCU clock configuration. The value used here matches the current settings applied in the OBC SDK package.\u00a0\u21a9</p> </li> <li> <p>All available exceptions in the fault storage get persisted to a file once the OBC starts. The file name is hard-coded to <code>/sd/fault.dmp</code>.\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>Communication to OBC is facilitated by the <code>SpacePY</code> package.\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"devguide/devguide_dirstructure.html","title":"SDK source package content","text":"<p>The purpose of this chapter is to briefly describe the overall folder organization of the SDK package.</p> <p>Note</p> <p>You can find a more detailed documentation generated from the source code.</p> <p>At the root level you will find the following structure:</p> Folder Sub-folder Description  build CMake files, build scripts and build outputs  espf EnduroSat Standard Platform source code  app Main application code (conops and initializations)  arch Architecture dependent code (cmsis, STM32 HAL, Drivers, startup code...)  config Configuration code for the different modules and services  core Libraries, middlewares and services  lib Pre-built libraries needed for the OBC SDK (i.e. libESPS)  es_obc_sdk_docs This documentation  debug_configurations Configuration for debugging the OBC SDK on the HW  other Other scripts and tools for code generation  cubemx CubeMX .ioc configuration file for the MCU  scripts Tooling and scripts for code generation (Macchiato, FW udpates, runtime configuration...)"},{"location":"devguide/devguide_es_adcs.html","title":"EnduroSat ADCS","text":"<p>The EnduroSat ADCS (ES ADCS) is a software module for achieving attitude control of the satellite. It makes use of several modules in the OBC:</p> <ul> <li>Sensor Data Service (SDS) - all sensor data, used as input for the ES ADCS, is obtained from the DataCache (DC), where it is written by the SDS.</li> <li>Coordsys transformations library - \u0410 coordinate transformation is required before the ES ADCS can use the data - this is because sensors and actuators are often physically mounted in a frame of orientation that differs from the defined satellite frame.</li> <li>Actuator Control Service - the ES ADCS is responsible for generating the appropriate control commands and then writing them to the DC, from where this service retrieves them and applies them to the actual hardware. </li> </ul> <p>The ES ADCS is structured as a main state machine, which determines the operating mode, based on which a FreeRTOS task executes different algorithms at a fixed frequency of 1Hz. The algorithms themselves are divided in two distinct categories:</p> <ul> <li>Estimators</li> <li>Controllers </li> </ul> <p>The estimators are responsible for using the sensor data and calculating (estimating) the position and orientation (attitude) of the satellite. Due to the inherent limitation of some estimation algorithms, the ES ADCS can execute two algorithms in the same control loop for more flexibility. The controllers use the output of the estimators and calculate control values to be sent to the actuators that will guide the estimated position/orientation of the satellite to the desired one.</p> <p>Note</p> <p>Both the SDS and Actuator Control Service are usually controlled by the main operating mode state machine (SM) of the ES ADCS, but they can be controlled by the ground operator through FP commands.</p>"},{"location":"devguide/devguide_es_adcs.html#modes","title":"Modes","text":""},{"location":"devguide/devguide_es_adcs.html#idle","title":"IDLE","text":"<p>This is the default mode after power-up. In this mode, the ES ADCS FreeRTOS task does not execute any algorithms. It can accept configuration changes and execute status requests.</p> <p>The SDS is in \"low rate\" mode, which means it only samples fast enough to satisfy telemetry data sampling speed requirements and does not provide data at sampling frequencies appropriate for the ES ADCS.</p> <p>The Actuator Control Service is inactive - actuators are disabled and updates to their values are not performed.</p>"},{"location":"devguide/devguide_es_adcs.html#run","title":"RUN","text":"<p>This is the main mode of the ES ADCS. In this mode, the ES ADCS FreeRTOS task executes estimator and controller algorithms. It can accept configuration changes, but they are preferably done in IDLE mode.</p> <p>The SDS is in \"high rate\" mode, which means it samples fast enough to satisfy ES ADCS data sampling speed requirements and telemetry data sampling speed requirements. The sampling speed can be configured using FP commands by the ground operator or by writing to the correct entry in NVM (if modifying through software).</p> <p>The Actuator Control Service is active - actuators are enabled, their outputs are updated with control values from the DC.</p>"},{"location":"devguide/devguide_es_adcs.html#trigger","title":"TRIGGER","text":"<p>This is usually a simulation-only mode. It is a carbon copy of RUN mode, but it only executes once, after which the ES ADCS automatically returns to IDLE mode.</p>"},{"location":"devguide/devguide_es_adcs.html#mode-transitions","title":"Mode Transitions","text":"<p>The ES ADCS can execute transitions between operating modes based on commands.</p> <p>The ES ADCS will not transition between operating modes automatically, with the only exception being the TRIGGER to IDLE transition.</p> <p>A diagram showing the possible transitions: </p>"},{"location":"devguide/devguide_es_adcs.html#idle-to-run","title":"IDLE to RUN","text":"<p>The SDS is set to \"high rate\" mode, where sampling frequency is set to the user-configured one that should satisfy ES ADCS requirements.</p> <p>The ES ADCS skip loop variable is set to TRUE. This variable guarantees that the ES ADCS will only execute algorithms after enough high speed data has been sampled by the SDS. It is automatically reset to FALSE by the ES ADCS.</p> <p>The Actuator Control Service is started - actuators initialized and control values are read from the DC and applied to physical actuators.</p>"},{"location":"devguide/devguide_es_adcs.html#idle-to-trigger","title":"IDLE to TRIGGER","text":"<p>Fully identical to IDLE to RUN transition.</p>"},{"location":"devguide/devguide_es_adcs.html#run-to-idle","title":"RUN to IDLE","text":"<p>The SDS is set to \"low rate\" mode, where sampling frequency is lowered to a pre-configured 1 Hz and only satisfies telemetry data sampling speed requirements.</p> <p>The Actuator Control Service is stopped - actuator values are first set to 0, after which they are deinitialized and control values are no longer read from the DC.</p>"},{"location":"devguide/devguide_es_adcs.html#run-to-trigger","title":"RUN to TRIGGER","text":"<p>Both the SDS and the Actuator Control Service remain with the same configuration. The ES ADCS will exit TRIGGER mode and go to IDLE after one control loop.</p>"},{"location":"devguide/devguide_es_adcs.html#trigger-to-idle","title":"TRIGGER to IDLE","text":"<p>The SDS is set to \"low rate\" mode, where sampling frequency is lowered to a pre-configured 1Hz and only satisfies telemetry data sampling speed requirements.</p> <p>The Actuator Control Service is stopped - actuator values are first set to 0, after which they are deinitialized and control values are no longer read from the DC. In most cases, this transition will execute automatically as the ES ADCS exits trigger mode.</p>"},{"location":"devguide/devguide_es_adcs.html#trigger-to-run","title":"TRIGGER to RUN","text":"<p>This transition is not allowed in the ES ADCS.</p> <p>A more detailed information for initiating mode transitions can be found in the Code Reference section.</p>"},{"location":"devguide/devguide_es_adcs.html#reading-status-information","title":"Reading status information","text":"<p>The ES ADCS has several status variables with different levels of depth.</p> <p>The main status information contains simplified states of the estimators and the controller, as well as the active operational mode.</p> <p>The estimators have their own more detailed status - it contains any general errors/warnings that have occured and individual algorithm errors/warnings.</p> <p>Just like the estimators, the controller also has a similar status information that contains any general errors/warnings that have occured and individual algorithm errors/warnings.</p> <p>Each status information can be obtained using a designated function.</p> <p>A more detailed information for reading the status information is presented in the Code Reference section.</p>"},{"location":"devguide/devguide_es_adcs.html#auxiliary-modules","title":"Auxiliary modules","text":"<p>The additional modules that the ES ADCS relies upon have a level of configuration that can affect its performance.</p>"},{"location":"devguide/devguide_es_adcs.html#sensor-data-service","title":"Sensor Data Service","text":"<p>The SDS has configuration for each sensor type and its sampling frequency. Each sensor can also be disabled by setting the sampling frequency as 0 Hz. There is also a general flag for switching between the sampling frequency modes. These settings are stored directly in the NVM: <pre><code>NVM_BLOCK_DEFINE_START(sds_sens_read_freq_t)\n    safe_bool_t enable;\n    uint16_t    sens_cfg[SENS_FREQ_CFG_MAX];\nNVM_BLOCK_DEFINE_END(sds_sens_read_freq_t)\n</code></pre> where SENS_FREQ_CFG_MAX is set to 4.</p> <ul> <li>\"High rate\" - the <code>enable</code> flag is set to <code>TRUE</code> and the sensors are sampled at the frequency set by the user in <code>sens_cfg</code>.</li> <li>\"Low rate\" - the <code>enable</code> flag is set to <code>FALSE</code> and the sensors are sampled at the pre-defined frequency of 1 Hz, regardless of what is set inside <code>sens_cfg</code>.</li> </ul> <p>Within the OBC SDK, these settings can be changed by writing directly to the corresponding NVM entry.</p> <p>Outside the OBC SDK (using FIDL), these configurations can be changed using the appropriate function found in <code>&lt;OBC SDK&gt;/espf/core/fidl/obc/fp/sds.fidl</code>.</p>"},{"location":"devguide/devguide_es_adcs.html#coordsys-transformations-library","title":"Coordsys transformations library","text":"<p>The coordsys transformation library has a level of configuration that allows run-time change of the rotation (transformation) matrices for both the sensors and the actuators.</p> <p>The library works on the base of an enumeration that is used to represent the satellite axes: <pre><code>typedef enum\n{\n    SAT_X_AXIS_POSITIVE,    /**&lt; Satellite frame positive X axis */\n    SAT_Y_AXIS_POSITIVE,    /**&lt; Satellite frame positive Y axis */\n    SAT_Z_AXIS_POSITIVE,    /**&lt; Satellite frame positive Z axis */\n    SAT_X_AXIS_NEGATIVE,    /**&lt; Satellite frame negative X axis */\n    SAT_Y_AXIS_NEGATIVE,    /**&lt; Satellite frame negative Y axis */\n    SAT_Z_AXIS_NEGATIVE     /**&lt; Satellite frame negative Z axis */\n} es_coordsys_satellite_axes_t;\n</code></pre> Each sensor/actuator frame is defined by how it connects with this satellite axes enumeration. <pre><code>typedef struct\n{\n    es_coordsys_satellite_axes_t gyr1;    /**&lt; Which satellite axis does gyroscope 1 correspond to */\n    es_coordsys_satellite_axes_t gyr2;    /**&lt; Which satellite axis does gyroscope 2 correspond to */\n    es_coordsys_satellite_axes_t gyr3;    /**&lt; Which satellite axis does gyroscope 3 correspond to */\n} es_coordsys_gyr_frame_t;\n\ntypedef struct\n{\n    es_coordsys_satellite_axes_t mag_x;    /**&lt; Which satellite axis does magnetometer X axis correspond to */\n    es_coordsys_satellite_axes_t mag_y;    /**&lt; Which satellite axis does magnetometer Y axis correspond to */\n    es_coordsys_satellite_axes_t mag_z;    /**&lt; Which satellite axis does magnetometer Z axis correspond to */\n} es_coordsys_mag_frame_t;\n\ntypedef struct\n{\n    es_coordsys_satellite_axes_t mtq1;    /**&lt; Which satellite axis does magnetorquer 1 correspond to */\n    es_coordsys_satellite_axes_t mtq2;    /**&lt; Which satellite axis does magnetorquer 2 correspond to */\n    es_coordsys_satellite_axes_t mtq3;    /**&lt; Which satellite axis does magnetorquer 3 correspond to */\n} es_coordsys_mtq_frame_t;\n\ntypedef struct\n{\n    es_coordsys_satellite_axes_t css1;    /**&lt; Which satellite axis does coarse sun sensor 1 correspond to */\n    es_coordsys_satellite_axes_t css2;    /**&lt; Which satellite axis does coarse sun sensor 2 correspond to */\n    es_coordsys_satellite_axes_t css3;    /**&lt; Which satellite axis does coarse sun sensor 3 correspond to */\n    es_coordsys_satellite_axes_t css4;    /**&lt; Which satellite axis does coarse sun sensor 4 correspond to */\n    es_coordsys_satellite_axes_t css5;    /**&lt; Which satellite axis does coarse sun sensor 5 correspond to */\n    es_coordsys_satellite_axes_t css6;    /**&lt; Which satellite axis does coarse sun sensor 6 correspond to */\n} es_coordsys_css_frame_t;\n</code></pre> All of the above definitions can be found inside <code>&lt;OBC SDK&gt;/espf/core/services/es_coordsys/inc/es_coordsys_types.h</code>.</p> <p>Using these definitions, the rotation (transformation) equation can be written as:</p> <p></p> <p>Where the left side represents sensor or actuator data in satellite frame.</p> <p>The right side vector represents sensor/actuator data in sensor/actuator frame.</p> <p>The R matrix is called the rotation (transformation) matrix for the given type of sensor/actuator and can change depending on the physical mounting of the hardware.</p> <p>For coarse sun sensors, the equation extends to 6 dimensions since there is, usually, a coarse sun sensor for each axis direction.</p> <p>Warning</p> <p>All rotation (transformation) matrices are unit matrices and they should only have a single \"one\" per row and per column. It can have a negative sign in front, except for the coarse sun sensor matrix.</p> <p>The rotation (transformation) matrices are kept in NVM and loaded from there upon initialization.</p> <p>The rotation (transformation) matrices can be changed during run-time within the Coordsys library itself without changing the NVM configuration.</p> <p>There is an additional function for transferring the active rotation (transformation) matrices to and from NVM. This allows for recovery in case of invalid reconfiguration of the matrices during run-time.</p>"},{"location":"devguide/devguide_es_adcs.html#actuator-control-service","title":"Actuator Control Service","text":"<p>The actuator control service has its own status information that provides the service state and last encountered error: <pre><code>typedef struct\n{\n    actuator_control_service_state_t state;        /**&lt; State of the actuator control service */\n    actuator_control_service_error_t lastError;    /**&lt; Last caught error that occured in the service */\n} actuator_control_service_status_t;\n</code></pre> where the state can be: <pre><code>typedef enum\n{\n    ACTUATOR_CONTROL_SERVICE_STATE_ACTIVE,     /**&lt; All actuators are updated with values from datacache based on ACTUATOR_CONTROL_SERVICE_SAMPLING_TIME_MS */\n    ACTUATOR_CONTROL_SERVICE_STATE_INACTIVE    /**&lt; All actuators are deinitialized and not updated */\n} actuator_control_service_state_t;\n</code></pre> and the last error is one of the following: <pre><code>typedef enum\n{\n    ACTUATOR_CONTROL_SERVICE_ERROR_NONE,                   /**&lt; No errors have occured during normal execution */\n    ACTUATOR_CONTROL_SERVICE_ERROR_DATA_CACHE_GET,         /**&lt; An error occured while reading data from the data cache */\n    ACTUATOR_CONTROL_SERVICE_ERROR_COORD_SYS_TRANSFORM,    /**&lt; An error occured while data was being transformed between coordinate frames  */\n    ACTUATOR_CONTROL_SERVICE_ERROR_GENERAL                 /**&lt; Actuator control service did not fully finish executing */\n} actuator_control_service_error_t;\n</code></pre></p>"},{"location":"devguide/devguide_es_adcs.html#examples-of-usage","title":"Examples of usage","text":""},{"location":"devguide/devguide_es_adcs.html#normal-operation","title":"Normal operation","text":"<p>Under normal circumstances, all the configurations for the ES ADCS should be preloaded in their respective NVM entries.</p> <p>The recommended sequence of operation is shown in the diagram below: </p> <p>Note</p> <p>Steps 2-5 can be combined by using the read function for the full ES ADCS configuration</p> <p>Following the successful execution of step 6, it is recommended to read the general status information to confirm that the ES ADCS has not experienced any errors with estimation or control and the operational mode has switched to <code>RUN(1)</code>.</p> <p>The ES ADCS configuration can be saved to NVM when the user has decided that it provides good performance.</p> <p>In case the configuration is not satisfactory, the user can revert to the last saved NVM configuration.</p>"},{"location":"devguide/devguide_es_adcs.html#reconfiguring-the-coordinate-frames","title":"Reconfiguring the coordinate frames","text":"<p>There exists a possibility that the hardware on the satellite has been mounted differently than what was initially expected. In such cases, the rotation (transformation) matrices must be changed accordingly.</p> <p>Though it is possible to change the rotation matrices during active operation of the ES ADCS, it is not recommended. As such, the following diagram assumes that the ES ADCS is in <code>IDLE(3)</code> mode.</p> <p>Note</p> <p>The diagram provides an example for changing the magnetometer rotation matrix - other sensors/actuators follow an identical sequence with their own functions.</p> <p></p> <p>Note</p> <p>As with the ES ADCS configuration, the coordsys library also provides the capability to save the active rotation matrices to NVM or revert to the last saved NVM configuration.</p> <p>Attention</p> <p>During step 2, it is possible to define a rotation matrix with more than one sensor/actuator per axis, thus making the rotation matrix invalid. It is important to take great care when configuring new rotation matrices.</p>"},{"location":"devguide/devguide_esps_cmd_extend.html","title":"Extending the set of OBC supported commands","text":"<p>There are multiple communication interfaces supported by the OBC (such as UART, SPI, I2C, etc.) which can be used to communicate with the module but only one of them is used and supported as a standard way of data exchange between EnduroSat modules and that is the RS-485 multi-master bus interface which is backed by the ESPS I. This is also the interface that is the backbone of the ground-station control channel communication passing through the EnduroSat radio gateway in the satellite (that being UHF or S-Band TMTC depending on your selected configuration). The standard OBC SDK package already supports multiple ESPS-based commands which can be used to control the operation of the OBC and configure the module. Of course, individual users of the SDK usually have their own specific needs and thus they have to be able to implement custom commands and extended the supported set themselves. Read on to get a better understanding of the different protocols supported as part of the ESPS I and how to work with those at source-code level.</p>"},{"location":"devguide/devguide_esps_cmd_extend.html#function-protocol-fp","title":"Function Protocol (FP)","text":"<p>FP is the main protocol used between ES modules to:</p> <ul> <li>Synchronize behavior</li> <li>Execute simple control commands</li> <li>Exchange information (such as basic telemetry and statuses)</li> </ul> <p>It heavily relies on code generation tools and enables fast and flexible command implementation for embedded and desktop usage. Using formal interface definitions for the ES module communication interfaces opens a vast array of options for generating output products such as source code, testing harness code, documentation, etc. Most of the FP handling takes place in generated code produced on the basis of an IDL called Franca. The FIDL code generator shipped with the OBC SDK is called macchiato.</p> <p>Here is how a typical development flow looks like:  </p>"},{"location":"devguide/devguide_esps_cmd_extend.html#file-organization","title":"File organization","text":"<p>Depending on the role of the module in the communication, the code can be generated for a Server (commands provided by the OBC to other modules) and/or a Client (to support usage of other module's commands) implementation and the file organization changes accordingly.</p> <p>Warning</p> <p>In this guide we assume that you have read the macchiato User's Guide and you have a basic understanding how to generate source code out of FIDL files. If that's not the case, maybe you should switch to the other guide at this time to get familiar with the code generation tooling and then come back here and continue your command generation.</p> <p>Note</p> <p>Let's assume that you are generating code for an interface named <code>PingPong</code> and its version is <code>0.1</code>.</p> <p>Then the corresponding generated files for the Client implementation can be described as shown in the table on the right.</p> File name Description To be changed by user <code>FP_PingPongClientApp.c</code> client API request handlers user implementation <code>FP_PingPongClientApp.h</code> public API registration interface <code>FP_PingPongProtocolClient.c</code> client API request handlers implementation <code>FP_PingPongProtocolClient.h</code> client API request handlers public interface <code>FP_PingPongProtocolTypes.h</code> client API request handlers type definitions <p>Note</p> <p>...and the Server version of the file structure is on the right.</p> File name Description To be changed by user <code>FP_PingPongServerApp.c</code> server API request handlers user implementation <code>FP_PingPongServerApp.h</code> public API registration interface <code>FP_PingPongProtocolServer.c</code> server API request handlers implementation <code>FP_PingPongProtocolServer.h</code> server API request handlers public interface <code>FP_PingPongProtocolTypes.h</code> server API request handlers type definitions"},{"location":"devguide/devguide_esps_cmd_extend.html#integrating-the-generated-fidl-sources-to-the-build","title":"Integrating the generated FIDL sources to the build","text":"<p>The files above have to be compiled as part of your build process and also registered to the ESPS I stack so that the commands they implement can be executed by the ESPS I command scheduler. This process can be performed manually but since it involves multiple steps, there is also a more streamlined way to do this by following a simple recipe during the preparation of your own <code>CMakeLists.txt</code> file. For more details refer to the Extending the SDK with new components chapter.</p>"},{"location":"devguide/devguide_esps_cmd_extend.html#using-sde-to-call-your-commands","title":"Using SDE to call your commands","text":"<p>Once after integrating the FIDL commands in the build, you can use the SDE tool to test if they are working properly. For the sake of consistency, we will take into consideration the example <code>telemetry</code> component we already integrated in the OBC SDK in chapter Extending the SDK with new components. If we want to use our component's FIDL commands in SDE, we have to first generate the corresponding GUI bindings via macchiato. If you remember, previously we generated server bindings for C code because it is the OBC serving the commands. Now we want to call those commands from SDE which acts as a client to the OBC server, thus we need a deployment schema file which configures macchiato to generate client bindings.  Let's have an example by editing the existing <code>telemetry</code> service deployment schema file in the expected way:</p> <p>Create a file called <code>espf/services/telemetry/fp/config/tlm_client_deployment.fdepl</code> and copy the lines below inside...</p> <p><pre><code>package org.endurosat.deploy\n\nimport \"../../../../../core/fidl/spec/PlatformSpec.fdepl\"\nimport \"../../../../../core/fidl/obc/fp/Telemetry.fidl\"\n\ndefine org.endurosat.spec.PlatformSpec for interface endurosat.pf.Telemetry { IsClient = true }\n</code></pre> What changed from the previous version of this file is the <code>IsClient</code> property value which is now set to <code>true</code>. The folder where you placed the file should be the same as the original <code>deployment.fdepl</code> file because of the relative paths used in the <code>import</code> statements. If you move the file somewhere else in the build, you have to ensure the relative paths are correctly updated.</p> <p>Now let's call macchiato to generate our <code>Telemetry.fidl</code> bindings for the SDE:</p> <ol> <li>Open a system console and change your working directory to <code>&lt;OBC SDK&gt;/espf/services/telemetry/fp/config</code>.</li> <li>Type <code>java -jar ../../../../../../other/scripts/gen/macchiato/macchiato.jar --gen-js tlm_client_deployment.fdepl</code><sup>1</sup></li> </ol> <p>You should see a similar output if everything goes well: <pre><code>... EnduroSat ...\n                              __    _       __\n   ____ ___  ____ ___________/ /_  (_)___ _/ /_____\n  / __ `__ \\/ __ `/ ___/ ___/ __ \\/ / __ `/ __/ __ \\\n / / / / / / /_/ / /__/ /__/ / / / / /_/ / /_/ /_/ /\n/_/ /_/ /_/\\__,_/\\___/\\___/_/ /_/_/\\__,_/\\__/\\____/ v1.0.18\n\n\nplease wait...\n  --gen-js: ESPSI JavaScript source code (JavaScript client API) [v3.2]\n&gt;&gt;&gt; opening C:\\Projects\\OBC\\demo\\3.0.2.sdk\\espf\\core\\services\\telemetry\\fp\\config\\tlm_client_deployment.fdepl\n0    [main] INFO  generators.macchiato.binders.Gen_JS  - ==&gt; Found 0 issues in file:/C:/Projects/OBC/demo/3.0.2.sdk/espf/core/services/telemetry/fp/config/tlm_client_deployment.fdepl\n1    [main] INFO  generators.macchiato.binders.Gen_JS  - ==&gt; Found 1 interfaces in file:/C:/Projects/OBC/demo/3.0.2.sdk/espf/core/services/telemetry/fp/config/tlm_client_deployment.fdepl\n15   [main] INFO  generators.macchiato.binders.Gen_JS  - =&gt; [Generating interfaces for Java Script]\n17   [main] INFO  generators.macchiato.binders.Gen_JS  - Calling ClientApp_JavaScript_Implementation_Generator\n for interface Telemetry...\nCreated file C:\\Projects\\OBC\\demo\\3.0.2.sdk\\espf\\core\\services\\telemetry\\fp\\config\\src-gen-js\\Telemetry\\v0.1\\gen\\TelemetryClientApp.js\n377  [main] INFO  generators.macchiato.binders.Gen_JS  -        ==&gt; TelemetryClientApp.js\n378  [main] INFO  generators.macchiato.binders.Gen_JS  - Calling ClientApp_Gui_JSON_Generator\n for interface Telemetry...\nCreated file C:\\Projects\\OBC\\demo\\3.0.2.sdk\\espf\\core\\services\\telemetry\\fp\\config\\src-gen-js\\Telemetry\\v0.1\\gen\\TelemetryClientAppGui.json\n435  [main] INFO  generators.macchiato.binders.Gen_JS  -        ==&gt; TelemetryClientAppGui.json\n437  [main] INFO  generators.macchiato.binders.Gen_JS  - =&gt; [done]\n444  [main] INFO  generators.macchiato.binders.Gen_JS  - Huh, I am fed up with generating code for a living :/ I am seriously considering changing jobs. I am better than this!\n==========================================================================================\n                                 Summary\n==========================================================================================\n              Interface |   ver |         ID | Deployed as |   Duplicated?\n==========================================================================================\n                Telemetry     0.1   0x00000102 client          no\n</code></pre></p> <p>Your generated SDE bindings should now be available in the <code>src-gen-js\\Telemetry\\v0.1\\gen</code> folder.</p> <ol> <li>Open the SDE.</li> <li>Choose <code>File</code> -&gt; <code>Import new FIDL definition</code> from the menu bar.</li> <li>Browse to the folder where the new bindings were generated and select either of the two files (<code>json</code> or <code>js</code>).</li> <li>You should now see a new item <code>TelemetryClient</code> appearing in the <code>COMMANDS</code> side pane.</li> <li>Click on <code>TelemetryClient</code> and you will see the full list of commands described in the <code>Telemetry.fidl</code> file.</li> <li>Open the <code>Connection Configuration</code> by clicking on the plug  icon which appears when you hover the <code>TelemetryClient</code> item with your mouse pointer.</li> <li>In the <code>Connection Config</code> dialog, choose the <code>Mac Dongle</code> setting from the <code>Connection Type</code> combo box.</li> <li>Select the correct <code>Com Port</code> to which your ES MAC Dongle is connected.</li> <li>Make sure the <code>HFP</code> option is set to <code>y</code>.</li> <li>Make sure that the <code>MAC Protocol</code> is set to <code>12</code> (decimal).</li> <li>Now open the <code>System Config</code> dialog by clicking on the gear  icon which appears when you hover the <code>TelemetryClient</code> item with your mouse pointer.</li> <li>Change the <code>Destination module address</code> to <code>51</code> (decimal) which is the OBC module ESPS MAC address.</li> <li>Now you can try clicking on the <code>getTelemetryGeneralConfig</code> command which doesn't have any input parameters and try sending a request to the OBC via the <code>Send</code> button.</li> </ol> <p>If everything goes well, you should see the parsed response data fields in the <code>RESPONSE</code> pane on the right.</p> <p></p>"},{"location":"devguide/devguide_esps_cmd_extend.html#command-protocol-cp","title":"Command Protocol (CP)","text":"<p>This is the ESPS sub-protocol used to handle GS commands. It provides mechanisms which enable reliable communication to the GS when OBC is used together with an ES radio module and ES GS equipment.</p> <p>You need to extend the CP command support when:</p> <ul> <li>Your commands require remote execution over a radio link.</li> <li>Your command payloads are bigger than the standard MAC frame size and you don't want to use chunk-based transfers over FP.</li> <li>You need a more reliable transport over ESPS I.</li> <li>You need to be able to resume interrupted transfers from OBC to GS.</li> <li>You need to exchange files between the GS and the OBC.</li> </ul> <p>Info</p> <p>GS commands and CP commands in this manual are both used interchangeably.</p>"},{"location":"devguide/devguide_esps_cmd_extend.html#file-organization_1","title":"File organization","text":"File name Description espf/core/services/espsi/cp/CP_Handler.c Command Protocol integration wrapper implementation (provides only initialization and task function prototypes) espf/core/services/espsi/tp/ESSA_Stack_TP_Layer.h Transport Protocol helpers interface espf/core/services/espsi/fwupd/FWUPD_Handler.h public interface of the FW update implementation espf/core/services/espsi/fwupd/FWUPD_Persistor.h public interface for the FW update persistor implementation espf/core/services/espsi/cp/cp_cmd_handler.c standard GS command handlers implementation espf/core/services/espsi/cp/cp_cmd_handler.h GS commands public interface espf/config/ESPLATFORM_NETWORK_STACK/src/FWUPD_Handler_Cfg.c FW update user handlers implementation espf/config/ESPLATFORM_NETWORK_STACK/inc/FWUPD_Handler_Cfg.h FW update user handlers public interface"},{"location":"devguide/devguide_esps_cmd_extend.html#how-to-add-a-new-cp-command-to-your-project","title":"How to add a new CP command to your project?","text":"<p>Each CP command function shall be of the following type: <pre><code>typedef eCPDispatchResult_t (*pfCPCmdHandler)(sCPDispatchContext_t * const psDispCtx);\n</code></pre></p> <p>The <code>psDispCtx</code> is passed over to the handler by the <code>CP_Handler.c</code> core implementation when the command is received and processed. It contains all necessary inputs for the processing of this command as well as any resultant data which is filled in by the command handler during its execution. Eventually, the core logic handles the response sending to the Ground Station based on the <code>eCPDispatchResult_t</code> return result and the information provided by the command handler in <code>psDispCtx</code> (e.g. size of response provided in the CP output buffers).</p> <p>Now, let's see what steps to perform in order to create a custom CP command handler and register it for execution...</p> <ol> <li>implement your command handler in <code>espf/core/services/espsi/cp/cp_cmd_handler.c</code>;</li> <li>declare your command handler function in <code>espf/core/services/espsi/cp/cp_cmd_handler.h</code>;</li> <li>add your new command to the list of commands in <code>espf/config/ESPLATFORM_NETWORK_STACK/inc/ESCP_CommandsLocalConf.h</code></li> </ol> <p>Edit <code>ESCP_CommandsLocalConf.h</code> in the following way...</p> <ul> <li>create a unique ID for your new command (take notice of the existing IDs in the file to avoid duplication) <pre><code>#define CP_CMD_EMERGENCY_RESET  ((uint16_t) 1026)\n</code></pre></li> <li>locate the <code>ESTL_CP_BEGIN_COMMAND_MAP()</code> and <code>ESTL_CP_END_COMMAND_MAP()</code> lines in the file and place a command entry between them: <pre><code>ESTL_CP_BEGIN_COMMAND_MAP()\n// ...\nESTL_CP_REGISTER_COMMAND(CP_CMD_EMERGENCY_RESET, OnESCP_CommandReceived, OnESCP_CmdCancelRequest)\n// ...\nESTL_CP_END_COMMAND_MAP()\n</code></pre></li> <li>finally, register your high-level CP command handler between <code>ESTL_CP_HANDLER_BEGIN_COMMAND_MAP()</code> and <code>ESTL_CP_HANDLER_END_COMMAND_MAP()</code> lines: <pre><code>ESTL_CP_HANDLER_BEGIN_COMMAND_MAP()\n// ...\nESTL_CP_HANDLER_REGISTER_COMMAND(CP_CMD_EMERGENCY_RESET, CPCmdHandler_EmergencyReset)\n// ...\nESTL_CP_HANDLER_END_COMMAND_MAP()\n</code></pre></li> </ul> <p>Here is an example of a CP command handler implementation: <pre><code>eCPDispatchResult_t CPCmdHandler_EmergencyReset(sCPDispatchContext_t * const psDispCtx)\n{\n    eCPDispatchResult_t res = ECPDISPATCHRESULT_ERROR;\n    uint32_t u32ResetAfterMs = DELAYED_RESET_MS_DEFAULT;\n\n    if (CPCmdHandler_IsDispContextValid(psDispCtx, CP_CMD_EMERGENCY_RESET))\n    {\n        // read number of milliseconds from the user arguments\n        if (psDispCtx-&gt;u32CmdDataSize &gt;= sizeof(u32ResetAfterMs))\n            u32ResetAfterMs = *((uint32_t *) psDispCtx-&gt;pu8CmdData);\n\n        TaskMonitor_TriggerDelayedReset(u32ResetAfterMs);\n\n        // prepare response\n        (void) memcpy((void *) psDispCtx-&gt;pu8ResponseBuf, (const void *) &amp;u32ResetAfterMs, sizeof(u32ResetAfterMs));\n\n        psDispCtx-&gt;u32ResponseActualSize = sizeof(u32ResetAfterMs);\n        psDispCtx-&gt;u8TLError = EESTL_SFERR_SUCCESS;\n\n        res = ECPDISPATCHRESULT_SIMPLERESULT_OK;\n    }\n\n    return res;\n}\n</code></pre></p> <p>Important considerations</p> <ol> <li>You can access your command data payload via the <code>psDispCtx-&gt;pu8CmdData</code> pointer. In this particular example, the command contains only a single <code>uint32_t</code> value which represents the reset delay in milliseconds (see line 10). Dereferencing the buffer address to <code>uint32_t</code> is possible because the ESPS I frames use Little Endian encoding and OBC CPU is also Little Endian;</li> <li>You can specify what shall be sent as the result of your command by filling-in the buffer pointed to by <code>psDispCtx-&gt;pu8ResponseBuf</code>;</li> <li>Then set the value of <code>psDispCtx-&gt;u32ResponseActualSize</code> to the number of bytes written in the <code>psDispCtx-&gt;pu8ResponseBuf</code> buffer;</li> <li>Finally, provide an adequate <code>eCPDispatchResult_t</code> return result to your handler so that CP command scheduler will know what to respond back to the GS.</li> </ol> <p>Tip: Postponing CP command response</p> <p>It is important to know that only one CP command can be processed at a time and it shall not block indefinitely because the rest of the commands in the queue will remain blocked. If you should implement a CP command handler which needs to wait for an asynchronous event for a certain time (e.g. routing of commands to other devices which need some time to respond and then getting back to send the response to GS), it is advisable to follow a pattern. There is a standard mechanism implemented to handle such cases with the help of CMSIS API OS events which is efficient and easy to use. There are three main function primitives involved (defined in <code>Middlewares/TPLayer/ESSA_Stack_TP_Layer.c/.h</code>):</p> <pre><code>void ESSA_Stack_TP_Layer_PrepareThreadWait(void);\neThreadBlockEvt_t ESSA_Stack_TP_Layer_ThreadWaitForEvent(uint32_t u32TimeoutMs);\nvoid ESSA_Stack_TP_Layer_ReleaseThreadWait(void);\n</code></pre> <p>Here is an example command implementation which makes use of this mechanism:</p> <pre><code>// called externally and scheduled by the StartAsyncOp() call in CPCmdHandler_MyBlockingCommand() below\nvoid AsyncCallback(void)\n{\n    // release CP thread upon reception of the async event...\n    ESSA_Stack_TP_Layer_ReleaseThreadWait();\n}\n\neCPDispatchResult_t CPCmdHandler_MyBlockingCommand(sCPDispatchContext_t * const psDispCtx)\n{\n    eCPDispatchResult_t res = ECPDISPATCHRESULT_ERROR;\n    eThreadBlockEvt_t waitResult = THREADBLOCKEVT_ERROR;\n\n    if (CPCmdHandler_IsDispContextValid(psDispCtx, CP_CMD_MYBLOCKINGCMD))\n    {\n        if (psDispCtx-&gt;u32CmdDataSize &gt;= cu32MyBlockingCmdSize)\n        {\n            // setup response buffer for ESSA Stack\n            userRespCtx.pu8DataBuf = psDispCtx-&gt;pu8ResponseBuf;\n            userRespCtx.u32MaxDataSize = psDispCtx-&gt;u32ResponseBufSize;\n            userRespCtx.u32ResponseSize = 0U;\n            userRespCtx.onCmdResponseReady = NULL;\n            userRespCtx.pUserCtx = NULL;\n\n            // prepare wait before triggering the blocking call...\n            ESSA_Stack_TP_Layer_PrepareThreadWait();\n\n            // trigger async operation...\n            StartAsyncOp();\n\n            // wait for AsyncCallback() to be called or timeout after a certain time of inactivity\n            waitResult = ESSA_Stack_TP_Layer_ThreadWaitForEvent(BLOCKINGCMD_RESPONSE_TIMEOUT_MS);\n\n            if (waitResult == THREADBLOCKEVT_WAITFINISHED)\n            {\n                psDispCtx-&gt;u8TLError = EESTL_SFERR_SUCCESS;\n            }\n            else\n                if (waitResult == THREADBLOCKEVT_WAITTIMEOUT)\n                {\n                    psDispCtx-&gt;u32ResponseActualSize = 0U;\n                    psDispCtx-&gt;u8TLError = EESTL_SFERR_RECEIVE_TIMEOUT;\n                }\n                else\n                {\n                    psDispCtx-&gt;u32ResponseActualSize = 0U;\n                    psDispCtx-&gt;u8TLError = EESTL_SFERR_UNKNOWN;\n                }\n        }\n        else\n        {\n            psDispCtx-&gt;u32ResponseActualSize = 0U;\n            psDispCtx-&gt;u8TLError = EESTL_SFERR_BAD_CMD_PARAMS;\n        }\n\n        res = ECPDISPATCHRESULT_RESULT_OK;\n    }\n\n    return res;\n}\n</code></pre> <p>The <code>AsyncCallback()</code> function is expected to be called by an external component when a particular event is signalled. During that time, the CP thread is suspended by the OS until either the <code>AsyncCallback()</code> is called, or the specified timeout interval elapses.</p> <ol> <li> <p>Use <code>/</code> (forward slash) if you are running under Linux/MacOS.\u00a0\u21a9</p> </li> </ol>"},{"location":"devguide/devguide_eth.html","title":"Ethernet","text":"<p>Experimental feature</p> <p>Before taking a decision to use this feature, you shall know that:</p> <ul> <li>This feature is not yet thoroughly tested by EnduroSat.</li> <li>It is not guaranteed to operate correctly under all conditions.</li> <li>It is turned off by default in the CMake build.</li> <li>You can use it solely at your own risk.</li> <li> EnduroSat does not provide customer support for experimental features at this time.</li> </ul> <p>The OBC SDK provides out-of-the-box Ethernet connectivity serving as a baseline for more advanced user development. This chapter will provide more insight on how this is integrated in the system and how it can be used to extend the OBC capabilities enabling it to connect to other payload computers or a PC via Ethernet, TCP/IP, SLIP and other related protocols.</p>"},{"location":"devguide/devguide_eth.html#related-sw-modules","title":"Related SW modules","text":"<p>The OBC networking comprises several modules. Some of the modules are just drivers which just manage the physical connectivity, others are responsible for the implementation of standard networking protocols. Still others provide basic networking services. Here is a short list with some descriptions:</p> Folder Description  espf/arch/stm32h753iit/drivers/comm/nxp-tja11xx NXP TJA11 Automotive PHY transceiver driver  espf/arch/stm32h753iit/drivers/comm/ethernetif STM32H753 Ethernet controller driver  espf/core/middlewares/external/lwIP Lightweight TCP/IP stack  espf/arch/stm32h753iit/drivers/comm/slipif SLIP interface driver (enabling Ethernet access via UART)  espf/core/services/netw/src/netw Networking service which is responsible to configure and start all related services  espf/core/services/tftpd Basic TFTP server implementation using UDP sockets"},{"location":"devguide/devguide_eth.html#network-configuration","title":"Network configuration","text":"<p>By default the network features of the OBC are all turned on. If you wish to exclude some of those features from your OBC SDK build to conserve resources or to speed up the build because you are not using them, there is a set of CMake options defined in <code>build/CMakeLists.txt</code> which you may modify:</p> Option name Description <code>LWIP_SUPPORT_ENABLED</code> Controls the integration of the lwIP TCP/IP stack. <code>ETHERNET_SUPPORT_ENABLED</code> Controls the Ethernet connectivity feature <code>SLIP_SUPPORT_ENABLED</code> Enables SLIP support in the OBC for use with restricted devices which do not have an Ethernet transceiver or to be used as a redundant physical link for IP connectivity over a standard UART <code>TFTPD_SUPPORT_ENABLED</code> Enables TFTP server service in the OBC which provides an easy way to upload/download files to the OBC SD card <p>The default OBC SDK networking configuration is listed below:</p> IP address Subnet mask Interface Where to change... Communication PHY speed <code>192.168.69.10</code> <code>255.255.255.0</code> Ethernet <code>espf/config/netw/netw_cfg.h</code> <code>100</code>Mbps Full-Duplex <code>192.168.70.10</code> <code>255.255.255.0</code> SLIP (over <code>UART8 PC104 H1:33/35</code> pins) <code>espf/config/slipif/slipif_cfg.h</code> <code>115200</code>Kbps Full-Duplex"},{"location":"devguide/devguide_eth.html#testing-the-ethernet-connection","title":"Testing the Ethernet connection","text":"<p>What you need to test the networking connection to your OBC board:</p> <ul> <li>Laptop</li> <li>100BASE-T1 USB adapter (e.g., FC602 USB 100BASE-T1 Stick for Automotive Single Pair Ethernet)</li> <li>2-wire cable with a Molex Pico-Lock 504050-0291 connector</li> <li>USB-C power cable for the OBC</li> <li> <p>OBC SDK v4.1.0+</p> </li> <li> <p>Download and install the USB-Ethernet adapter manufacturer drivers and connect the USB Ethernet adapter to one of your laptop's USB ports. You have to assign an IPv4 IP address to the USB-Ethernet adapter manually. This address must be part of the same network to which the OBC default address belongs, in our case - we could use <code>192.168.69.11</code> with a subnet mask of <code>255.255.255.0</code>.</p> </li> <li> Configure the USB-Ethernet adatper to work in Slave mode (check your adapter documentation for details on how to do that).</li> <li>Connect the 2-wire Molex connector cable to your adapter and the OBC board  (observe the correct P/N line polarity).</li> <li>Power your OBC board and check if the on-board LED flashes green at approximately 1-second intervals (assuming your board is already flashed with the default SDK, all networking features should work out of the box).</li> <li>Try <code>ping</code>-ing your OBC board.</li> </ul> <p>If everything is setup correctly, you should observe an output similar to the following: <pre><code>$ ping 192.168.69.10\n\nPinging 192.168.69.10 with 32 bytes of data:\nReply from 192.168.69.10: bytes=32 time=1ms TTL=255\nReply from 192.168.69.10: bytes=32 time&lt;1ms TTL=255\nReply from 192.168.69.10: bytes=32 time&lt;1ms TTL=255\nReply from 192.168.69.10: bytes=32 time&lt;1ms TTL=255\n\nPing statistics for 192.168.69.10:\n    Packets: Sent = 4, Received = 4, Lost = 0 (0% loss),\nApproximate round trip times in milli-seconds:\n    Minimum = 0ms, Maximum = 1ms, Average = 0ms\n</code></pre></p>"},{"location":"devguide/devguide_eth.html#testing-the-slip-connection","title":"Testing the SLIP connection","text":"<p>What you need to test the networking connection to your OBC board:</p> <ul> <li>Laptop with a Linux OS setup (could also be a Virtual Machine setup)</li> <li>USB to TTL Serial Cable (3.3V) (e.g., FTDI TTL-232R-3V3)</li> <li>USB-C power cable for the OBC</li> <li>OBC SDK v4.1.0+</li> </ul> <p>Tip</p> <p>SLIP is an old protocol and latest versions of Windows do not support it natively. It turns out that it is very difficult or almost impossible to test this under Windows unless you write your own NDIS drivers. In Linux however, SLIP is supported as a kernel module. If you don't want to install a Linux VM in your Windows environment and you don't have a Linux installation on your machine, then you can just as well use a RaspberryPi or a BeagleBone board to test this implementation.</p> <p>Note</p> <p>All instructions that follow assume an Ubuntu Linux-comaptible machine is used for the testing of the SLIP connection. All tests were performed with an Ubuntu 22.04 VM running on top of VirtualBox.</p> <ol> <li>If you have a standard FTDI cable (like the one mentioned above), Linux already natively supports this in the kernel so you should not bother about driver installation. If your cable is very specific, then follow the instructions in the manufacturer's manual to install the respective drivers before going further.</li> <li> <p>Check which <code>tty</code> device your cable registers to. You can see that by typing:     <pre><code>sudo dmesg -wH\n</code></pre></p> <p>You should observe a similar output: <pre><code>[  +0.020449] usbcore: registered new interface driver usbserial_generic\n[  +0.000019] usbserial: USB Serial support registered for generic\n[  +0.009234] usbcore: registered new interface driver ftdi_sio\n[  +0.000016] usbserial: USB Serial support registered for FTDI USB Serial Device\n[  +0.000193] ftdi_sio 1-2:1.0: FTDI USB Serial Device converter detected\n[  +0.000034] usb 1-2: Detected FT232RL\n[  +0.045678] usb 1-2: FTDI USB Serial Device converter now attached to ttyUSB0\n</code></pre> In this case our <code>tty</code> device would be <code>ttyUSB0</code>. This information will be used in the following steps.</p> </li> <li> <p>Create a network interface and attach it to <code>ttyUSB0</code>:</p> <pre><code>sudo slattach -L -d -p slip -s 115200 /dev/ttyUSB0\n</code></pre> <p>Important</p> <p>Pay attention to the <code>-L</code> option which disables the flow control. If your cable doesn\u2019t support HW flow control, you will not get any packet on the communication lines until you disable the flow control.</p> <p>After executing this command you should observe a similar output:</p> <pre><code>slattach: tty_open: looking for lock\nslattach: tty_open: trying to open /dev/ttyUSB0\nslattach: tty_open: /dev/ttyUSB0 (fd=3)\nslattach: tty_set_speed: 115200\nslattach: tty_set_databits: 8\nslattach: tty_set_stopbits: 1\nslattach: tty_set_parity: N\nslip started on /dev/ttyUSB0 interface sl0\n</code></pre> </li> <li> <p>Now after you have the <code>sl0</code> interface mapped to the serial TTY device, you must add the network interface and start it via:</p> <pre><code>sudo ifconfig sl0 192.168.70.1 pointopoint 192.168.70.10 netmask 255.255.255.0\n</code></pre> <p>We are using the default IP address <code>192.168.70.10</code> which is bound to the SLIP interface on the OBC board. The gateway address is also a configuration in your OBC SDK. You can find it in the same file where the SLIP IP address is defined (see above for details).</p> <p>Now the OBC SLIP interface address is set to <code>192.168.70.10</code> and the gateway address is set to <code>192.168.70.1</code>. You can check this by typing:</p> <pre><code>ifconfig sl0\n</code></pre> <p>You should see a similar output:</p> <pre><code>sl0: flags=4305&lt;UP,POINTOPOINT,RUNNING,NOARP,MULTICAST&gt;  mtu 296\n        inet 192.168.70.1  netmask 255.255.255.0  destination 192.168.70.10\n        slip  txqueuelen 10  (Serial Line IP)\n        RX packets 0  bytes 0 (0.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 0  bytes 0 (0.0 B)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n</code></pre> </li> <li> <p>Finally if everything is connected correctly, you should be able to ping the OBC board via the serial connection:</p> <pre><code>ping 192.168.70.10\n64 bytes from 192.168.70.10: icmp_seq=1142 ttl=255 time=16.5 ms\n64 bytes from 192.168.70.10: icmp_seq=1143 ttl=255 time=16.4 ms\n64 bytes from 192.168.70.10: icmp_seq=1144 ttl=255 time=16.4 ms\n...\n</code></pre> <p>Now you can peacefully enjoy your slow Ethernet connection over serial\u2026 Going back to the 80s! </p> </li> </ol>"},{"location":"devguide/devguide_eth.html#tftp-server","title":"TFTP server","text":"<p>The OBC SDK comes pre-configured with a TFTP daemon service which you can find under <code>espf/core/middlewares/external/lwIP/src/apps/tftp</code>. The implementation is not optimal but it is adapted for the OBC SDK environment and works fine with the existing SD card storage. It can be used for basic file transfers over Ethernet or SLIP. In order to test this you will need a TFTP client. Read on for instructions on how to install one.</p>"},{"location":"devguide/devguide_eth.html#step-1-open-a-terminal","title":"Step 1: Open a Terminal","text":"<p>On Linux, open a terminal application. You can typically find it in the Applications menu or by searching for \"Terminal\" in the system search.</p>"},{"location":"devguide/devguide_eth.html#step-2-update-package-lists","title":"Step 2: Update Package Lists","text":"<p>Before installing any new software, it's a good idea to update the package lists to ensure you get the latest version. Enter the following command in the terminal:</p> <pre><code>sudo apt update\n</code></pre>"},{"location":"devguide/devguide_eth.html#step-3-install-the-tftp-client","title":"Step 3: Install the TFTP Client","text":"<p>The TFTP client is typically provided by the <code>tftp-hpa</code> package. To install it, use the following command:</p> <pre><code>sudo apt install tftp-hpa\n</code></pre>"},{"location":"devguide/devguide_eth.html#step-4-confirm-installation","title":"Step 4: Confirm Installation","text":"<p>After the installation is complete, you can confirm that the TFTP client is installed by checking its version. Enter the following command:</p> <pre><code>tftp --version\n</code></pre> <p>If the installation was successful, you should see the TFTP client's version information printed in the terminal.</p>"},{"location":"devguide/devguide_eth.html#step-5-test-the-tftp-client","title":"Step 5: Test the TFTP Client","text":"<p>Now that you have the TFTP client installed, you can test it by trying to download a file from your OBC board. Replace <code>SERVER_IP</code> with the IP address of the TFTP server and <code>FILE_NAME</code> with the name of the file you want to download (the listen port on OBC side is set to <code>69</code> which is the default port for this kind of service, so you don't need to actually specify it on the command line):</p> <pre><code>tftp SERVER_IP -m binary -v -c get FILE_NAME\n</code></pre> <p>You should observe an output similar to the following: <pre><code>Connected to 192.168.69.10 (192.168.69.10), port 69\nputting FILE_NAME to 192.168.69.10:FILE_NAME [octet]\nSent 1048576 bytes in 15.9 seconds [526229 bit/s]\n</code></pre></p> <p>If everything is setup correctly and <code>FILE_NAME</code> exists on the OBC SD card, the file will be downloaded to your current directory, otherwise you will get an error.</p> <p>That's it! You have successfully installed a TFTP client on your Linux system. The TFTP client allows you to interact with TFTP servers to download or upload files using the TFTP protocol.</p> <p>Note</p> <p>Keep in mind that the TFTP protocol is typically used for simple file transfer tasks and may not have the security features of more complex protocols like FTP or SFTP. It also doesn't support transfer resuming. Always use it in trusted environments and for non-sensitive data. If you rely on this protocol to exchange data between OBC and other payloads, make sure you fully verify the integrity of your transferred file after the operation is finished.</p> <p> EnduroSat does not recommend using this protocol for critical applications.</p>"},{"location":"devguide/devguide_eth.html#tcpip-stack","title":"TCP/IP stack","text":"<p>OBC SDK comes with an integrated lwIP distribution which you can use to kick-start your networking development. lwIP is a small yet efficient open-source TCP/IP stack designed for embedded systems with limited resources. It provides a range of networking protocols, making it a suitable choice for integrating networking capabilities into your project. Some key features of lwIP include:</p> <ul> <li> <p>Small Footprint: lwIP is designed to have a minimal memory footprint, making it suitable for resource-constrained environments.</p> </li> <li> <p>Supported Protocols: lwIP supports various networking protocols, such as IPv4, IPv6, TCP, UDP, ICMP, DHCP, DNS, and more.</p> </li> <li> <p>Modular Design: The stack is designed in a modular way, allowing users to enable or disable specific features based on their requirements.</p> </li> <li> <p>Efficient Buffer Management: lwIP implements an efficient buffer management system to minimize memory usage during data transmission.</p> </li> <li> <p>Portability: lwIP is written in C and is highly portable, making it easy to integrate with different hardware platforms and operating systems.</p> </li> <li> <p>Extensive Protocol Support: The stack offers support for common networking protocols like HTTP, FTP, MQTT, and more.</p> </li> <li> <p>BSD Socket API: lwIP implements a BSD socket-like API, making it familiar to developers who have experience with standard socket programming.</p> </li> <li> <p>Customization Options: lwIP provides several configuration options, allowing users to tailor the stack according to their specific needs.</p> </li> <li> <p>Free and Open Source: lwIP is licensed under the permissive BSD license, making it free to use and modify in both commercial and non-commercial projects.</p> </li> </ul>"},{"location":"devguide/devguide_eth.html#documentation-references","title":"Documentation references","text":"<p>The purpose of this documentation is not to provide an in-depth reference on lwIP APIs usage but here are some helpful resources to get started with lwIP integration and development:</p> <ul> <li> <p>lwIP Official Website: The official website provides the latest news, downloads, and documentation for lwIP.</p> </li> <li> <p>lwIP GitHub Repository: The lwIP source code is available on GitHub, which is a great place to access the latest development version and report issues.</p> </li> <li> <p>lwIP Wiki: The lwIP community maintains a wiki that contains valuable information, FAQs, and troubleshooting tips.</p> </li> <li> <p>lwIP API Documentation: The official API documentation provides details on the available functions and their usage.</p> </li> <li> <p>lwIP Mailing List Archives: The mailing list archives contain discussions and solutions shared by the lwIP community.</p> </li> </ul> <p>Note</p> <p>Remember to refer to the official documentation and resources to ensure you have the most up-to-date and accurate information on lwIP integration and usage.</p>"},{"location":"devguide/devguide_eth.html#lwip-stack-configuration","title":"lwIP stack configuration","text":"<p>The lwIP stack has many configuration options and parameters which must be adapted to your needs. You can find those parameters here:</p> <ul> <li><code>espf/config/lwIP/lwipopts.h</code></li> </ul> <p>Details on the individual parameters can be found in the lwIP documentation reference and also inside the header file itself.</p> <p>Note</p> <p>lwIP in the OBC SDK is configured with most options set to their default values. It is your responsibility to review those and adapt them to your project-specific needs.</p>"},{"location":"devguide/devguide_fwupd.html","title":"Bootloader and firmware updates handling","text":""},{"location":"devguide/devguide_fwupd.html#bootloader","title":"Bootloader","text":"<p>The OBC Bootloader is a programming image provided by EnduroSat which enables updates of the standard OBC application via:</p> <ul> <li>ESPS I (by wire)</li> <li>ESPS I (OTA)</li> </ul> <p>Note</p> <p>You should have received the EnduroSat Bootloader binary image as part of your OBC SDK purchase package.</p> <p>Warning</p> <p>Bootloader image updates are only possible via the JTAG link cable and the ST-Link programmer!</p> <p>When you receive your OBC board from EnduroSat, it will be originally flashed with the OBC Bootloader binary. Since you have full control over what gets written into your MCU FLASH ROM, you can easily erase (accidentally or on purpose) the original EnduroSat Bootloader image from FLASH ROM. If that happens and you want to get back to your original board state, perform the following steps (it is assumed that you have the <code>STM32CubeProgrammer CLI</code> executable installed on your machine):</p> <ol> <li>Make sure your OBC board is not powered</li> <li>Connect the ST-Link JTAG programmer to the OBC board</li> <li>Connect the ST-Link JTAG programmer to your PC USB port</li> <li>Power on your OBC board</li> <li>Open a command-line console and execute the following command:</li> </ol> <p><pre><code>STM32_Programmer_CLI -c port=JTAG --erase all --download &lt;OBC Bootloader bin file path&gt; 0x08000000\n</code></pre> You should see an output similar to the following: <pre><code>      -------------------------------------------------------------------\n                       STM32CubeProgrammer v2.13.0\n      -------------------------------------------------------------------\n\nST-LINK SN  : 36FF73064D59303615371643\nST-LINK FW  : V2J41S7\nBoard       : --\nVoltage     : 3.28V\nJTAG freq   : 9000 KHz\nConnect mode: Normal\nReset mode  : Software reset\nDevice ID   : 0x450\nRevision ID : Rev V\nDevice name : STM32H7xx\nFlash size  : 2 MBytes\nDevice type : MCU\nDevice CPU  : Cortex-M7\nBL Version  : 0x90\n\n\nMass erase ...\n\nMass erase successfully achieved\n\n\nMemory Programming ...\nOpening and parsing file: obc_bootloader.bin\n  File          : obc_bootloader.bin\n  Size          : 201.51 KB\n  Address       : 0x08000000\n\n\nErasing memory corresponding to segment 0:\nErasing internal memory sectors [0 1]\nDownload in Progress:\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 100%\n\nFile download complete\nTime elapsed during download operation: 00:00:11.926\n</code></pre> If everything went fine and you didn't get any errors during the process, the OBC green indicator LED will be blinking slowly at approx. 2-second intervals. This indicates you are in Bootloader mode. From this point on, you can flash a new application bundle to the board by following the instructions in Flashing application binaries via the OBC Bootloader or Flashing application bundles via the OBC Bootloader.</p>"},{"location":"devguide/devguide_fwupd.html#bootloaderapplication-data-interface","title":"Bootloader/Application data interface","text":"<p>If you are opting to use the standard EnduroSat bootloader, you have to be careful not to break the Bootloader/Application interface so that all functions of the system work as expected. Here is a short summary of the interfacing aspects between the Bootloader and the Application images:</p> <ul> <li>Firmware update image location on the on-board storage is set to the following mount point: <code>/sd/OBC_img.bin</code><ul> <li>This file will be used as a firmware image to flash the OBC Application region after rebooting the system after an image file transfer. If you change the name of the file, the Bootloader will not be able to find it and the system will remain in Bootloader mode.</li> </ul> </li> <li>Bootloader/Application shared NVM blocks<ul> <li>These data blocks are placed at the beginning of the FRAM storage and contain data which is used by the Bootloader and the Application. It is recommended to keep these NVM blocks unchanged. These shared blocks can be found in <code>espf/config/nvm_bootcfg/inc/nvm_boot_block_ids.h</code> file.</li> </ul> </li> </ul>"},{"location":"devguide/devguide_fwupd.html#obc-sdk-firmware-updates","title":"OBC SDK firmware updates","text":"<p>FW update functionality from the ES GS is provided to the OBC module out-of-the-box. The file transfer is completely handled by the ESPS I FWUPD protocol which ensures that you will have your update bundle stored on the SD card when the operation is finished. The actual update is performed by the <code>FWUPD_Handler_Cfg.c::FWUPD_Handler_Cfg_HandleTransferComplete(...)</code> function.</p> <p>Warning</p> <p>Please have in mind that while the transfer of a firmware update image can be performed by both Application and Bootloader, the physical flashing of the OBC SDK firmware at the moment of writing this guide can only be performed by the Bootloader.</p> <p>The procedure involves the following major steps:</p> <ol> <li>The transferred update file is stored on the SD card.</li> <li>A soft reset is performed in Bootloader mode.</li> <li>Bootloader detects that a flash operation is requested and starts the procedure.</li> <li>After flashing the application FLASH blocks, the Bootloader calculates a CRC of the flashed image and compares it to the CRC calculated from the image file.</li> <li>If both CRCs match, the application is flashed correctly and a jump to the application image entry-point is performed; otherwise, the OBC remains in Bootloader mode waiting for another flashing attempt.</li> </ol> <p></p>"},{"location":"devguide/devguide_fwupd.html#my-payload-does-not-speak-esps-i-can-i-still-transfer-a-custom-payload-firmware-via-this-mechanism","title":"My payload does not speak ESPS I. Can I still transfer a custom payload firmware via this mechanism?","text":"<p>Absolutely. If you already have specific payloads in your system which are managed by the OBC and they are not manufactured by EnduroSat, you can still use the same FWUPD mechanism to transfer update images for those payloads. As a matter of fact, you can transport any file via this mechanism. You are free to implement your custom handling for those images in the <code>FWUPD_Handler_Cfg.c::FWUPD_Handler_Cfg_HandleTransferComplete(...)</code> function. Read on for more details on how to do that with the OBC SDK.</p> <p>Warning</p> <p>Please have in mind, that the current operating speeds of the ESPS I bus is fairly low so bigger images may take a very long time to transfer. This mechanism is only suitable for exchanging smaller files, e.g. on the order of several hundred bytes.</p> <p>Let's inspect the <code>FWUPD_Handler_Cfg_HandleTransferComplete(...)</code> prototype more closely...</p> <pre><code>// This function is called whenever a new update image is received by the OBC and is ready to be processed\nbool FWUPD_Handler_Cfg_HandleTransferComplete(sTransferInfo_t * const pTransferInfo,\n                                              const uint64_t u64ActiveTransferId,\n                                              const char * const pFileName)\n</code></pre> <p>It provides the following information:</p> <ul> <li><code>pTransferInfo</code> which is a pointer to the update transfer context structure (it contains details on the actual type of update package which was uploaded)</li> <li><code>u64ActiveTransferid</code> is an unique identifier assigned to this particular transfer session by the GS</li> <li><code>pFileName</code> is the name of the file transferred on the SD card</li> </ul> <p>The bundle header which can be accessed via <code>pTransferInfo-&gt;header</code> field is of type <code>SESSoftwareUPD_Bundle</code> and contains the following attributes: <pre><code>typedef struct\n{\n    SESSoftwareUPD_Hdr hdr;\n    uint16_t nSubModule;\n    uint16_t nModuleType;\n    uint16_t nModuleConfig;\n    uint16_t nBoardRevision;\n    uint16_t nCPUType;\n    uint16_t nFWType;\n    uint16_t nFWVerMaj;\n    uint16_t nFWVerMin;\n    uint64_t nFlags;\n} SESSoftwareUPD_Bundle;\n</code></pre></p> <p><code>SESSoftwareUPD_Bundle::nModuleType</code> has a fixed value of <code>FW_OBC_SUBMODULE_SELF</code> for OBC FW updates by default (this defined in the <code>Middlewares/TPLayerUser/FWUPD_Handler_Cfg.h</code> header).</p> <p>Tip</p> <p>As all header fields are assigned to the update image at the time of preparation on the GS, you can use these fields to perform specific checks about your update image or simply define a special type of image which you can identify based on this header and process in a specific way when received on the OBC.</p> <p>Considering this, the FWUPD mechanism is actually quite generic and can also be used for other purposes such as uploading NVRAM content, uploading a settings file to your device or transferring update images for OBC-connected slave devices which do not speak the ESPS I protocol and do not have a connection to the RS-485 bus.</p> <p>Note</p> <p>The original implementation of the FWUPD protocol was never intended to transfer files but rather binary images for memory-constrained devices. As such, the original protocol does not give the users a way to specify a file name. OBC will store whatever data is received in a file called <code>OBC_IMG.BIN</code> by default. The OBC SDK however provides a specific protocol extension to support naming uploaded data images via the FWUPD protocol. It is called a <code>meta-data footer block</code> which gets appended to the FWUPD bundle. The only specific requirement for the update bundle header is to use the <code>FW_OBC_MODULE_TYPE (0)</code> value for the <code>nModuleType</code> field. The existence of this meta-data block is verified by the example implementation of the <code>FWUPD_Handler_Cfg_HandleTransferComplete</code> function and if the block exists, the uploaded data is stored on the SD card using the <code>file_name</code> field value from the footer structure.</p> <p>The <code>footer block</code> binary structure is defined as:</p> Field name Type Description ext_bun_sig <code>uint8[7]</code> extended bundle footer signature in ASCII, fixed to the string <code>EXT_BUN</code> (no terminating NULL character) file_name <code>uint8[47]</code> ASIIZ file name to use for storing the received data on the SD card ext_bun_crc <code>uint16</code> CRC16-CCITT of all footer fields (poly: <code>0x1021</code>, seed: <code>0xFFFF</code>) <p>On top of that, there is a generic file handling mechanism implemented which gets triggered as soon as a file is uploaded via the FWUPD protocol. The handling of files is based on their extension. If you would like to register your own file extension to handle in a specific way, here are the steps you should perform (we will assume that you want to handle the <code>zip</code> file extension):</p> <ul> <li> <p>create a file extension handler function which matches the function prototype defined by type <code>p_file_handler_t</code>:     <pre><code>static void zip_handler(const char * const p_file_name)\n{\n    // handle p_file_name as a ZIP file\n}\n</code></pre></p> </li> <li> <p>extend the <code>file_ext_map</code> array with your new <code>zip</code> entry:     <pre><code>static const file_ext_map_t file_ext_map[EXT_MAP_ENTRIES_CNT] =\n{\n    ...,\n    { .uppercase_ext = \"ZIP\", .lowercase_ext = \"zip\", .p_file_ext_handler = &amp;zip_handler },\n};\n</code></pre> Do not forget to update the <code>EXT_MAP_ENTRIES_CNT</code> value</p> </li> <li> <p>Upload a <code>zip</code> file to the OBC using the mechanism described here and your new <code>zip_handler</code> function will be called when the upload finishes providing the name of the file as an argument.<sup>1</sup></p> </li> </ul>"},{"location":"devguide/devguide_fwupd.html#os-tasks","title":"OS tasks","text":"Task name Defined in... Execution policy Description MACTLDrvTask ESSA_Stack_TP_Layer.c Periodic @ 50 ms main ESPS I Transport Layer task driver (CP commands get scheduled by a call to the <code>CP_Handler.c::CP_Handler_Task()</code> function) FwUpdateTask FWUPD_Handler.c Event/Periodic @ 20 ms FWUPD task which handles incoming packets from ESPS FWUPD protocol and persists them on the SD card"},{"location":"devguide/devguide_fwupd.html#flashing-application-binaries-via-the-obc-bootloader","title":"Flashing application binaries via the OBC Bootloader","text":"<p>Usually, when your project is in the active development phase, you will be directly flashing the OBC via the ST-Link JTAG programmer during debugging using <code>noboot</code> images which do not require the presence of a bootloader on the OBC board.</p> <p>Warning</p> <p>When testing your final releases, the release images can only be flashed by the EnduroSat Bootloader which must be provisioned on your board in advance (see Bootloader section for details). Once this is done, you can use macaron to streamline your flashing experience as the preparation of an application bundle contains a few steps which you may not want to perform manually to avoid errors:</p> <ol> <li> <p>build your OBC image in a <code>debug</code> or <code>release</code> configuration (check Building OBC SDK from the console via macaron for more details) <pre><code>cd &lt;OBC_ROOT&gt;/build\npython macaron.py -b release\n</code></pre></p> </li> <li> <p>now flash the produced binary image in the <code>./release</code>  folder by typing the following in the console: <pre><code>python macaron.py --flash-bin ./release/OBC_STDPF_STM32H_release.bin --dongle-port &lt;your dongle com port id&gt; --obc-mac-addr &lt;OBC ESPS MAC address&gt;\n</code></pre> By default, the OBC ESPS MAC address is set to <code>0x33</code> so if you didn't change it yourself, you must use this value.</p> </li> </ol> <p>Tip</p> <p>If you only want to create a bundle which you would give to someone else for flashing the OBC, then you can use the following command line: <pre><code>python macaron.py --create-app-bundle ./release/OBC_STDPF_STM32H_release.bin\n</code></pre> You should see an output similar to the following: <pre><code>Endurosat -macaron- build front-end [v0.3]\nmacaron.py started with args: Namespace(build=None, release_ver=None, clean=False, clean_gen_content=WindowsPath('.'), fp_gen=False, datacache_gen=False, fp_gen_all=False, depl_config='', fp_merge_root=WindowsPath('.'), verbose=False, error_out_only=False, reset_log=False, flash_bin=None, dongle_port=None, obc_mac_addr=51, create_app_bundle=WindowsPath('C:/Projects/SWP/GitRepo/obc-stdpf-hw-1.x\n           0 00 00                                              ................\n          16  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  ................\n          32  00 00 00 00 00 00 EB 53  B7 A4                    .......S..\n        2023/09/08 18:51:53 FWUpd header with size 7 serialized:\n           0  DF 9B 57 13 01 00 00                              ..W....\n        2023/09/08 18:51:53 Bundle parameters with size 24 serialized:\n           0  00 00 06 00 01 00 01 00  01 00 01 00 00 00 00 00  ................\n          16  00 00 00 00 00 00 00 00                           ........\n        2023/09/08 18:51:53 Bundle exported successfully\n&gt;  command finished successfully!\nOBC application bundle created here: \"C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x-dev\\build\\release\\OBC_STDPF_STM32H_release.bin.bun\"\n</code></pre></p>"},{"location":"devguide/devguide_fwupd.html#flashing-application-bundles-via-the-obc-bootloader","title":"Flashing application bundles via the OBC Bootloader","text":"<p>If you want to flash a prebuilt bundle file directly, you can use the following command in the console: <pre><code>python macaron.py --flash-bun &lt;bundle file path&gt; --dongle-port &lt;your dongle com port id&gt; --obc-mac-addr &lt;OBC ESPS MAC address&gt;\n</code></pre></p>"},{"location":"devguide/devguide_fwupd.html#resuming-an-interrupted-bundle-upload","title":"Resuming an interrupted bundle upload","text":"<p>If you start the application bundle flashing procedure, your image must first be uploaded to the OBC board. With the current physical interface and baud-rate used, it takes a few minutes for an average binary of several hundred kilobytes to transfer via a dongle. You could also be doing this over a radio dongle which requires more time. If something happens during the transfer, it can potentially get interrupted. Fortunately, you can still continue the transfer from where it stopped by using a special command line parameter which you can pass to macaron. It is called a <code>session-id</code>.</p> <p>Info</p> <p>A <code>session-id</code> is a unique identifier of the communication session established between the satellite and the ground segment (or a test PC when testing in the lab). By default <code>session-id</code>s get generated randomly upon the start of a new transfer. They are printed as part of the debug output during a flashing session. Here is a simple flashing session log:</p> <p><pre><code>Endurosat -macaron- build front-end [v0.3]\nmacaron.py started with args: Namespace(build=None, release_ver=None, clean=False, clean_gen_content=WindowsPath('.'), fp_gen=False, datacache_gen=False, fp_gen_all=False, depl_config='', fp_merge_root=WindowsPath('.'), verbose=False, error_out_only=False, reset_log=False, flash_bin=None, flash_bun=WindowsPath('release/OBC_STDPF_STM32H_release.bin.bun'), session_id=462308182, dongle_port='6', obc_mac_addr=52, create_app_bundle=None)\nESPF_ROOT_BUILD_PATH environment variable not set. Using default path setting resolving to \"C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x-dev\".\ncleaning up all directories with name \"src-gen-c\" under \"C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x-dev\\build\"...\nstarting bundle app flash procedure: \"C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x-dev\\other\\tools\\GSEmulation.exe --com 6 --protocol FWUPD --network-type RS485 --test-type 0 --source-addr 1 --dest-module-addr 52 --satellite-id 0 --input-file C:\\Projects\\SWP\\GitRepo\\obc-stdpf-hw-1.x-dev\\build\\release\\OBC_STDPF_STM32H_release.bin.bun --verbose 1 --tl_packet-id 462308182\"\n        [2023/09/11 13:33:32.695] StandAloneThread thread : started\n        Entering CESTL_Drv::Init(): 1\n         ++++++++ CESTL_Sender::StartTransfer::nTLHostContext: 9223372037317083990\n        s\n        Send FW Bundle [462308182]\n        a\n        [Restarted @ 34.4 %]\n        [24576]ddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddsa[24576] | 37.88\n        [24576]ddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddsa[24576] | 41.36\n        [24576]ddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddsa[24576] | 44.83\n        [24576]ddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddsa[24576] | 48.31\n        [24576]ddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddsa[24576] | 51.78\n        [24576]ddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddsa[24576] | 55.26\n        [24576]ddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddsa[24576] | 58.74\n        [24576]ddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddsa[24576] | 62.21\n        [24576]ddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddsa[24576] | 65.69\n        [24576]ddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddsa[24576] | 69.16\n        [24576]ddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddsa[24576] | 72.64\n        [24576]ddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddsa[24576] | 76.12\n        [24576]ddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddsa[24576] | 79.59\n        [24576]ddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddsa[24576] | 83.07\n        [24576]ddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddsa[24576] | 86.54\n        [24576]ddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddsa[24576] | 90.02\n        [24576]ddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddsa[24576] | 93.50\n        [24576]ddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddsa[24576] | 96.97\n        [21400]dddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddsa[21400] | 100.00\n        SA\n        [13]DSA[13] | 100% Transfer Completed\n        Status : [SESUL_UPLS_WAITING] Upload received ok, and pending for update, Err : [SESUL_UPLE_SUCCESS] No error\n         ++++++++ CESTL_Sender::StartTransfer::nTLHostContext: 462308182\n        s\n        Send UPD CMD [462308182] a\n        [Restarted @ 0.0 %]\n        [11]dsa[11] | 100.00\n        SA\n        [13]DSA[13] | 100% Transfer Completed\n        Status : [SESUL_UPLS_WAITING] Upload received ok, and pending for update, Err : [SESUL_UPLE_SUCCESS] No error\n         ++++++++ CESTL_Sender::StartTransfer::nTLHostContext: 462308182\n        s\n        Send UPD CMD [462308182] a\n        [Restarted @ 0.0 %]\n        [11]dsa[11] | 100.00\n         ++++++++ CESTL_Sender::StartTransfer::nTLHostContext: 462308182\n        s\n        Send UPD CMD [462308182] a\n        [Restarted @ 0.0 %]\n        [11]dsa[11] | 100.00\n        ===============================================\n        SUCCESS\n&gt;  command finished successfully!\n</code></pre> The <code>session-id</code> is given at line <code>10</code> in square brackets =&gt; <code>462308182</code>.</p> <p>If your transfer interrupts for some reason, you can easily continue the transfer by specifying its original <code>session-id</code> at the command line as follows: <pre><code>python macaron.py --flash-bin ./release/OBC_STDPF_STM32H_release.bin --dongle-port &lt;your dongle com port id&gt; --obc-mac-addr &lt;OBC ESPS MAC address&gt; --session-id 462308182\n</code></pre></p> <p>If the <code>session-id</code> you specified is the same as the session registered in the OBC, the transfer will just continue from where it left off, otherwise the transfer will be restarted with the <code>session-id</code> you specified.</p> <p>Tip</p> <p>If you don't want to scan flash logs to recover the <code>session-id</code> for your transfer, you can directly specify it via the <code>--sesssion-id</code> macaron parameter when you first start the transfer. If the transfer breaks, just run the same command in the console and it will continue your transfer right away.</p> <ol> <li> <p>This mechanism only works with FWUPD file uploads. If the file is uploaded via the FileManager FP API, the handler will not be called.\u00a0\u21a9</p> </li> </ol>"},{"location":"devguide/devguide_micropython.html","title":"MicroPython","text":"<p>Experimental feature</p> <p>Before taking a decision to use this feature, you shall know that:</p> <ul> <li>This feature is not yet thoroughly tested by EnduroSat.</li> <li>It is not guaranteed to operate correctly under all conditions.</li> <li>It is turned off by default in the CMake build.</li> <li>You can use it solely at your own risk.</li> <li> EnduroSat does not provide customer support for experimental features at this time.</li> </ul> <p>It is crucial for satellites to be controlled based on feedback from onboard sensors while in space. All the information must be gathered and based on it a decision for some actions to be taken (ex.: such action could be to tilt the satellite to a specific degree and take a photo in predefined time). Actions, before introducing MicroPython, were taken only from the ground station or based on a predefined scheduled operation.  It was found that such predefined scheduling mechanisms are not convenient, because in many cases small modifications must be made, but it leads to reflash of the OBC module. It was decided that introduction of a scripting language can vastly increase the usability of the satellite and will improve the usability in several ways: \u2003- satellite to have a generic and arbitrary means to be controlled and connected to Payload. \u2003- Use of established technic for arbitrary command and flow-control. \u2003- Easy to commission over the air</p> <p>The solution that EnduroSat proposes is using MicroPython. A small python script engine is running on the OBC and can be used to execute simple scripts on the satellite.</p>"},{"location":"devguide/devguide_micropython.html#what-are-the-capabilities-of-the-scripts-that-can-be-written","title":"What are the capabilities of the scripts that can be written.","text":"<p>Normally all kinds of scripts can be written and executed in the OBC, but as this is not a PC, but embedded system there are some limitations that need to be considered when writing scripts.</p> id Limitations description 1 Only one script can be executed at a time 2 After execution of one script the heap is cleared and the MicroPython environment is reinitialized for the next script. (This is done automatic) 3 A script shall not go into endless loop. If the script goes into endless loop the MicroPython environment will wait for time defined by the interface for invocation of the script and will terminate the script if it does not finish in time. 4 As we are in the world of embedded SW there is limited amount of heap which can be used by the python script. This means that we need to be careful not only with the memory used by our script, but also what we are including in our script. Each included module is loaded into the heap. The heap currently reserved is 128KB.  TIP: There are 2 different ways of script integration. Frozen scripts or external modules. The frozen scripts are integrated within the build and use much less heap. If a module is found to be used very frequently it can be implemented as Frozen module and this will give us optimization of heap usage. 5 There are a lot of existing implemented modules for MicroPython, but only a few of them are enabled in the OBC integration. The purpose of this is to have optimal implementation (only use is needed).  TIP: In case of missing module please contact the SW_PLATFORM team to enable the module. List of modules that can be activated can be found in following links:  \u2003- MicroPython standard libraries \u2003- MicroPython specific libraries \u2003- other modules ported for MicroPython can be found here 6 A script shall not use the MicroPython output extensively for logging information it shall be used only in case of an error. A specific log file to be used for detailed information. 7 The MicroPython output is going to a common file and extensive use of this output will make the file unreadable. The purpose of the MicroPython output file shall be only to get a better understanding of what happens in case of an error. For storing this output, a rolling file is used placed on the root folder of the SD card. The filename pattern is the following: upy_log.d&lt;X&gt;&lt;Y&gt;  &lt;X&gt; \u2003- value \"o\" means this is currently used log file \u2003\u2003\u2003- value \"x\" means this file is not currently used. &lt;Y&gt; - number from 0 to 9, gives the consecutive number of the file."},{"location":"devguide/devguide_newcomp.html","title":"Extending the SDK with new components","text":"<p>Note</p> <p>In the context of the OBC SDK, a <code>software component</code> is a collection of source files (.c and .h) which encapsulate a set of logically related functions or implement a specific algorithm. Communication to software components takes place only via their declared public interface (in the C language, that would be one or more header file(s)). Software components are packaged as a static library and have clearly defined dependencies in the CMake build through the <code>target_link_libraries</code> CMake command.</p> <p>This chapter is intended for users who wish to extend the OBC SDK with their own components and integrate their code in the build process but don't have much experience with CMake. We will describe the pattern that EnduroSat follows when extending the OBC SDK and which also integrates the build process with macchiato source code generation from FIDL files (if you are using them in your implementation).</p>"},{"location":"devguide/devguide_newcomp.html#component-folder-structure","title":"Component folder structure","text":"<p>The proposed folder structure of a component is the following:</p> Folder Sub-folder Description <code>component name</code><sup>1</sup> Place here the CMakeLists.txt file describing how to build your component. <code>inc</code> Place here the public headers of your component (.h files). <code>src</code> Place here the source code of your component (.c files). <code>config</code> Place here configuration files used by your component build such as macchiato deployment schema files for code generation. <code>fp</code> Place here macchiato-generated code for the Function Protocol ESPS I layer (based on FIDL descriptions)."},{"location":"devguide/devguide_newcomp.html#the-anatomy-of-a-typical-obc-sdk-cmakeliststxt-file","title":"The anatomy of a typical OBC SDK CMakeLists.txt file","text":"<p>Each software component needs a build recipe. In the context of the OBC SDK, that would be the <code>CMakeLists.txt</code> file which contains instructions on building your component. There are many ways with CMake to describe your build ingredients and this instruction aims to provide a basic template which you can directly use and which is well integrated with the rest of the OBC SDK build infrastructure. You can always deviate from this, if additional flexibility is needed or your component does not exactly fit into the shape promoted here.</p> <p>Our assumption would be that we are writing a build file for a telemetry service and we have already implemented our source code in the proposed folder structure above. The component is also using some FP commands described with a FIDL file and we want to enable automatic code generation with macchiato for this component. Let's start...</p> <ul> <li>Define a project for your component</li> </ul> <pre><code>project(telemetry C)\nset(make_target \"telemetry\")\n</code></pre> <p>Tip</p> <p>We define the <code>make_target</code> variable here to use in all commands expecting a CMake target to make it easier to change the name of the produced .a file later, e.g. in this case that would be <code>libtelemetry.a</code>. You can skip this customization step if you want.</p> <ul> <li>Include OBC SDK-specific CMake helper functions</li> </ul> <p><pre><code>include(${ROOT_BUILD_PATH}/espf.cmake)\n</code></pre> <code>${ROOT_BUILD_PATH}</code> is a variable is defined by the root <code>CMakeLists.txt</code> file.</p> <ul> <li>Create absolute path variables for your deployment schema (FDEPL) and FIDL file used for the FP code generation of your component</li> </ul> <pre><code>cmake_path(SET fdepl_path \"${PROJECT_SOURCE_DIR}/config/telemetry.fdepl\")\ncmake_path(SET fidl_path \"${FIDL_ROOT_OBC}/Telemetry.fidl\")\n</code></pre> <p>Warn</p> <p><code>cmake_path</code> command is used here to ensure macchiato code generator is provided correctly formatted build host paths.</p> <ul> <li>Let's create a list of FIDL files which code generation with macchiato will depend on. It will be used later to enable automatic code generation upon modification of any of the FIDL files listed.</li> </ul> <pre><code>list(APPEND fidl_dependencies_list\n    ${fidl_path}\n)\n</code></pre> <ul> <li>Now we will list all C source files which are generated by macchiato. If you don't know these in advance, you can run macchiato first to get the list of files and then put them in your <code>CMakeLists.txt</code> file. The number of files and naming pattern doesn't change with each generation so once you do this the first time, you will just know how to name your files based on the name of your FIDL interface.</li> </ul> <pre><code>list(APPEND fp_list\n        ${PROJECT_SOURCE_DIR}/fp/Telemetry/v0.1/Telemetry_server/FP_TelemetryProtocolServer.c\n        ${PROJECT_SOURCE_DIR}/fp/Telemetry/v0.1/Telemetry_server/FP_TelemetryServerApp.c\n        ${PROJECT_SOURCE_DIR}/fp/Telemetry/v0.1/Telemetry_server/FP_TelemetryProtocolTypes.h\n        ${PROJECT_SOURCE_DIR}/fp/Telemetry/v0.1/Telemetry_server/FP_TelemetryProtocolServer.h\n        ${PROJECT_SOURCE_DIR}/fp/Telemetry/v0.1/Telemetry_server/FP_TelemetryServerApp.h\n)\n</code></pre> <ul> <li>Once we are ready with the description of our FIDL dependencies, we can add a custom CMake command to arm the triggering of macchiato when the build starts and the files we specified in <code>fp_list</code> do not exist. This is easily done with a predefined function from the <code>espf.cmake</code> file which we included earlier:</li> </ul> <p><pre><code>FP_GEN_AT_PATH(fp_list ${fdepl_path} fidl_dependencies_list \"${PROJECT_SOURCE_DIR}/fp\")\n</code></pre> This line will:</p> <ul> <li>Configure your project to generate automatically your specified deployment schema (<code>fdepl_path</code>) in the <code>fp</code> subfolder of your component root folder.</li> <li>Trigger generation of the files specified by <code>fp_list</code> above in case any of the original <code>fdepl_path</code> or <code>fidl_path</code> files get modified.</li> <li> <p>Automatically merge any changes you made to the <code>FP_TelemetryServerApp.c</code> file after performing a new generation in any of the previous steps<sup>2</sup></p> </li> <li> <p>So far, so good but we need to include the generated source files to the list of files our component needs to build.</p> </li> </ul> <pre><code>list(APPEND telemetry_sources\n    \"src/telemetry.c\"\n    \"src/telemetry_sm_config_user.c\"\n    \"src/telemetry_sm_config.c\"\n    \"src/telemetry_file_sink_sm_config_user.c\"\n    \"src/telemetry_file_sink_sm_config.c\"\n    \"src/telemetry_queue.c\"\n    \"src/telemetry_file_sink.c\"\n    ${fp_list}\n)\n\nadd_library(${make_target} STATIC\n    ${telemetry_sources}\n)\n</code></pre> <p>Note</p> <p>If you inspect closer the <code>telemetry_sources</code> CMake list, you will notice that lines <code>1-7</code> enumerate all manually written C source files and at line <code>8</code> we append the <code>fp_list</code> with all generated C files. This is how all component-specific source files will eventually be added to the static library build target and CMake will take care to compile them for you.</p> <ul> <li>We integrated all FIDL-generated sources for the component into the component build process but we still need to incorporate the generated commands into the ESPS I stack used by the project. There is some fair automation going behind the scenes but fortunately you don't need to know details about how this is exactly done. What you have to do from the perspective of your own component is to set a couple of global properties and leave the rest to CMake . Here is how those property settings look like:</li> </ul> <pre><code>set_property(GLOBAL APPEND PROPERTY FUNCTION_PROTOCOL_INCLUDE_LIST\n    \"#include \\\"fp/Telemetry/v0.1/Telemetry_server/FP_TelemetryProtocolServer.h\\\"\"\n)\n\nset_property(GLOBAL APPEND PROPERTY FUNCTION_PROTOCOL_HANDLERS_LIST\n    \"&amp;FP_TelemetryProtocolServerInfo\"\n)\n\nset_property(GLOBAL APPEND PROPERTY FUNCTION_PROTOCOL_APP_INCLUDE_LIST\n    \"#include \\\"fp/Telemetry/v0.1/Telemetry_server/FP_TelemetryServerApp.h\\\"\"\n)\n\nset_property(GLOBAL APPEND PROPERTY FUNCTION_PROTOCOL_APP_INIT_LIST\n    \"TelemetryServerAppInit()\\;\"\n)\n</code></pre> <p>Note</p> <p>The above properties actually specify lines of C code which get accumulated to a list and later placed in files automatically generated by CMake which provide the ESPS configuration used by the OBC SDK project. In fact, this serves as a plug-in mechanism for FIDL commands because if your component <code>CMakeLists.txt</code> file is not added to the root project, its corresponding FIDL-generated commands will not be available for the end-users to execute.</p> <ul> <li>Finally we will add our component public include paths and specify the compilation and linker options for our component as well as its external dependencies:</li> </ul> <pre><code>list(\n    APPEND module_includes\n    \"${PROJECT_SOURCE_DIR}\"\n    \"${PROJECT_SOURCE_DIR}/inc\"\n    \"${PROJECT_SOURCE_DIR}/src\"\n)\n\ntarget_include_directories(${make_target} PUBLIC ${module_includes} PRIVATE ${ROOT_INCLUDES})\ntarget_compile_definitions(${make_target} PUBLIC ${ROOT_COMPILE_DEFS})\ntarget_compile_options(${make_target} PUBLIC ${ROOT_COMPILE_OPTIONS})\ntarget_link_options(${make_target} PUBLIC ${ROOT_LINK_OPTIONS})\ntarget_link_libraries(${make_target} timer hsm datetime COBS datacache)\n</code></pre> <p>Note</p> <p>All CMake variables containing the word <code>ROOT</code> are actually defined by the root <code>CMakeLists.txt</code> file. In this case, most of the compiler and linker options are inherited from the top-level project.</p> <p>Tip</p> <p>The <code>target_link_libraries</code> call on line <code>12</code> provides the names of all other CMake components your implementation depends on.  Why is this important?  This is how CMake knows to rebuild your library if any of the dependent libraries get rebuilt. This line also ensures that the public include paths for all dependent components is added to the list of include folders passed to the compiler when building your component sources.</p> <ul> <li>Your component build recipe is now ready. What remains is adding this to the top-level project of the OBC SDK so that it will be automatically built by CMake when you trigger one of the OBC SDK build targets. To do that, open <code>espft/CMakeLists.txt</code> file and add the following lines somewhere before the <code>target_link_libraries</code> call:</li> </ul> <pre><code>add_subdirectory(core/services/telemetry telemetry)\nlist(APPEND libs telemetry)\n</code></pre> <p>Note</p> <p>Line <code>1</code> enlists your component to the build chain of CMake while line <code>2</code> puts a global dependency to the <code>telemetry</code> static library to the list of libraries built in the OBC SDK.</p> <ol> <li> <p>It is highly recommended to use lowercase for naming your components especially if you are working with your SDK project under different platforms (Windows, Linux, MacOS).\u00a0\u21a9</p> </li> <li> <p>Make sure that you follow the special comment blocks in <code>FP_TelemetryServerApp.c</code> which indicate where user changes can be performed in order to preserve your changes later after generating the code again.\u00a0\u21a9</p> </li> </ol>"},{"location":"devguide/devguide_operations_guide.html","title":"Introduction","text":"<p>After deployment, each spacecraft passes through different mission stages. In each of these the operator may need to use a different strategy for handling the spacecraft, such as resorting to using low-level APIs, using onboard services or both. This handling is known throughtout this page as Operations. For the purpose of this guide, spacecraft operations are split into:</p> <ul> <li>Commissioning - initially, the user (operator) will send many different commands to assess the spacecraft health and performance, and to perform commissioning procedures. To achieve this, the user will use mostly low-level direct commanding and less onboard services</li> <li>Nominal Flight - the user will reside to using mostly onboard services</li> <li>Contingency - the user may need to use any command, regardless if part of an onboard service or low-level interface</li> </ul> <p>In the SDK, Operations are achieved through the combination of the Concept of Operations, User Payloads, AOCS control service, Payload Scheduler and any of the ADCS services (such as the CubeADCS Gen2 Service).</p> <p>Note</p> <p>The guide assumes that a CubeSpace's Gen2 ADCS solution is part of the spacecraft. However, the presented solution is agnostic to the used ADCS hardware.</p>"},{"location":"devguide/devguide_operations_guide.html#operations","title":"Operations","text":"<p>The following figure gives an overview of the different components and players involved in Operations and highlight how they interact among each other.</p> <p></p>"},{"location":"devguide/devguide_operations_guide.html#1-commanding-the-gen2-module-using-cubespaces-apis","title":"(1.) Commanding the Gen2 module using CubeSpace's APIs","text":"<p>The full API of the Gen2 is exposed to the operator through a group of FIDL files, as described in the CubeADCS Gen2 Service.</p> <ul> <li>During commissioning many different commands will have to be sent to the ADCS. These include changing the used estimation mode, control mode, enabling nodes, changing configurations, etc.</li> <li>During nominal operations, it is likely that direct API commands will not be used since most of the interaction with the ADCS is taken up by the services.</li> <li>If a contingency has to be executed, the operator may need to reside to using use service or API command</li> </ul>"},{"location":"devguide/devguide_operations_guide.html#2-using-the-gen2-service-through-the-service-fidl","title":"(2.) Using the Gen2 service through the service FIDL","text":"<p>This use-case revolves around the use of the <code>&lt;OBC SDK&gt;/espf/core/fidl/obc/fp/OBC_CUBEADCS_GEN2.fidl</code> interface. Typically, the operator will use it during commissioning:</p> <ul> <li>Fetch the ADCS Operational State as a quick way to assess the health status of the ADCS</li> <li>To perform file transfers to/from the ADCS</li> <li>To update the commissioning status, once commissioning has been completed (this commissiong status is used by the ConOps)</li> </ul> <p>During nominal operations, the operator typically will use it:</p> <ul> <li>To perform file transfers to/from the ADCS</li> <li>To configure the downloadable telemetry or the AOCS State</li> <li>To check the operation of the Gen2 Service FDIR</li> <li>To perform a soft/hard reset of the ADCS.</li> <li>To put the ADCS in bootloader or application mode</li> </ul> <p>During contingecny, this interface can be used:</p> <ul> <li>To upload a new FW image</li> <li>To download telemetry</li> </ul>"},{"location":"devguide/devguide_operations_guide.html#3-commanding-via-aocs_cntrl-fidl","title":"(3.) Commanding via aocs_cntrl FIDL","text":"<p>This interface (<code>&lt;OBC SDK&gt;/espf/core/fidl/obc/fp/OBC_AOCS_CNTRL.fidl</code>) has two relevant methods used to perform high level control of the ADCS during nominal operations. These are:</p> <ul> <li> <p><code>OBC_AOCS_CNTRL.fidl::setAocsState</code> - As the name suggests, this method can be used by the operator to set the AOCS State. Under the hood, the logic which sets the AOCS State is the same one used internally (by the ConOps, Payload Controller, etc.). Typically, this call will be used:</p> <ul> <li>During AIT/mission planning, etc., when performing HIL simulations</li> <li>After reset, to set the satellite under preferred control in order to request change to ConOps IDLE mode</li> <li>To manually change the AOCS State at any moment</li> </ul> </li> <li> <p><code>OBC_AOCS_CNTRL.fidl::getAocsState</code> - It can be used to read the currently set AOCS State</p> </li> </ul> <p>Note</p> <p>The interface contains many other methods. These are used to configure the AOCS performance monitor.</p>"},{"location":"devguide/devguide_operations_guide.html#4-commanding-the-conops-using-the-conops-fidl","title":"(4.) Commanding the ConOps using the ConOps FIDL","text":"<p>In the context of operations, this interface is typically used during nominal flight:</p> <ul> <li>After commissioning and each time the ConOps is in SAFE mode, to switch from SAFE mode to IDLE mode.</li> <li>To check the current ConOps mode. </li> <li>During AIT/mission planning, etc. when performing HIL simulations as it allows to directly enable/disable payload modes.</li> </ul> <p>Most of the methods described in <code>&lt;OBC SDK&gt;/espf/core/fidl/obc/fp/ConOps.fidl</code> are documented in ConOps mode.</p>"},{"location":"devguide/devguide_operations_guide.html#5-updateupload-on-board-schedule-using-file-upload-procedure","title":"(5.) Update/Upload on-board schedule using file upload procedure","text":"<p>The only use-case to update/upload on-board schedule files is during nominal operations (be this in-orbit or during simulations on the ground). Refer to Payload Scheduler for further information on how to use the payload scheduler.</p>"},{"location":"devguide/devguide_operations_guide.html#6-trigger-payload_ctrl","title":"(6.) Trigger payload_ctrl","text":"<p>This use-case is not directly accessible to the user, but is the result of user interaction with the Payload Scheduler. The latter uses the Concept of Operations public interface <code>&lt;OBC SDK&gt;/espf/app/conops/conops.h</code> to request the activation/deactivation of the PAYLOAD mode.</p>"},{"location":"devguide/devguide_operations_guide.html#7-request-aocs-state-commissioning-status-etc","title":"(7.) Request AOCS state, commissioning status, etc.","text":"<p>The ConOps makes regular request to the AOCS Control service to fetch the AOCS State, commissioning status, etc. It does this to evaluate guard conditions or to make a switch to a new ConOps mode. Each time it does this, it uses the following public interface <code>&lt;OBC SDK&gt;/espf/core/services/aocs/aocs_cntrl/inc/aocs_cntrl.h</code>.</p>"},{"location":"devguide/devguide_operations_guide.html#8-request-payload-logic-aocs-state-and-parameters","title":"(8.) Request payload logic, AOCS state and parameters","text":"<p>Once the ConOps is in PAYLOAD mode, it will request the activation of specific logic and will present this logic with user-defined information. This request is performed through the public interface <code>&lt;OBC SDK&gt;/espf/core/services/payload_ctrl/inc/payload_ctrl.h</code>.</p>"},{"location":"devguide/devguide_operations_guide.html#9-receive-notifications-from-payload-logic","title":"(9.) Receive notifications from payload logic","text":"<p>In PAYLOAD mode, the ConOps state machine periodically checks if an error has occurred with the payload (and ADCS for that matter). To this end, the ConOps is subscribed to events generated by the Payload Controller, through the public interface <code>&lt;OBC SDK&gt;/espf/core/services/payload_ctrl/inc/payload_ctrl.h</code>.</p>"},{"location":"devguide/devguide_operations_guide.html#10-trigger-and-monitor-aocs-pointing","title":"(10.) Trigger and monitor AOCS pointing","text":"<p>Prior to activating a payload logic, the Payload Controller makes an AOCS State request to AOCS Control using the public interface <code>&lt;OBC SDK&gt;/espf/core/services/aocs/aocs_cntrl/inc/aocs_cntrl.h</code>. The Payload Controller then regularly checks the status of the made request through the <code>&lt;OBC SDK&gt;/espf/core/services/aocs/aocs_cntrl/inc/aocs_cntrl_feedback.h</code> interface. It does this for the user-defined time located in the Payload Scheduler file.</p>"},{"location":"devguide/devguide_operations_guide.html#summary","title":"Summary","text":"<p>A summary of the described use-cases and their usage throughout operations. The table legend can be summarized as:</p> <ul> <li><code>-</code> indicates that the use-case may be used</li> <li> indicates that the use-case is most likely not used</li> <li> indicates that the use-case is definitely used</li> </ul> Use-Case  Used During Commissioning Nominal Contingency 1. Commanding the Gen2 module using CubeSpace's APIs <code>-</code> 2. Commanding the Gen2 service using service FIDL <code>-</code> 3. Commanding via aocs_cntrl FIDL <code>-</code> 4. Commanding the ConOps using the ConOps FIDL <code>-</code> 5. Update/Upload on-board schedule using file upload procedure 6. Trigger payload_ctrl 7. Request AOCS state, commissioning status, etc. 8. Request payload logic, AOCS state and parameters 9. Receive notifications from payload logic 10. Trigger and monitor AOCS pointing"},{"location":"devguide/devguide_payload_scheduler.html","title":"Introduction","text":"<p>The Payload Scheduler is a simple, time-based, on-board scheduler, used to trigger payload operations. It uses a binary file (called the payload scheduler file) as the input and operates by comparing the information in this file to the on-board UNIX time every second.</p>"},{"location":"devguide/devguide_payload_scheduler.html#structure-of-the-payload-scheduler-file","title":"Structure of the Payload Scheduler File","text":"<p>The payload schedule file is a binary file containing 40 slots, each one containing 41 bytes of information, necessary for the correct operation of the payload. The structure of the payload scheduler file is depicted in the following figure:</p> <p></p> <p>where, each slot contains the following fields:</p> <ul> <li>payload ID \u2013 payload identifier as defined in <code>&lt;OBC SDK&gt;/espf/config/payload_ctrl/payload_cfg_user.h</code></li> <li>flags - payload-specific flags interpreted by the payload logic. This is a user-defined field</li> <li>time - UNIX-timestamp specifying the start time of the payload</li> <li>duration - time, in seconds, indicating the duration of the payload mode. Once this time elapses, the payload mode is left</li> <li>payload boot time - time, in seconds, used to start the payload ahead of the time parameter. Typically used to reflect the payload boot/initialisation time</li> <li>adcs prep time \u2013 time, in seconds, during which the Payload Controller listens for feedback from the AOCS control service on the successful execution of the requested AOCS State. If this time elapses, the ConOps PAYLOAD mode is left. Note that the payload (logic) will be activated only if the AOCS State request was successful</li> <li>adcs system state \u2013 this is the AOCS State as defined in the AOCS control service</li> <li>adcs manoeuvre params \u2013 parameters passed to the AOCS control service. These can be target coordinates, Roll-Pitch-Yaw angles, etc. encoded as three float (32-bit) values</li> <li>payload arguments - these are payload-specific parameters interpreted by the payload logic. It is a user-defined field - could be file name which contains payload specific instructions, flags, etc.</li> </ul> <p>Note</p> <p>Some fields in the Scheduler File figure are presented in a human-readable form intentionally</p>"},{"location":"devguide/devguide_payload_scheduler.html#related-commands","title":"Related Commands","text":"<p>The Payload Scheduler shares the same interface with the Concept of Operations. The two methods in <code>&lt;OBC SDK&gt;/espf/core/fidl/obc/fp/ConOps.fidl</code> related to the use of the Payload Scheduler are:</p> <ul> <li><code>ConOps.fidl::addNewScheduleRecord</code>, which can be used to add a new entry to the first empty slot. An empty slot has a payload ID of 255(DEC). Once a slot has been executed, it is invalidated by the Payload Schduler by writing the empty slot payload ID value.</li> <li><code>ConOps.fidl::clearScheduleRecords</code>, which clears all scheduled entries</li> </ul>"},{"location":"devguide/devguide_payload_scheduler.html#uploading-a-payload-scheduler-file","title":"Uploading a Payload Scheduler File","text":"<p>The Payload Scheduler File update logic relies on the Firmware Update Protocol and follows the same logic as does a normal firmware update. The difference between a firmware update binary and the payload schedule binary is in the information used to create the binary bundle.</p>"},{"location":"devguide/devguide_payload_scheduler.html#creating-the-bundle","title":"Creating the bundle","text":"<p>The bundle can be created using macaron (<code>&lt;OBC SDK&gt;/build/macaron.py</code>). The command line is:</p> <pre><code>python macaron.py --create-schedule-bundle ../other/tools/schedule.bin\n</code></pre> <p>The tool will take care of encoding the necessary information for the correct interpretation of the file by the OBC.</p>"},{"location":"devguide/devguide_payload_scheduler.html#uploading-the-bundle-to-the-obc","title":"Uploading the bundle to the OBC","text":"<p>To upload the created schedule file bundle, the following command line is used:</p> <pre><code>python macaron.py --upload-bun-file schedule.bin.bun --dongle-port &lt;your dongle com port id&gt; --obc-mac-addr &lt;OBC ESPS MAC address&gt;\n</code></pre> <p>Once the bundle is uploaded, it is unpacked and the new schedule file replaces the old one. This means that any slot from the old file not executed prior to the upload of the new file is lost!</p> <p>Warning</p> <p>The Firmware Update Protocol takes care of the reliable upload of the payload scheduler file and will report success once the file has been uploaded successfully. However, the process of replacement of the old scheduler file may fail and this will not be reported by the update procedure. Therefore, the user should check the uploaded file to make sure that the schedule was updated successfully.</p>"},{"location":"devguide/devguide_pm.html","title":"Performance monitor","text":""},{"location":"devguide/devguide_pm.html#overview","title":"Overview","text":"<p>The Performance monitor is a sub-function of the AOCS service, and it is composed of the files listed below. It has the task to analyze a user-specified telemetry (Attitude angles, rates, estimator convergence parameters, temperature...), and give metrics that encode the behavior of said telemetry. The utility of this sub-function is the ability to gain an averaged estimate of the behavior of the telemetry of interest over a long and short time span, without needing to download telemetry logs to the ground.</p> <ul> <li>espf\\core\\services\\aocs\\aocs_cntrl\\src\\aocs_pm.c</li> <li>espf\\core\\services\\aocs\\aocs_cntrl\\inc\\aocs_pm.h</li> <li>espf\\core\\services\\aocs\\aocs_cntrl\\inc\\aocs_pm_types.h</li> <li>espf\\config\\aocs\\aocs_cntrl\\aocs_pm_cfg.h</li> </ul> <p>Info</p> <p>Currently the PM is integrated with CubeAdcs gen 1 but will be extended to all supported hardware (CubeAdcs gen 2, ES ADCS ).</p>"},{"location":"devguide/devguide_pm.html#evaluation-of-data","title":"Evaluation of data","text":"<p>The PM works by storing the measurements of a given variable over the last 128 minutes in a FIFO buffer. On each execution, the PM evaluates two metrics:</p> <ul> <li>a long-term (128 min) performance metric.</li> <li>a short-term (8 minute) one.</li> </ul> <p>The evaluation of the metrics is done by comparing the value of the variable against a reference value (referred to as an offset), with a configurable allowable range around the reference (called threshold values). The threshold values have a user configurable safety factor associated with them, which functions as a hysteresis around the threshold (it is expressed as a percentage value of the threshold value).</p> <p>The definition of the long-term metric is: The fractional time (of 128 minutes) that the variable in question has remained within the given threshold levels around the reference value, for at least 8 minutes. The PM outputs this value as a percentage.</p> \\[ \\operatorname{long-term metric} = \\dfrac{s}{T} * 100 \\] <p>Where: T - period of 128 minutes; s - time that the variable stayed within the allowable range for at least 8 minutes, it is calculated as follows:</p> <p>Let \\(t_0\\) be the time that the variable enters the allowable range, then at any time \\(t&gt;t_0\\)     \\begin{equation}         s = \\begin{cases} &amp;0,\\quad \\text{if}\\quad t - t_0 &lt; 8 \\min\\\\ &amp;t - t_0 - 8 \\min,\\quad \\text{if} \\quad t-t_0 &gt; 8\\min         \\end{cases}     \\end{equation}</p> <p>To complement the long-term metric, the short-term metric utilizes the FIFO buffer to give an averaged \"history\" of the variable in question. The 128 minute interval is split into 16 sub-intervals of 8 minutes each (referred to as short-term metrics). The PM will output a uint16 number, where each bit represents whether the variable in question has continuously remained within the threshold levels around the offset for the duration of the last sub-interval (8 minutes) corresponding to the bit.</p> <p>In the diagram below there is an example of monitoring the Roll angle. The sub-intervals of 8 minutes are separated with black lines, for the first part of the diagram the encoded value will be b0011111111011111, the vertical red lines indicate separate long-term periods.</p> <p></p> <p>The upper and lower thresholds have a hysteresis associated with them, in order to prevent \"noise\" in the PM output, when the monitored variable oscillates around their value. It is controlled via the \"safety factor\" variable, which is represented as a fraction of the user-specified threshold value. </p> <p>This effectively modifies the threshold levels as: \\(T \\rightarrow T_{u / l} = \\alpha_{u / l}  T\\), where \\(T\\) is the user-specified threshold value and \\(\\alpha_{u/l}\\) are two coefficients, which are initialized to 1. The labels \\(u / l\\) stand for the \"upper\" and \"lower\" thresholds. Then at any point in time after initialization, the value of \\(\\alpha_{u/l}\\) is calculated as follows (let \\(x\\) be the variable being monitored):</p> \\[\\begin{equation}     \\alpha_u = \\begin{cases} &amp;1 - \\text{safety},\\quad \\text{if}\\quad x &gt; \\text{offset} + \\alpha_u T\\\\ &amp;1 + \\text{safety},\\quad \\text{if}\\quad x &lt; \\text{offset} + \\alpha_u T\\\\     \\end{cases} \\end{equation}\\] \\[\\begin{equation}     \\alpha_l = \\begin{cases} &amp;1 - \\text{safety},\\quad \\text{if}\\quad x &lt; \\text{offset} + \\alpha_l T\\\\ &amp;1 + \\text{safety},\\quad \\text{if}\\quad x &gt; \\text{offset} + \\alpha_l T\\\\     \\end{cases} \\end{equation}\\]"},{"location":"devguide/devguide_pm.html#logging-capability","title":"Logging capability","text":"<p>The PM is designed to facilitate the logging of monitored parameters and the collection of critical metrics, which serve as invaluable tools for gaining insights into the operational status of your ADCS system. Whenever the ADCS engages in target tracking, an automatic logging process is initiated (this feature is inherently enabled and cannot be deactivated or turned off). This is done to ensure thorough monitoring of ADCS activities during target tracking, as it is imperative to closely observe its operations during this phase. Manually initiating the logging process is straightforward; you simply need to execute the <code>OBC_AOCS_CNTRL.fidl::startLogging</code> command from the <code>core/fidl/obc/fp/OBC_AOCS_CNTRL.fidl</code> interface. Specify the desired duration for logging in seconds, and the system will proceed accordingly. After this period, you will find a file named <code>/sd/AOCS_PM.TXT</code> on the OBC's SD card, containing the logged data. The file contains data organized in columns, and these columns are separated by commas. The fields within these columns include the following information:</p> <ul> <li>Unix timestamp - timestamp</li> <li>dT - sample rate in seconds</li> </ul> <p>The subsequent fields are replicated three times for each variable</p> <ul> <li>Short-term metric - this metric serves as an indicator of data stability for the current sample. A value of <code>1</code> denotes acceptable performance, based on the user-configured offsets and thresholds, while <code>0</code> signifies unacceptable performance</li> <li>Data - the specific values that are being monitored and observed as part of the process</li> <li>Long-term metric - the fractional time (of 128 minutes) that the variable in question has remained within the given threshold levels given in percentage</li> <li>Encoded history - 16-bit number, where each bit represents the short-term metric</li> <li>Offset - this is the reference value that the actual value is compared to</li> <li>Stable time - stable uninterrupted time that the parameter is within the thresholds, measured in seconds</li> </ul> <p>Here is an example of how the file looks:</p> <pre><code>date, time, dt,short term metric, data, long term metric, enc history, offset, stable time,short term metric, data, long term metric, enc history, offset, stable time,short term metric, data, long term metric, enc history, offset, stable time \n946686685,4.2,0,9.17,0,0,0,0,0,-0.34,0,0,0,4,0,-0.15,0,0,0,4,\n946686698,3.84,0,9.06,0,0,0,0,0,0.11,0,0,0,8,0,-0.08,0,0,0,8,\n946686711,3.95,0,8.81,0,0,0,0,0,2.06,0,0,0,12,0,0.15,0,0,0,12,\n946686724,4.13,0,8.69,0,0,0,0,0,3.58,0,0,0,16,0,0.34,0,0,0,16,\n</code></pre> <p>Warning</p> <p>The date and time cells in the header should be merged that way they will correspond to the unix timestamp field!</p> <p>Note</p> <p>When initiating a new logging session, the PM appends the data to the already existing file, this is done to ensure that no data is lost.</p> <p>A safety feature has been implemented to restrict the maximum logging time, and this can be customized using the command <code>OBC_AOCS_CNTRL.fidl::setMaxTimeForAutoLogging</code>. Once this predefined time duration elapses, automatic logging will cease, unless manually started or if the satellite initiates target tracking.</p> <p>Note</p> <p>The presence of the value 123456.98 in the data field within the log indicates a communication disruption, signifying that the PM did not receive valid data at that point.</p>"},{"location":"devguide/devguide_pm.html#data-types-offset-and-skipping-samples","title":"Data types, offset and skipping samples","text":"<p>Types of the data the PM can monitor:</p> <ul> <li>EST_ATT_ANGL - estimated attitude angles</li> <li>EST_ANG_RATES - estimated angular rates</li> <li>MEAS_MAG_FIELD_VEC - measured magnetic field vector</li> <li>EST_INNOVATION_VEC - estimated innovation matrix</li> <li>Q_ERR_VEC - quaternion error vector  </li> <li>MAG_MCU_TEMP - magnetometer and MCU temperature</li> <li>RATE_SENS_TEMP - rate sensor temperature</li> <li>RATE_CONVERGENCE - rate convergence</li> </ul> <p>What type of data is monitored can be changed with the command <code>OBC_AOCS_CNTRL.fidl::setDataTypeForAssessment</code>.</p> <p>Warning</p> <p>Changing the monitored type resets the statistics accumulated by the PM.</p> <p>Note</p> <p>During the monitoring of Estimated Attitude Angles, the PM is designed to identify the commanded attitude angles and employ them as reference values (offsets).</p> <p>Note</p> <p>When monitoring Estimated angular rates and the system state of the ADCS is either <code>AOCS_CNTRL_SYS_STATE_Y_THOMSON_MEMS_RATE</code> or <code>AOCS_CNTRL_SYS_STATE_Y_THOMSON</code> there is a constant offset of 1 deg/sec on the Y-axes (Y-Thomson algorithm is a detumbling procedure that initializes the satellite to spin at a constant rate of 1 deg/per second specifically along the Y-axis).</p> <p>The monitor incorporates a built-in functionality to skip data samples during satellite maneuvers or when unreliable data is received. Sample skipping repeats the most recent data point. The quantity of samples to be skipped can be configured using the command <code>OBC_AOCS_CNTRL.fidl::setSamplesToSkip</code>.</p>"},{"location":"devguide/devguide_pm.html#configuration","title":"Configuration","text":"<p>The interface file <code>OBC_AOCS_CNTRL.fidl</code> serves as the means to interact with the PM. It enables both the reading of output data and the configuration of various parameters. Additionally, it allows logging of specific PM algorithm data.</p> <p>For clarity, here is a summary of the commands that configure various parameters:</p> <ul> <li><code>OBC_AOCS_CNTRL.fidl::setMaxTimeForAutoLogging</code> - Configures the maximum logging time for automatic logging.</li> <li><code>OBC_AOCS_CNTRL.fidl::setSamplesToSkip</code> - Sets the number of samples to skip during maneuvers or when dealing with unreliable data.</li> <li><code>OBC_AOCS_CNTRL.fidl::setDataTypeForAssessment</code> - changes the type of data that is being monitored ( this will reset the statistics that the PM accumulates).</li> <li><code>OBC_AOCS_CNTRL.fidl::setThresholdLevels</code> - changes the allowable range around the reference.</li> <li><code>OBC_AOCS_CNTRL.fidl::setUpdateInterval</code> changes the sample rate in seconds.</li> </ul>"},{"location":"devguide/devguide_pm.html#monitoring-user-specified-parameters","title":"Monitoring user-specified parameters","text":"<p>To enable users to incorporate their own data types for monitoring, the initial step is to extend the enum for data types. Here's how you can do that:</p> <pre><code>typedef enum\n{\n    EST_ATT_ANGL,\n    EST_ANG_RATES,\n    MEAS_MAG_FIELD_VEC,\n    EST_INNOVATION_VEC,\n    Q_ERR_VEC,\n    MAG_MCU_TEMP,\n    RATE_SENS_TEMP,\n    RATE_CONVERGENCE,\n    USR_DATA\n}aocs_log_data_types_t;\n</code></pre> <p>Subsequently, you will need to develop custom logic for data retrieval. This can be accomplished by extending the switch case in the <code>espf/config/aocs/aocs_cntrl/aocs_cntrl_cubeadcs_int.c</code> file, specifically within the <code>aocs_cntrl_cubeadcs_int_get_log_data</code> function. Below is a concise example:</p> <pre><code>STATIC aocs_cntrl_res_t aocs_cntrl_cubeadcs_int_get_log_data(aocs_cntrl_log_data_t *p_log_data, aocs_log_data_types_t data_type, aocs_cntrl_offset_t* p_offset_values)\n{\n\n    DATA_CACHE_USER_DATA_t user_data;\n    DATA_CACHE_USER_DATA_t user_data_offset;\n\n    switch(data_type)\n    {\n        case USR_DATA:\n            dc_status = dc_get_user_data(&amp;user_data);\n\n            if(DC_DATA_STATUS_OK == dc_status)\n            {\n                p_log_data-&gt;value1 = (int32_t)user_data.value_1;\n                p_log_data-&gt;value2 = (int32_t)user_data.value_2;\n                p_log_data-&gt;value3 = (int32_t)user_data.value_3;\n                ret = AOCS_CNTRL_OK;\n\n                dc_status = DC_DATA_STATUS_TOUT;\n                dc_status = dc_get_user_data(&amp;user_data_offset);\n                // if you want to use data for reference value when evaluating if you don't have such a value just put 0 \n                if(DC_DATA_STATUS_OK == dc_status)\n                {\n                    p_offset_values-&gt;offset_value[0] = (int32_t)user_data_offset.value_1;\n                    p_offset_values-&gt;offset_value[1] = (int32_t)user_data_offset.value_2;\n                    p_offset_values-&gt;offset_value[2] = (int32_t)user_data_offset.value_3;\n                }\n                else if(DC_DATA_STATUS_TOUT == dc_status)\n                {\n                    ret = AOCS_CNTRL_FAILED;\n                }\n            }\n            else if(DC_DATA_STATUS_TOUT == dc_status)\n            {\n                ret = AOCS_CNTRL_FAILED;\n            }\n        break;\n        default:\n            ret = AOCS_CNTRL_FAILED;\n        break;\n    }\n}\n</code></pre> <p>Tip</p> <p>It would be easier if the data that you want to monitor is in the datacache, that way the implementation becomes much more straightforward.</p> <p>The final step in this process is to update the <code>OBC_AOCS_CNTRL.fidl</code> enumeration to include the new data type. This ensures that the user-defined data can be effectively interfaced with the PM.</p> <pre><code>enumeration logDataTypes\n{\n    EST_ATT_ANGL,\n    EST_ANG_RATES,\n    MEAS_MAG_FIELD_VEC,\n    EST_INNOVATION_VEC,\n    Q_ERR_VEC,\n    MAG_MCU_TEMP,\n    RATE_SENS_TEMP,\n    RATE_CONVERGENCE,\n    USR_DATA\n}\n</code></pre> <p>Note</p> <p>To monitor fewer than three values of a parameter in the PM, you should populate the empty slots in the /espf/config/aocs/aocs_cntrl/aocs_cntrl_cubeadcs_int.c file with dummy parameters, setting them to 0. This ensures that the PM operates correctly even when monitoring less than the full complement of parameters. We can revisit the example and make the necessary modifications to monitor only the first value. Here's how you can do it:</p> <pre><code>STATIC aocs_cntrl_res_t aocs_cntrl_cubeadcs_int_get_log_data(aocs_cntrl_log_data_t *p_log_data, aocs_log_data_types_t data_type, aocs_cntrl_offset_t* p_offset_values)\n{\n\n    DBG_ASSERT(NULL != p_log_data);\n    DBG_ASSERT(NULL != p_offset_values);\n\n    aocs_cntrl_res_t ret = AOCS_CNTRL_FAILED;\n    dc_data_status_t dc_status;\n    DATA_CACHE_USER_DATA_t user_data;\n    DATA_CACHE_USER_DATA_t user_data_offset;\n\n    switch(data_type)\n    {\n        case USR_DATA:\n            dc_status = dc_get_user_data(&amp;user_data);\n\n            if(DC_DATA_STATUS_OK == dc_status)\n            {\n                p_log_data-&gt;value1 = (int32_t)user_data.value_1;\n                p_log_data-&gt;value2 = (int32_t)0;\n                p_log_data-&gt;value3 = (int32_t)0;\n                ret = AOCS_CNTRL_OK;\n\n                dc_status = DC_DATA_STATUS_TOUT;\n                dc_status = dc_get_user_data(&amp;user_data_offset);\n                // if you want to use data for reference value when evaluating if you don't have such a value just put 0 \n                if(DC_DATA_STATUS_OK == dc_status)\n                {\n                    p_offset_values-&gt;offset_value[0] = (int32_t)user_data_offset.value_1;\n                    p_offset_values-&gt;offset_value[1] = (int32_t)0;\n                    p_offset_values-&gt;offset_value[2] = (int32_t)0;\n                }\n                else if(DC_DATA_STATUS_TOUT == dc_status)\n                {\n                    ret = AOCS_CNTRL_FAILED;\n                }\n            }\n            else if(DC_DATA_STATUS_TOUT == dc_status)\n            {\n                ret = AOCS_CNTRL_FAILED;\n            }\n        break;\n        default:\n            ret = AOCS_CNTRL_FAILED;\n        break;\n    }\n}\n</code></pre>"},{"location":"devguide/devguide_sysconfig.html","title":"Run-time Configuration","text":"<p>There are several HW modules in the OBC that are commonly found in the spacecraft system. In order to avoid rebuilding the system with different preprocessor directives for the different setups, the OBC SDK contains the runtime configuration. The OBC contains a description of the active configuration in a place in the memory and it will read it on startup and initialize only the modules that are active. After verifying that the configuration is valid.</p>"},{"location":"devguide/devguide_sysconfig.html#mcu-flash-layout","title":"MCU Flash Layout","text":"<p>The configuration is placed at the beggining of the last FLASH bank, which is the address <code>0x081C0000</code>.</p> <p></p> <p>Note</p> <p>The addresses for the Bootloader and for the Application are mentioned previously in Build configurations. This should not be modified.</p>"},{"location":"devguide/devguide_sysconfig.html#configuration-structure","title":"Configuration structure","text":"Field Bytes Description Signature 0-4 The string \"MCFG\\0\" Version 5-6 Version of the configuration format (MSB: major, LSB: minor version) Size 7-8 Size of the following data containing the module configuration (8 for this version) Modules 9-17 A byte per module, 0xFF is active, any other value is not active CRC 18-21 CRC-32 of all the previous bytes <p>The list of modules is as follows:</p> <ol> <li>EPS I: EnduroSat EPS I module</li> <li>EPS II: EnduroSat EPS II module</li> <li>EPS M: Third party EPS module</li> <li>ES ADCS: EnduroSat ADCS (integrated in the OBC)</li> <li>CubeADCS Gen1 module</li> <li>GNSS receiver</li> <li>S/X Band transmitter module</li> <li>Solar Panels (specific for the 6U)</li> <li>CubeADCS Gen2 module</li> </ol>"},{"location":"devguide/devguide_sysconfig.html#configuration-compatibility","title":"Configuration compatibility","text":"<p>There are some restrictions as to which modules can be active at the same time. The <code>sys_conf.c</code> module is verifying that the configuration is valid:</p> <ul> <li>The CRC of the whole data</li> <li>Signature is correct</li> <li>Version of the structure is compatible</li> <li>Active modules are compatible at a system level</li> </ul> <p>These are the restrictions that are expected to be fulfilled:</p> Restrictions At least one but only one EPS module should be active EnduroSat ADCS can only be active with the EPS I Only one ADCS module can be active at the same time <p>Important</p> <p>If any of the previous conditions is not fulfilled, the OBC will determine that the configuration is invalid and none of the modules will be considered active. None of the dependencies will be initialized (see the System Instancer).</p> <p>Important</p> <p>The OBC status LED is going to be blinking yellow instead of green if the binary configuration is not valid. All the modules that are described in the configuration won't be initialized.</p>"},{"location":"devguide/devguide_sysconfig.html#relevant-files-or-modules","title":"Relevant files or modules","text":"Name Description System Instancer Directly interacts with the system configuration to initialize the modules STM32H753IITx_FLASH_No_Bootloader.ld Description of the memory for 'NoBoot' configurations STM32H753IITx_FLASH.ld Description of the memory for configurations with the bootloader"},{"location":"devguide/devguide_sysconfig.html#es-sys-config-tool","title":"es-sys-config tool","text":"<p>The OBC SDK contains a tool developed in python to help operating with the OBC runtime configuration. Said tool requires the ST-Link and the STM32_Programmer_CLI to read, write or just generate a binary file with the runtime configuration contents as expected by the OBC.</p> <p>This tool is located in <code>other/scripts/sys_config_generation</code>. The tool can be run executing the sources or it can be packed and installed in the local python installation. It is a Command Line Interface (CLI).</p>"},{"location":"devguide/devguide_sysconfig.html#installation-as-a-python-module-in-the-local-python-installation","title":"Installation as a python module in the local python installation","text":"<p>The tool is ready to be installed as a library in a python distribution. In order to do this you would need to install the python module build. You can use <code>pip</code> for that:</p> <pre><code>python -m pip install build\n</code></pre> <p>Once this module is installed, you can generate the package by calling:</p> <pre><code>python -m build\n</code></pre> <p>This will generate the wheel package in a folder called <code>dist</code> that can be later installed with <code>pip</code>:</p> <pre><code>python -m pip install es-sys-config --find=dist/\n</code></pre> <p>Once it is installed, we can call the tool directly like:</p> <pre><code>&gt; es-sys-config --help\nUsage: es-sys-config [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --version  Show the application's version and exit.\n  --help     Show this message and exit.\n\nCommands:\n  flash\n  generate\n  read\n</code></pre> <p>Tip</p> <p> Situation</p> <ul> <li><code>es-sys-config</code> is not found as a command</li> </ul> <p> Hypothesis The folder <code>scripts</code> from your local python installation is not added to the PATH variable. If your python installation is in the folder <code>C:\\my\\python39\\</code>, you should add to the PATH system variable the folder <code>C:\\my\\python39\\Scripts\\</code>.</p> <p>If you have an older version of es-sys-config installed, you can upgrade it once you have the <code>dist</code> folder generated: <pre><code>python -m pip install es-sys-config --upgrade --find=dist/\n</code></pre></p>"},{"location":"devguide/devguide_sysconfig.html#run-the-python-sources-directly","title":"Run the python sources directly","text":"<p>Alternatively, the tool can be used by calling directly the source code. This will require to first install the python dependencies which are listed in the file <code>requiremetns.txt</code>.</p> <pre><code>python -m pip install -r requirements.txt\n</code></pre> <p>Once the python dependencies are installed, the tool can be called from the <code>sys_config_generation</code> folder:</p> <pre><code>python -m es_sys_config\n</code></pre> <p> Install the python dependencies and run locally</p>"},{"location":"devguide/devguide_sysconfig.html#example-of-usage","title":"Example of usage","text":"<p>In order to use the tool, you will need to setup the HW first. You can see how in the Connecting your OBC hardware section.</p> <p>Additionally to the hardware, you need to add to the system PATH variable the executable for the STM32_Programmer_CLI. In a typical installation it can be found in C:\\Program Files\\STMicroelectronics\\STM32Cube\\STM32CubeProgrammer\\bin\\STM32_Programmer_CLI.exe.</p> <p>Tip</p> <p>If you cannot or prefer to not add the STM32_Programmer_CLI.exe to the PATH, you could modify the python source to include the path to the STM32_Programmer_CLI.exe there. This should be done in the file <code>stm32_programmer_cli.py</code>, line 16: <pre><code># STM32_Programmer executable\nCLI_EXE = 'whole/path/to/STM32_Programmer_CLI'\n</code></pre></p> <p>Once that is done, the script can be called. There is the option to read the configuration from the OBC, as well as to save it in a binary file. You could just generate a new configuration file interactively (answering to what modules you want to configured in your setup). Or you could directly try to flash a new configuration, again, interactively or specifying a binary file already generated.</p> <p>The script will take care of verifying any incompatibilities with between the modules and a warning will be shown in the screen. Even if there is an incompatibility, the binary will be generated and flashed. If there is not a valid configuration, the system instancer will not initialize any of the modules included in the runtime configuration and the status LED will be blinking yellow instead of green.</p> <p>The flash and generate commands require you to specify the OBC SW version for which the configuration is intended. Please, make sure that you provide the correct version (e.g. 4.1.0), otherwise the system instancer will detect incompatibility and prevent all modules from initializing.</p> <p>Tip</p> <p> Situation</p> <p>If you see the following error: <pre><code>[WinError 2] The system cannot find the file specified\nI had a problem because I could not read from the device\n</code></pre> and you have added the <code>STM32_Programmer_CLI.exe</code> to the path.</p> <p> Hypothesis</p> <p>This error means that windows is not finding STM32_Programmer_CLI as a valid command to execute:</p> <ul> <li>Verify that the file is actually in the path you added to the Path system variable.</li> <li>Refresh the command window you are using to take in account the changes in the Path system variable.</li> <li>The windows configuration doesn't allow to call executables without using the <code>.exe</code> extension. You can modify the python source to include the extension in the file <code>stm32_programmer_cli.py</code>, line 16:</li> </ul> <p><pre><code># STM32_Programmer executable\nCLI_EXE = 'STM32_Programmer_CLI.exe'\n</code></pre> Once this changes are done, you can rebuild the python library as detailed in the above section Installation as a python module in the local python installation.</p>"},{"location":"devguide/devguide_telemetry.html","title":"Telemetry","text":"<p>The OBC SDK comes with a basic integrated telemetry mechanism. It consists of two main services:</p> <ul> <li>File telemetry service (managed by the <code>espf/core/services/telemetry</code> component);</li> <li>Radio telemetry service (managed by the <code>espf/core/services/beacons</code> component);</li> </ul> <p>The common thing between these two services is how they acquire data. They both source their data from the Data Cache.</p> <p>Tip</p> <p>If you are not yet familiar with how the Data Cache works, please read this chapter before you continue with telemetry.</p> <p>What is the benefit of using DC as the single source of data for telemetry? As a matter of fact, there are multiple benefits, some of them are:</p> <ul> <li>A unified mechanism for data collection which is easily extensible.</li> <li>Telemetry handling can be completely generic relying on standard interfaces which can also be simulated externally (thus telemetry is easily testable).</li> <li>Telemetry parsing on the ground segment can make use of the existing Python code generators available for FIDL interfaces (just because telemetry data is Data Cache data, and Data Cache data is already described via FIDL files).</li> <li>Any data stored in the Data Cache can be provided as telemetry on the ground via dynamic configuration.</li> <li>OBC SDK component developers do not need to take care of telemetry collection if they rely on the DC mechanism - the data they produce is already part of the telemetry even without them knowing.</li> </ul> <p></p>"},{"location":"devguide/devguide_telemetry.html#file-telemetry-service","title":"File Telemetry Service","text":""},{"location":"devguide/devguide_telemetry.html#telemetry-encoding-format","title":"Telemetry encoding format","text":"<p>The standard telemetry service implementation collects telemetry data as <code>telemetry messages</code>. A <code>telemetry message</code> directly maps to a DC <code>attribute</code>. When stored as a file, <code>telemetry messages</code> are aggregated in <code>telemetry frames</code> which provide additional context about the system at the moment when a <code>telemetry message</code> was sampled. A <code>telemetry frame</code> contains the following fields:</p> Unix timestamp Message rolling counter ConOps mode Message ID (maps to a DC <code>attribute</code>) Data status (from DC) Message length (in bytes) Message data CRC16 (over the entire frame)<sup>1</sup> 4 bytes 1 byte 1 byte 2 bytes 1 byte 2 bytes depends on previous field value 2 bytes <p><code>Telemetry frames</code> get stored in a file with a COBS<sup>2</sup>-encoding to enable unambiguous frame delimiting.</p> <p>Warn</p> <p>Frame compression is not supported at the moment of writing this guide. It will most probably be part of future releases of the OBC SDK.</p> <p>After the messages are COBS-encoded, they  saved in a file sequence on the OBC SD card. This file sequence represents a circular buffer. All files comprising the circular buffer have the same size. Each file part of the telemetry file sequence contains a header with the following fields: </p> <ul> <li><code>signature</code> - a hardcoded file signature to make it easier to visually identify the content type when using an ASCII editor; it it a zero-terminated ASCII string: \u201cESTLM\\0\u201d.</li> <li><code>version</code> - file format version hardcoded to 0x00000101 for the moment.</li> <li><code>next write offset</code> - this is the offset of the last write position, thus when the buffer is full and we start all over again we will only write over some of the already existing data. Some of the old data will be broken when partially or fully replaced by new data (because frames can differ in length) but COBS encoding allows us to properly handle the full frames remaining in the file. The offset must be updated with each <code>telemetry frame</code> write.</li> <li><code>reserved</code> - some slack space reserved for future use.</li> <li><code>file complete</code> - a flag indicating that the file writing is fully complete because the file size limit has been reached (the flag is always <code>false</code> for newly created telemetry files or in case the file is opened again for writing after a circular buffer roll-over to the beginning;</li> <li><code>CRC16</code> - Calculated over the header. If not valid for some reason, writing in the file starts from the beginning and the header gets replaced by a valid one.</li> </ul>"},{"location":"devguide/devguide_telemetry.html#telemetry-file-configuration","title":"Telemetry file configuration","text":"<p>The behavior of the telemetry file collection can be configured via ESPS I FP commands. For details on the configuration, please check the method description in <code>&lt;OBC SDK/espf/core/fidl/obc/fp/Telemetry.fidl</code>. The default telemetry configuration is available in <code>&lt;OBC SDK&gt;/espf/config/nvm_appcfg/inc/nvm_app_defs.inc</code> (search for <code>NVM_BLOCK_DEFAULTS_START(telemetry_preset_cfg, telemetry_preset_cfg_t)</code>). You can modify the default configuration as per your needs but it can easily be changed later using the provided FIDL interface. The configuration is persisted in the OBC on-board FRAM. Additional build time configuration parameters can be edited in <code>&lt;OBC SDK&gt;/espf/config/telemetry/telemetry_cfg_user.h</code>. The telemetry service can be switched on or off at build time via the CMake <code>TELEMETRY_ENABLED</code> build option. Refer to the descriptions in <code>&lt;OBC SDK&gt;/build/CMakeLists.txt</code> file.</p>"},{"location":"devguide/devguide_telemetry.html#telemetry-files-on-the-obc-sd-card","title":"Telemetry files on the OBC SD card","text":"<p>When the telemetry service is activated, it will operate according to its configuration. If everything is fine and the OBC SD card is operational, telemetry files will by default be stored in the root folder following this <code>printf</code> name pattern: <code>%05d.TLM</code>:</p> <ul> <li><code>00000.TLM</code></li> <li><code>00001.TLM</code></li> <li><code>00002.TLM</code></li> <li>...</li> </ul>"},{"location":"devguide/devguide_telemetry.html#radio-telemetry-service","title":"Radio Telemetry Service","text":""},{"location":"devguide/devguide_telemetry.html#radio-encoding-format","title":"Radio encoding format","text":"<p>The beacons service shipped with the OBC SDK supports beacon frames encoding suitable for the EnduroSat UHF transceiver module. Each beacon frame has a maximum length of <code>77</code> bytes, which after encoding in AX.25 ends up with a maximum length of 128 bytes (a limit imposed by the used radio IC in the UHF module).</p> <p>A <code>beacon frame</code> contains the following fields:</p> <ul> <li><code>Beacon Consecutive Number</code> - used by the ground segment to detect missing frames (this is just a rolling frame counter).</li> <li><code>OBC Operational Mode</code> - ID of the current operational mode of the OBC.</li> <li><code>Reserved</code> - It equalizes the beacon message size with the expected beacon message size transmitted by the UHF. Reserved for future use. Currently only the LS bit is used to denote whether beacon data is split over multiple <code>beacon frames</code>.</li> <li> <p><code>Beacon Message</code> - this field contains the following data:</p> <ul> <li><code>Beacon Type ID</code> - A unique data identifier</li> <li><code>Beacon Type Length</code> - The length of the beacon data in bytes</li> <li><code>Beacon Type Data</code> - The actual beacon data</li> </ul> </li> </ul> <p>Note</p> <p>Similar to the Telemetry collection service, all <code>beacon types</code> map directly to DC <code>attributes</code>.</p> <p></p> <p><code>Beacon frames</code> are transmitted in <code>bursts</code>, with the minimum burst containing a single beacon frame. Here is how beacon transmission happens:</p> <p></p> <p>Tip</p> <p><code>bcn_tx_period</code> and <code>bcn_inter_frame_period</code> are configuration parameters which can be altered via the provided <code>&lt;OBC SDK&gt;/espf/core/fidl/obc/fp/Beacons.fidl</code> interface.</p>"},{"location":"devguide/devguide_telemetry.html#beacon-frames-assembly","title":"Beacon frames assembly","text":"<p>Beacon frames get their data from DC <code>attributes</code>. The beacons service supports data segmentation or in other words if a beacon message cannot fit in the remaining beacon frame space, it can be split to continue in the next beacon frame. Assembly is then performed on the ground segment. Here is how such splitting looks like: </p> <p>Example</p> <p>We are transferring a beacon message of <code>100</code> bytes which cannot fit in a single beacon frame. We have only <code>72</code> bytes in the beacon frame available for data. <code>4</code> bytes are occupied by the beacon message header, therefore we can provide only <code>68</code> bytes in the first chunk. The length field of the first chunk, however, shall indicate <code>100</code> bytes because this is the actual number of data bytes remaining to be transferred. The subsequent chunk has to provide the remaining (100 - 68) = <code>32</code> bytes, hence its length shall indicate <code>32</code>.</p>"},{"location":"devguide/devguide_telemetry.html#radio-beacons-configuration","title":"Radio beacons configuration","text":"<p>The behavior of the beacons telemetry can be configured via ESPS I FP commands. For details on the configuration, please check the method descriptions in <code>&lt;OBC SDK/espf/core/fidl/obc/fp/Beacons.fidl</code>. The default beacons configuration is available in <code>&lt;OBC SDK&gt;/espf/config/nvm_appcfg/inc/nvm_app_defs.inc</code> (search for <code>NVM_BLOCK_DEFAULTS_START(beacons_presets_cfg, beacons_presets_cfg_t)</code>). You can modify the default configuration as per your needs but it can easily be changed later using the provided FIDL interface. The configuration is persisted in the OBC on-board FRAM. Additional build time configuration parameters can be edited in <code>&lt;OBC SDK&gt;/espf/config/beacons/beacons_cfg_user.h</code>. The beacons service can be switched on or off at build time via the CMake <code>BEACONS_ENABLED</code> build option. Refer to the descriptions in <code>&lt;OBC SDK&gt;/build/CMakeLists.txt</code> file. When started, the beacons service will emit beacon frames to the UHF via the <code>&lt;OBC SDK&gt;/espf/core/fidl/uhf/fp/UHF2.fidl</code> API. No feedback is expected from the UHF as frame transmission is not replied to from the ground segment.</p> <ol> <li> <p>The parameters of the CRC16 algorithm used are: initial seed = 0xFFFF / polynomial = 0x1021 or 0x8408 reversed.\u00a0\u21a9</p> </li> <li> <p>Constant Overhead Byte Stuffing - implemented in <code>&lt;OBC SDK&gt;/espf/core/lib/libcobs</code>.\u00a0\u21a9</p> </li> </ol>"},{"location":"devguide/devguide_user_payloads.html","title":"User Payloads","text":"<p>The Payload Modes of the ConOps is responsible to manage the correct activation, control and deactivation of the integrated payloads.</p> <p>The SW modules orchestrating the payloads are listed below:</p> <ul> <li> <p><code>payload_scheduler</code> (espf/core/services/payload_scheduler)</p> <ul> <li>Responsible for the activation of time-based schedule entries by taking into account the given payload boot time and also ADCS pointing time. This means, your payload will be activated a bit earlier so that actual operation can start as soon as the specified schedule time ticks in. The <code>payload_scheduler</code> does not start the payload on its own. It just notifies the <code>conops</code> module that there is a payload ready for activation.</li> </ul> </li> <li> <p><code>conops</code> (espf/app/conops)</p> <ul> <li>Responsible for handling the OBC operational states. If the OBC resides in the <code>Idle</code> state and the <code>payload_scheduler</code> requests a payload activation, <code>conops</code> will check if the operating conditions allow this activation and will trigger or reject the operation accordingly. Activating the payload is requested from the <code>payload_ctrl</code> module (see below for details).</li> </ul> </li> <li> <p><code>payload_ctrl</code> (espf/core/services/payload_ctrl)</p> <ul> <li>Handles the communication with the individual payloads in the system through a unified interface defined in  the <code>if_payload_control.h</code> header. Every payload integrated in the system must implement this interface so that it can be controlled by the mechanism described here. <code>payload_ctrl</code> will also make sure the correct AOCS pointing is established before starting the payload. If multiple payloads should be started at the same time or in overlapping time intervals, it is possible, provided they share the same ADCS pointing requirements. Otherwise, only the first payload will start and the rest of the payload activations will be ignored unless scheduled again at a later time by themselves or along with other payloads sharing the same pointing mode parameters.</li> </ul> </li> <li> <p><code>aocs</code> (espf/core/services/aocs)</p> <ul> <li>Controls the satellite pointing.</li> </ul> </li> <li> <p><code>user_payload_1</code> \u2026 <code>user_payload_n</code></p> <ul> <li>These SW modules are responsible to handle the life cycle of the individual payloads. All of them shall implement the <code>if_payload_control.h</code> interface. A payload SW module usually controls a HW device to enable operation from the ground but in fact, it could provide any implementation which you want to be able to execute through the on-board scheduling mechanism. The payload start interface is very generic and can be used to execute simple commands implemented by your payload as well as provision your payload with operational data residing in a file which has been uploaded to the satellite before running the schedule. The format of the file is payload-specific and it is a responsibility of the payload implementation to interpret the file and perform action based on its content.</li> </ul> </li> </ul> <p>Tip</p> <p>You can use <code>payload_dummy.c</code> and <code>payload_dummy.h</code> files located in the <code>espf/core/services/payload_ctrl/src</code> folder as a starting template for your new payload implementation.</p> <p></p> <p>Here is the basic sequence followed when a new schedule file is uploaded and executed:</p> <p></p>"},{"location":"devguide/devguide_user_payloads.html#implement-a-thruster-payload-handler","title":"Implement a thruster payload handler","text":"<p>Now let's take a short example on how to extend the payload control mechanism to handle an imaginary thruster payload. For brevity we will use the name <code>THR</code> below when naming different files and folders.</p> <p>The general steps are:</p> <ol> <li> <p>Create a folder for your new payload implementation in the OBC SDK project (let's put this under <code>espf/core/services/pl_thr</code>).</p> </li> <li> <p>Copy the dummy payload templates from <code>espf/core/services/payload_ctrl/src</code> to the newly created folder and rename them to <code>pl_thr.c</code> and <code>pl_thr.h</code> respectively.</p> </li> </ol> <p>Now let's take a quick look at the file content and focus on the important aspects of integrating our new payload.</p> pl_thr.h<pre><code>#ifndef PL_THR_H\n\n#define PL_THR_H\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif  // __cplusplus\n\n#include \"if_payload_control.h\"\n\nextern const pl_control_if_t pl_thr_if;\n\n#ifdef __cplusplus\n}\n#endif  // __cplusplus\n#endif // PL_THR_H\n</code></pre> <p>This header file exports the user payload interface instance at line <code>12</code>. This instance will then be referenced in the OBC payload configuration.</p> <p>pl_thr.c<pre><code>#include \"es_cdef.h\"\n#include \"if_payload_control.h\"\n\nstatic p_pl_event_notify_t p_event_cbk = (p_pl_event_notify_t) NULL;\nstatic pl_state_t current_state = PL_STATE_NOT_INIT;\n\nstatic inline void fire_event(const pl_instance_id_t instance_id, pl_state_t to_state)\n{\n    if (NULL != p_event_cbk)\n    {\n        p_event_cbk(instance_id, to_state);\n    }\n}\n\nstatic pl_op_status_t pl_thr_init(const pl_instance_id_t instance_id,\n                                      pl_config_t * const p_init_cfg,\n                                      const p_pl_event_notify_t p_event_notify_cb)\n{\n    (void) p_init_cfg;\n\n    current_state = PL_STATE_STOPPED;\n    p_event_cbk = p_event_notify_cb;\n\n    fire_event(instance_id, current_state);\n\n    return PL_OP_STATUS_OK;\n}\n\nstatic pl_op_status_t pl_thr_deinit(const pl_instance_id_t instance_id)\n{\n    current_state = PL_STATE_NOT_INIT;\n\n    fire_event(instance_id, current_state);\n\n    return PL_OP_STATUS_OK;\n}\n\nstatic pl_op_status_t pl_thr_start(const pl_instance_id_t instance_id, pl_config_t * const p_start_cfg)\n{\n    current_state = PL_STATE_STARTED;\n\n    fire_event(instance_id, current_state);\n\n    return PL_OP_STATUS_OK;\n}\n\nstatic pl_op_status_t pl_thr_stop(const pl_instance_id_t instance_id, const pl_op_stop_mode_t stop_mode)\n{\n    current_state = PL_STATE_STOPPED;\n\n    fire_event(instance_id, current_state);\n\n    return PL_OP_STATUS_OK;\n}\n\nstatic pl_state_t pl_thr_get_active_state(const pl_instance_id_t instance_id)\n{\n    return current_state;\n}\n\nstatic uint32_t pl_thr_get_last_error(const pl_instance_id_t instance_id)\n{\n    return 0;\n}\n\n// This is the Thruster payload interface which will be referenced by the\n// system payload configuration. Only this part of the payload implementation must\n// remain public.\nconst pl_control_if_t pl_thr_if =\n{\n    .init = pl_thr_init,\n    .deinit = pl_thr_deinit,\n    .start = pl_thr_start,\n    .stop = pl_thr_stop,\n    .get_state = pl_thr_get_active_state,\n    .get_last_error = pl_thr_get_last_error,\n};\n</code></pre> The <code>pl_thr.c</code> file currently contains a very basic user payload implementation:</p> <ul> <li>It tracks the payload state in relation to the control commands received through the <code>pl_thr_if</code> interface.</li> <li>It returns a default error status.</li> <li>It reports the correct internal state of the payload.</li> <li>It notifies the payload subsystem about state changes if a <code>p_event_notify_cb</code> callback was provided during initialization.</li> </ul> <p>Last but not least, we have to create a CMake file for our implementation and to extend the OBC SDK build to include our new module in the build process.</p> <p>Paste the following code in a <code>CMakeLists.txt</code> file under the <code>espf/core/services/pl_thr</code> folder.</p> <pre><code>set(make_target \"pl_thr\")\nproject(${make_target} C)\n\nadd_library(${make_target} STATIC\n    \"src/pl_thr.c\"\n)\n\nlist(\n    APPEND module_includes\n    \"${PROJECT_SOURCE_DIR}/inc\"\n)\n\ntarget_include_directories(${make_target} PUBLIC ${module_includes} PRIVATE ${ROOT_INCLUDES})\ntarget_compile_definitions(${make_target} PUBLIC ${ROOT_COMPILE_DEFS})\ntarget_compile_options(${make_target} PUBLIC ${ROOT_COMPILE_OPTIONS})\ntarget_link_options(${make_target} PUBLIC ${ROOT_LINK_OPTIONS})\n</code></pre> <p>This file basically includes our <code>pl_thr.c</code> file in the build (line <code>5</code>), inherits all build options from the parent project through <code>${ROOT_COMPILE_DEFS}</code> and <code>${ROOT_LINK_OPTIONS}</code> (lines <code>13-16</code>), and provides the include path to the <code>pl_thr.h</code> file for any other modules linking to this one (line <code>10</code>).</p> <p>Tip</p> <p>It is a rare event that a new software module relies only on itself, so if you depend on other modules in the system, you have to add those as follows: <pre><code>    target_link_libraries(${make_target} timer libtrace ...)\n</code></pre></p> <p>For now, however, we will keep this simple. And before bringing-in more functionality, let's add our new payload interface to the system payloads list so that it can be directly managed by the <code>payload_ctrl</code>. After testing the basic operation, we will extend the functionality to support some more useful actions.</p> <ul> <li>Open <code>espf/config/payload_ctrl/payload_cfg_user.h</code> and edit the <code>payload_ctrl_payload_t</code> enumeration to include the new payload ID (line <code>4</code> below).</li> </ul> payload_cfg_user.h<pre><code>...\ntypedef enum\n{\n    PAYLOAD_SX_BAND = 0,\n    PAYLOAD_THR = 1,            // &lt;-- our new payload\n    PAYLOAD_COUNT\n} payload_ctrl_payload_t;\n...\n</code></pre> <ul> <li>Now we have to register the <code>pl_thr_if</code> to the list of supported payload interfaces. Edit <code>espf/config/payload_ctrl/payload_cfg_user.c</code> as follows:</li> </ul> payload_cfg_user.c<pre><code>#include \"pl_thr.h\"     // include the payload header here\n\n...\n\n// This is a simple adapter function between the if_payload_control.h callback interface and the\n// payload_ctrl interface which doesn't operate directly with payload instances (e.g. if multiple instances\n// are supported by your payload).\nstatic void payload_pl_thr_state_notify(const pl_instance_id_t instance_id, pl_state_t to_state)\n{\n    // just map the instance_id argument to the correct payload_ctrl_payload_t identifier and\n    // call the payload_ctrl to inform it of the state change event\n    payload_ctrl_event_notify(PAYLOAD_THR, to_state);\n}\n\n...\n\nconst payload_immutable_cfg_t payload_cfg[PAYLOAD_COUNT] =\n{\n    // PAYLOAD_SX_BAND\n    { .p_pl_interface = &amp;sxband_pl_ctrl_if,\n      .internal_inst_id = 0U,\n      .init_config =\n      {\n          .p_config_data = NULL,\n          .size = 0U\n      },\n      .p_pl_notif_cbk = &amp;payload_sxband_state_notify\n    },\n\n    // PAYLOAD_THR &lt;== our new payload entry\n    { .p_pl_interface = &amp;pl_thr_if,\n      .internal_inst_id = 0U,\n      .init_config =\n      {\n          .p_config_data = NULL,\n          .size = 0U\n      },\n      .p_pl_notif_cbk = &amp;payload_pl_thr_state_notify\n    }\n};\n\n...\n</code></pre> <ul> <li>The final integration step is to extend the OBC SDK build to include the thruster payload. Open <code>espf/CMakeLists.txt</code> and add the <code>pl_thr</code> module as follows (line <code>8</code> and <code>30</code> below):</li> </ul> <pre><code>add_subdirectory(config/datacache datacache)\nadd_subdirectory(core/lib/crc crc)\nadd_subdirectory(core/lib/cbuf cbuf)\nadd_subdirectory(core/lib/cobs_inplace cobs_inplace)\nadd_subdirectory(core/lib/trace libtrace)\nadd_subdirectory(core/lib/sys_printf sys_printf)\n...\nadd_subdirectory(core/services/pl_thr pl_thr)       # &lt;-- tell CMake to build our new module\n\n...\n\nlist(APPEND libs\n    payload_ctrl\n    SGP4\n    COBS\n    hsm\n    timer\n    eps_ctrl\n    datetime\n    csp\n    sys_time\n    datacache\n    crc\n    nvm\n    nvm_cfg\n    cbuf\n    cobs_inplace\n    libtrace\n    sys_printf\n    pl_thr           # &lt;-- add the payload module to the list of SDK libraries\n)\n</code></pre> <p>Build your project and flash it on the OBC board to check our initial payload integration.</p>"},{"location":"devguide/devguide_user_payloads.html#verifying-the-payload-basic-operation","title":"Verifying the payload basic operation","text":"<p>After customizing the base user payload template and registering it to the list of system payloads, <code>payload_ctrl</code> should now start managing your payload without any additional programming on your side. What you should observe at first is that your payload gets initialized right after OBC boot. Place a breakpoint on the <code>pl_thr_init</code> operation in <code>pl_thr.c</code> and see if it gets called when you run the project.</p> <p></p> <p>Now as the <code>plp_thr_init</code> hook gets called, let's try to activate our thruster payload using the standard <code>Payload_Control.fidl</code> interface provided as part of the OBC SDK under the <code>espf/core/fidl/obc/fp</code> folder. It serves as a basic user payload testing surface enabling easy start/stop control for payloads as well as querying their state. For anything more complicated, you shall implement your own payload-specific FIDL interface to support custom payload configurations for example. You can refer to the Extending the SDK with new components chapter for additional examples how to do that for your new component.</p> <p>Back to our example, we will load the <code>Payload_Control.fidl</code> API into SDE and we will attempt to control our payload (which has a payload ID of <code>1</code> as defined in <code>payload_cfg_user.h</code> above) and query its state. Calling <code>startPayload</code>/<code>stopPayload</code> FIDL methods shall trigger our <code>pl_thr_start</code> and <code>pl_thr_stop</code> handlers respectively. Using the <code>getPayloadInfo</code> method shall properly report the thruster state.</p> <p></p> <p>We have seen that basing our new implementation on the standard user payload template can quickly get us started on working with a new payload as part of the OBC SDK build. It also has out-of-the-box testing interface provided for the standard payload life-cycle operations. So far, so good, but one real-life thruster would need to perform more complicated handling in orbit, hence in the next chapters we will see how to provide more functions to it and also demonstrate how to call it with the on-board OBC scheduler. Read on...</p>"},{"location":"devguide/devguide_user_payloads.html#specifying-payload-start-parameters","title":"Specifying payload start parameters","text":"<p>At this time, our <code>pl_thr_start</code> operation is only changing the payload state and doesn't do anything useful. What would an engineer imagine a thruster needs to do in orbit is perhaps execution of a programmed sequence of maneuvers when it is started. It would be nice if we could schedule the sequence of maneuvers from the ground. Fortunately we can do this by utilizing the payload start configuration parameters provided by the <code>if_payload_control.h</code> interface we already implemented. Let's remember what the <code>pl_thr_start</code> function prototype looks like:</p> <p><pre><code>static pl_op_status_t pl_thr_start(const pl_instance_id_t instance_id, pl_config_t * const p_start_cfg)\n</code></pre> You should focus on the <code>p_start_cfg</code> argument. The <code>pl_config_t</code> type definition is the following:</p> <pre><code>typedef struct\n{\n    void *p_config_data;        /**&lt; a pointer to the payload-specific configuration data */\n    const uint32_t size;        /**&lt; size of the data pointed to by p_config_data */\n} pl_config_t;\n</code></pre> <p>As you can see, we can pass pretty much anything to the payload start function through this parameter since it doesn't define a concrete type for the <code>p_config_data</code>. The interpretation of this field is completely left to the payload implementation. <code>payload_ctrl</code> only makes sure the data is transparently forwarded to the respective payload handler. No processing or error checking is performed on this data on its way.</p> <p>Warning</p> <p>Please have in mind that currently the maximum size of the data which can be passed through the <code>p_config_data</code> argument is limited to the maximum size supported by the on-board OBC scheduler record. At the time of writing this guideline, this size is set to <code>16 bytes</code>.</p> <p>The constraint comes from the <code>record_t::payload_args[]</code> field definition in <code>espf/core/services/payload_scheduler/payload_scheduler.h</code>.</p> <p>In fact, the idea here is that if you need more than 16 bytes to configure your payload, it would be better to use a file-based configuration instead and just provide the file name here. Some adjustments to this size are possible in the next revisions of the OBC SDK but for now this limitation is also imposed by the DGS payload control operations as well.</p> <p>As already noted, it is up to the user payload code designer to decide whether to use the <code>p_config_data</code> argument as a binary blob field to configure the payload start operation, or to provide here a file name which must be loaded and processed by the user payload directly.</p> <p>For the sake of simplicity, we will not use files but instead implement a very simple maneuver scheme encoded in the <code>16-byte</code> <code>p_config_data</code> argument which will instruct our thruster what maneuvers to execute and in what order. Simplifying even further, each byte in <code>p_config_data</code> will encode a specific type of maneuver which will be held in execution for only 2 seconds. Once all maneuvers are executed, the payload will remain in execution of the last maneuver until stopped by the on-board scheduler. You should perhaps avoid this kind of implementation for a real satellite but for the purpose of demonstration that would be perfectly fine. Let's continue with our implementation according to the new requirements we just adopted for our payload.</p>"},{"location":"devguide/devguide_user_payloads.html#implementing-custom-thruster-maneuvers","title":"Implementing custom thruster maneuvers","text":"<p>We will define the list of maneuvers supported by our thruster as an enumeration like this:</p> <pre><code>/** @brief List of maneuvers supported by the thruster */\nenum\n{\n    PL_THR_MAN_NONE               = (uint8_t) 0,\n    PL_THR_MAN_SGL_THRUST_SHORT   = (uint8_t) 1,\n    PL_THR_MAN_SGL_THRUST_LONG    = (uint8_t) 2,\n    PL_THR_MAN_DBL_THRUST_SHORT   = (uint8_t) 3,\n    PL_THR_MAN_DBL_THRUST_LONG    = (uint8_t) 4,\n    PL_THR_MAN_INCR_THRUST_HALF_S = (uint8_t) 5,\n    PL_THR_MAN_INCR_THRUST_ONE_S  = (uint8_t) 6,\n    PL_THR_MAN_MAX = (uint8_t) 7\n};\n</code></pre> <p>Executing the maneuvers would be a long-term operation and thus we cannot execute this inside the <code>pl_thr_start</code> hook because we would block the <code>payload_ctrl</code> thread. The maneuver activation shall happen inside a dedicated OS thread. Let's create one:</p> <ul> <li>We will edit the list of includes in <code>pl_thr.c</code> to enable use of the OS APIs and also the OBC trace subsystem which we will use to indicate that our maneuvers are being executed. Add the following includes at the top of the file: <pre><code>#include \"cmsis_os2.h\"\n#include \"trace.h\"\n</code></pre></li> </ul> <p>Note</p> <p>For <code>trace.h</code> support you also have to edit the <code>CMakeLists.txt</code> file to include the following line at the end: <pre><code>target_link_libraries(${make_target} PUBLIC libtrace)\n</code></pre></p> <ul> <li>Now let's create an empty thruster OS thread by placing the following code in the <code>pl_thr.c</code> file:</li> </ul> <pre><code>static osThreadId_t thruster_task = NULL;\n\nstatic void pl_thr_task(void * p_task_arg);\n\nstatic void pl_thr_task(void * p_task_arg)\n{\n    (void) p_task_arg;\n\n    for (;;)\n    {\n        osDelay(1000U);\n    }\n}\n</code></pre> <ul> <li>The new thread needs to be initialized in the <code>pl_thr_init</code> function by adding the following code: <pre><code>    static const osThreadAttr_t task_attr =\n    {\n        .attr_bits = osThreadDetached,\n        .name      = \"pl_thr_task\",\n        .priority  = osPriorityNormal,\n        .cb_mem    = NULL,\n        .cb_size   = 0U,\n        .stack_mem = NULL,\n        .stack_size = 1000U\n    };\n\n    if (NULL == thruster_task)\n    {\n        thruster_task = osThreadNew(&amp;pl_thr_task,\n                                    NULL,\n                                    &amp;task_attr);\n    }\n</code></pre></li> </ul> <p>Now after building and flashing the OBC via the debugger, you should be able to verify the the <code>pl_thr_task</code> function is called by the OS. It is not doing much at this time but we will add our maneuver activation code in a few moments.</p> <ul> <li> <p>Let's first define the list of supported thruster maneuvers and allocate some memory for the maneuvers sequence which we will accept as a payload argument when the <code>pl_thr_start</code> hook is called: <pre><code>/** @brief List of maneuvers supported by the thruster */\nenum\n{\n    PL_THR_MAN_NONE               = (uint8_t) 0,\n    PL_THR_MAN_SGL_THRUST_SHORT   = (uint8_t) 1,\n    PL_THR_MAN_SGL_THRUST_LONG    = (uint8_t) 2,\n    PL_THR_MAN_DBL_THRUST_SHORT   = (uint8_t) 3,\n    PL_THR_MAN_DBL_THRUST_LONG    = (uint8_t) 4,\n    PL_THR_MAN_INCR_THRUST_HALF_S = (uint8_t) 5,\n    PL_THR_MAN_INCR_THRUST_ONE_S  = (uint8_t) 6,\n    PL_THR_MAN_MAX = (uint8_t) 7\n};\n\nstatic uint8_t maneuvers_seq[MAX_MANEUVERS_CNT];   /**&lt; Maneuvers sequence to be executed by the payload */\n</code></pre></p> </li> <li> <p>A simple operation to execute our maneuvers would also be nice to have: <pre><code>static void execute_thr_maneuver(const uint8_t man_id)\n{\n    static const char *maneuver_names[PL_THR_MAN_MAX] =\n    {\n        \"NONE\",\n        \"SGL_THRUST_SHORT\",\n        \"SGL_THRUST_LONG\",\n        \"DBL_THRUST_SHORT\",\n        \"DBL_THRUST_LONG\",\n        \"INCR_THRUST_HALF_S\",\n        \"INCR_THRUST_ONE_S\",\n    };\n\n    if (man_id &lt; PL_THR_MAN_MAX)\n    {\n        ES_TRACE_INFO(\"executing maneuver '%s'\\r\\n\", maneuver_names[(uint8_t) man_id]);\n    }\n    else\n    {\n        ES_TRACE_ERROR(\"invalid maneuver id '%d'\\r\\n\", (uint8_t) man_id);\n    }\n}\n</code></pre></p> </li> </ul> <p>The <code>execute_thr_maneuver</code> function will only trace the execution of the supplied maneuvers by the start configuration parameter. For a real thruster, this would also be handling the HW control aspects of the execution but for our demonstration, it is completely sufficient.</p> <ul> <li>Now that we have all maneuver code in place, we need to properly process the start configuration parameter so that we can use it to trigger a specific sequence of maneuvers requested by MCS. For this to work fine, we need to copy the start configuration data in the <code>maneuvers_seq</code> buffer which we statically allocated so that it can be processed later when our <code>pl_thr_task</code> function is scheduled by the OS. Add the following code to the <code>pl_thr_start</code> function: <pre><code>if (NULL != p_start_cfg)\n{\n    (void) memcpy(maneuvers_seq,\n                  p_start_cfg-&gt;p_config_data,\n                  (size_t) fmin(sizeof(maneuvers_seq), p_start_cfg-&gt;size));\n}\n</code></pre>  You would need the <code>math.h</code> include at the top of the file to resolve the <code>fmin()</code> function and the <code>string.h</code> include to resolve the <code>memcpy()</code> function.</li> </ul> <p>Warning</p> <p>We are currently assuming that <code>p_start_cfg-&gt;p_config_data</code> points to a buffer of maneuvers as we defined it here. This must be ensured when preparing an on-board schedule file via MCS or when requesting scheduler operations via the <code>ConOps.fidl::addNewScheduleRecord</code> method (e.g. refer to the <code>payArgs</code> argument).</p> <ul> <li> <p>We transferred the maneuver sequence into our internal buffer but we don't have any code in place to process it. Let's add this to our <code>pl_thr_task</code> function: <pre><code>static void pl_thr_task(void * p_task_arg)\n{\n    // currently unused\n    (void) p_task_arg;\n\n    for (;;)\n    {\n        for (uint8_t man_idx = 0; man_idx &lt; MAX_MANEUVERS_CNT; man_idx++)\n        {\n            if (((uint8_t) PL_THR_MAN_NONE &lt; maneuvers_seq[man_idx]) &amp;&amp;\n                ((uint8_t) PL_THR_MAN_MAX &gt; maneuvers_seq[man_idx]))\n            {\n                execute_thr_maneuver(maneuvers_seq[man_idx]);\n\n                osDelay(2000U);\n            }\n        }\n    }\n}\n</code></pre></p> </li> <li> <p>If you are paying close attention to our implementation here, you probably already noticed some flaws. The task function is constantly processing the <code>maneuvers_seq</code> buffer but doesn't actually know if the buffer contains anything valid. What would also happen if the asynchronous <code>pl_thr_start</code> operation is called in the middle of our processing and replaces the content of the buffer? Alas, this can lead to any number of side effects we will observe as weird and most probably incorrect behavior of our maneuver execution. Moreover there is no guarantee our maneuver execution will run to completion which may be detrimental to the satellite operation. As we are currently focused on implementing a simple user payload operation, we still have to account for any possible race condition effects which may occur in a fully preemptive system as is the OBC. Now let's see what we can do to improve the situation and make our maneuver execution deterministic. As a first step, we could execute our <code>pl_thr_task</code> only when there is a maneuver sequence to execute and avoid looping around and wasting CPU time when there is nothing to execute. We can use a OS thread flag for this purpose which would signal the <code>pl_thr_task</code> only when a payload start operation is requested. Let's add the following code to our <code>pl_thr_start</code> function after we have performed the <code>memcpy</code> of the maneuver sequence to our internal buffer: <pre><code>...\n// signal thruster OS task to process the new maneuvers\n(void) osThreadFlagsSet(thruster_task, NEW_MANEUVERS_AVL_FLAG);\n...\n</code></pre> Also place <code>NEW_MANEUVERS_AVL_FLAG</code> as a define at the top of the file like this: <pre><code>#define NEW_MANEUVERS_AVL_FLAG          (0x01U)\n</code></pre></p> </li> </ul> <p>We will extend the <code>pl_thr_task</code> code to wait for the <code>NEW_MANEUVERS_AVL_FLAG</code> flag event before starting execution of the maneuver sequence. This way, our thread will be blocked until an actual start operation is requested to our payload which is what we wanted initially: <pre><code>static void pl_thr_task(void * p_task_arg)\n{\n    uint32_t thread_flags = 0;\n    // currently unused\n    (void) p_task_arg;\n\n    for (;;)\n    {\n        thread_flags = osThreadFlagsWait(NEW_MANEUVERS_AVL_FLAG, osFlagsWaitAny, osWaitForever);\n\n        if (thread_flags &gt; 0)\n        {\n            for (uint8_t man_idx = 0; man_idx &lt; MAX_MANEUVERS_CNT; man_idx++)\n            {\n                if (((uint8_t) PL_THR_MAN_NONE &lt; maneuvers_seq[man_idx]) &amp;&amp;\n                    ((uint8_t) PL_THR_MAN_MAX &gt; maneuvers_seq[man_idx]))\n                {\n                    execute_thr_maneuver(maneuvers_seq[man_idx]);\n\n                    osDelay(2000U);\n                }\n            }\n        }\n        else\n        {\n            osDelay(1000U);     // just in case we have continous errors reported by the osThreadFlagsWait() API\n        }\n    }\n}\n</code></pre></p> <ul> <li>So far, so good but we still have one potential flaw to address. We must avoid the possibility of interrupting our maneuver execution sequence from start to completion by accepting a new payload start configuration parameter, e.g. in case our schedule was incorrect and attempted to execute overlapping maneuver operations. We will again rely on the OS APIs for this. Let's use a mutex to enable a critical section in our task. The mutex will be released as soon as we finish our full maneuver sequence. That very same mutex shall also be used inside the <code>pl_thr_start</code> operation when a new request arrives asynchronously to our <code>pl_thr_task</code> function potentially interrupting it.</li> </ul> <p>We will allocate a mutex and initialize it in <code>pl_thr_init</code>. We will also initialize our maneuver sequence buffer just to make sure it always starts with some valid values inside.</p> <pre><code>static osMutexId_t man_seq_lock = NULL;\n\nstatic pl_op_status_t pl_thr_init(const pl_instance_id_t instance_id,\n                                  pl_config_t * const p_init_cfg,\n                                  const p_pl_event_notify_t p_event_notify_cb)\n{\n    ...\n\n    if (NULL == man_seq_lock)\n    {\n        man_seq_lock = osMutexNew(NULL);\n    }\n\n    (void) memset(&amp;maneuvers_seq, (uint8_t) PL_THR_MAN_NONE, MAX_MANEUVERS_CNT);  // initialize the maneuver sequence\n    ...\n}\n</code></pre> <p>Now let's put the mutex to use by creating critical sections inside <code>pl_thr_start</code> and <code>pl_thr_task</code> functions:</p> <pre><code>static pl_op_status_t pl_thr_start(const pl_instance_id_t instance_id, pl_config_t * const p_start_cfg)\n{\n    osStatus_t lock_stat = osError;\n\n    current_state = PL_STATE_STARTED;\n\n    fire_event(instance_id, current_state);\n\n    if (NULL != p_start_cfg)\n    {\n        lock_stat = osMutexAcquire(man_seq_lock, osWaitForever);\n\n        if (osOK == lock_stat)\n        {\n            (void) memcpy(maneuvers_seq, p_start_cfg-&gt;p_config_data, (size_t) fmin(sizeof(maneuvers_seq), p_start_cfg-&gt;size));\n\n            (void) osMutexRelease(man_seq_lock);\n        }\n\n        // signal thruster OS task to process the new maneuvers\n        (void) osThreadFlagsSet(thruster_task, NEW_MANEUVERS_AVL_FLAG);\n    }\n\n    return PL_OP_STATUS_OK;\n}\n\nstatic void pl_thr_task(void * p_task_arg)\n{\n    osStatus_t lock_stat = osError;\n    uint32_t thread_flags = 0;\n    // currently unused\n    (void) p_task_arg;\n\n    for (;;)\n    {\n        thread_flags = osThreadFlagsWait(NEW_MANEUVERS_AVL_FLAG, osFlagsWaitAny, osWaitForever);\n\n        if (thread_flags &gt; 0)\n        {\n            lock_stat = osMutexAcquire(man_seq_lock, osWaitForever);\n\n            if (osOK == lock_stat)\n            {\n                for (uint8_t man_idx = 0; man_idx &lt; MAX_MANEUVERS_CNT; man_idx++)\n                {\n                    if (((uint8_t) PL_THR_MAN_NONE &lt; maneuvers_seq[man_idx]) &amp;&amp;\n                        ((uint8_t) PL_THR_MAN_MAX &gt; maneuvers_seq[man_idx]))\n                    {\n                        execute_thr_maneuver(maneuvers_seq[man_idx]);\n\n                        osDelay(2000U);\n                    }\n                }\n\n                (void) osMutexRelease(man_seq_lock);\n            }\n        }\n        else\n        {\n            osDelay(1000U);\n        }\n    }\n}\n</code></pre> <ul> <li> <p>Finally, we shall execute an empty maneuver on the <code>pl_thr_stop</code> function: <pre><code>static pl_op_status_t pl_thr_stop(const pl_instance_id_t instance_id, const pl_op_stop_mode_t stop_mode)\n{\n    current_state = PL_STATE_STOPPED;\n\n    fire_event(instance_id, current_state);\n\n    // stop the active maneuver (if any)\n    execute_thr_maneuver(PL_THR_MAN_NONE);\n\n    return PL_OP_STATUS_OK;\n}\n</code></pre></p> </li> <li> <p>You can find the full source code to our thruster payload here as a reference:</p> </li> </ul> <pre><code>#include \"es_cdef.h\"\n#include \"cmsis_os2.h\"\n#include \"if_payload_control.h\"\n#include \"trace.h\"\n#include \"math.h\"\n#include \"string.h\"\n\n#define MAX_MANEUVERS_CNT               (16U)\n#define NEW_MANEUVERS_AVL_FLAG          (0x01U)\n\n/** @brief List of maneuvers supported by the thruster */\nenum\n{\n    PL_THR_MAN_NONE               = (uint8_t) 0,\n    PL_THR_MAN_SGL_THRUST_SHORT   = (uint8_t) 1,\n    PL_THR_MAN_SGL_THRUST_LONG    = (uint8_t) 2,\n    PL_THR_MAN_DBL_THRUST_SHORT   = (uint8_t) 3,\n    PL_THR_MAN_DBL_THRUST_LONG    = (uint8_t) 4,\n    PL_THR_MAN_INCR_THRUST_HALF_S = (uint8_t) 5,\n    PL_THR_MAN_INCR_THRUST_ONE_S  = (uint8_t) 6,\n    PL_THR_MAN_MAX = (uint8_t) 7\n};\n\nstatic p_pl_event_notify_t p_event_cbk = (p_pl_event_notify_t) NULL;\nstatic pl_state_t current_state = PL_STATE_NOT_INIT;\nstatic uint8_t maneuvers_seq[MAX_MANEUVERS_CNT];\nstatic osMutexId_t man_seq_lock = NULL;\nstatic osThreadId_t thruster_task = NULL;\n\nstatic void pl_thr_task(void * p_task_arg);\nstatic void execute_thr_maneuver(const uint8_t man_id);\n\nstatic inline void fire_event(const pl_instance_id_t instance_id, pl_state_t to_state)\n{\n    if (NULL != p_event_cbk)\n    {\n        p_event_cbk(instance_id, to_state);\n    }\n}\n\nstatic pl_op_status_t pl_thr_init(const pl_instance_id_t instance_id,\n                                  pl_config_t * const p_init_cfg,\n                                  const p_pl_event_notify_t p_event_notify_cb)\n{\n    static const osThreadAttr_t task_attr =\n    {\n        .attr_bits = osThreadDetached,\n        .name      = \"pl_thr_task\",\n        .priority  = osPriorityNormal,\n        .cb_mem    = NULL,\n        .cb_size   = 0U,\n        .stack_mem = NULL,\n        .stack_size = 1000U\n    };\n\n    (void) instance_id;\n    (void) p_init_cfg;\n\n    if (NULL == man_seq_lock)\n    {\n        man_seq_lock = osMutexNew(NULL);\n    }\n\n    if (NULL == thruster_task)\n    {\n        thruster_task = osThreadNew(&amp;pl_thr_task,\n                                    NULL,\n                                    &amp;task_attr);\n    }\n\n    current_state = PL_STATE_STOPPED;\n    p_event_cbk = p_event_notify_cb;\n\n    (void) memset(&amp;maneuvers_seq, (uint8_t) PL_THR_MAN_NONE, MAX_MANEUVERS_CNT);\n\n    fire_event(instance_id, current_state);\n\n    return PL_OP_STATUS_OK;\n}\n\nstatic pl_op_status_t pl_thr_deinit(const pl_instance_id_t instance_id)\n{\n    current_state = PL_STATE_NOT_INIT;\n\n    fire_event(instance_id, current_state);\n\n    return PL_OP_STATUS_OK;\n}\n\nstatic pl_op_status_t pl_thr_start(const pl_instance_id_t instance_id, pl_config_t * const p_start_cfg)\n{\n    osStatus_t lock_stat = osError;\n\n    current_state = PL_STATE_STARTED;\n\n    fire_event(instance_id, current_state);\n\n    if (NULL != p_start_cfg)\n    {\n        lock_stat = osMutexAcquire(man_seq_lock, osWaitForever);\n\n        if (osOK == lock_stat)\n        {\n            (void) memcpy(maneuvers_seq, p_start_cfg-&gt;p_config_data, (size_t) fmin(sizeof(maneuvers_seq), p_start_cfg-&gt;size));\n\n            (void) osMutexRelease(man_seq_lock);\n        }\n\n        // signal thruster OS task to process the new maneuvers\n        (void) osThreadFlagsSet(thruster_task, NEW_MANEUVERS_AVL_FLAG);\n    }\n\n    return PL_OP_STATUS_OK;\n}\n\nstatic pl_op_status_t pl_thr_stop(const pl_instance_id_t instance_id, const pl_op_stop_mode_t stop_mode)\n{\n    (void) stop_mode;\n\n    current_state = PL_STATE_STOPPED;\n\n    fire_event(instance_id, current_state);\n\n    // stop the active maneuver (if any)\n    execute_thr_maneuver(PL_THR_MAN_NONE);\n\n    return PL_OP_STATUS_OK;\n}\n\nstatic pl_state_t pl_thr_get_active_state(const pl_instance_id_t instance_id)\n{\n    (void) instance_id;     // we support only one payload instance here\n\n    return current_state;\n}\n\nstatic uint32_t pl_thr_get_last_error(const pl_instance_id_t instance_id)\n{\n    (void) instance_id;\n\n    return 0;\n}\n\nstatic void pl_thr_task(void * p_task_arg)\n{\n    osStatus_t lock_stat = osError;\n    uint32_t thread_flags = 0;\n    // currently unused\n    (void) p_task_arg;\n\n    for (;;)\n    {\n        thread_flags = osThreadFlagsWait(NEW_MANEUVERS_AVL_FLAG, osFlagsWaitAny, osWaitForever);\n\n        if (thread_flags &gt; 0)\n        {\n            lock_stat = osMutexAcquire(man_seq_lock, osWaitForever);\n\n            if (osOK == lock_stat)\n            {\n                for (uint8_t man_idx = 0; man_idx &lt; MAX_MANEUVERS_CNT; man_idx++)\n                {\n                    if (((uint8_t) PL_THR_MAN_NONE &lt; maneuvers_seq[man_idx]) &amp;&amp;\n                        ((uint8_t) PL_THR_MAN_MAX &gt; maneuvers_seq[man_idx]))\n                    {\n                        execute_thr_maneuver(maneuvers_seq[man_idx]);\n\n                        osDelay(2000U);\n                    }\n                }\n\n                (void) osMutexRelease(man_seq_lock);\n            }\n        }\n        else\n        {\n            osDelay(1000U);\n        }\n    }\n}\n\nstatic void execute_thr_maneuver(const uint8_t man_id)\n{\n    static const char *maneuver_names[PL_THR_MAN_MAX] =\n    {\n        \"NONE\",\n        \"SGL_THRUST_SHORT\",\n        \"SGL_THRUST_LONG\",\n        \"DBL_THRUST_SHORT\",\n        \"DBL_THRUST_LONG\",\n        \"INCR_THRUST_HALF_S\",\n        \"INCR_THRUST_ONE_S\",\n    };\n\n    if (man_id &lt; PL_THR_MAN_MAX)\n    {\n        ES_TRACE_INFO(\"executing maneuver '%s'\\r\\n\", maneuver_names[(uint8_t) man_id]);\n    }\n    else\n    {\n        ES_TRACE_ERROR(\"invalid maneuver id '%d'\\r\\n\", (uint8_t) man_id);\n    }\n}\n\nconst pl_control_if_t pl_thr_if =\n{\n    .init = pl_thr_init,\n    .deinit = pl_thr_deinit,\n    .start = pl_thr_start,\n    .stop = pl_thr_stop,\n    .get_state = pl_thr_get_active_state,\n    .get_last_error = pl_thr_get_last_error,\n};\n</code></pre> <p>Summary</p> <p>Good work!</p> <p>Now our payload thruster can be operated either via the <code>ConOps.fidl::addNewScheduleRecord</code> operation or through the DGS Web GUI which is able to prepare an OBC on-board schedule for autonomous execution in orbit.</p> <p> Please have in mind that the on-board scheduler operation is very tightly coupled with the satellite operational modes and in order to properly execute these schedules, there are system conditions which must be fulfilled in advance (e.g. such as optimal battery voltage levels and correct ADCS pointing), otherwise your payload implementation will not be called.</p> <p>Let's recap on what we learned in this chapter:</p> <ul> <li>We explored how user payload scheduling in the OBC works.</li> <li>We looked at the standard interfaces a user payload must implement in order to be used with the OBC on-board scheduler.</li> <li>We implemented a simple user payload module for a thruster based on the OBC SDK templates.</li> <li>We saw how we can use specific payload configuration arguments supplied through the standard payload <code>if_payload_control.h::start()</code> interface.</li> <li>We extended the basic implementation by providing an OS thread to handle our more complex payload operations.</li> <li>We looked into some best practices on how to protect our payload operation if it must be run in a separate OS thread.</li> <li>We used the OBC SDK <code>libtrace</code> library to trace our payload operations.</li> </ul>"},{"location":"devguide/hldesign.html","title":"High-Level Design","text":"<p>The OBC SDK consists of the following packages:</p> <p></p>"},{"location":"devguide/hldesign.html#mcu-vendor-hal-and-platform-al-abstraction-layer","title":"MCU Vendor HAL and Platform AL (Abstraction Layer)","text":"<p>Note</p> <p>These packages contain MCU-specific code.</p>"},{"location":"devguide/hldesign.html#mcu-vendor-hal","title":"MCU Vendor HAL","text":"<p>This package is implemented by the MCU manufacturer (ST) and is a supporting package for projects based on STM32 MCUs. It is your decision whether to use the package or do your own register-level handling instead but keep in mind that the HAL provides a structured interface to the MCU peripherals and easy to use configurable mechanisms to enable MCU peripheral operation even by novice programmers. This package also ensures that peripheral operation is done in the \u201ccorrect\u201d way and saves much effort in working with the more complicated peripherals. All this flexibility and ease of use come at a price - more CPU/memory resources. If your OBC application allows it, however, it is recommended to rely on the vendor HAL interfaces to control the MCU peripherals. The OBC SDK comes with drivers for most peripherals but you can completely exclude from your build anything that is unused in your project.</p> <p>Warning</p> <p>The ST HAL packages provided as part of the OBC SDK are the most current at the time of the SDK release. If you want to ensure you are working with the latest version of those HALs, you can update the relevant files directly from the ST GitHub repository.</p>"},{"location":"devguide/hldesign.html#platform-al","title":"Platform AL","text":"<p>The Platform Abstraction Layer is not implemented at the moment of writing this documentation but it will be intended to cut any direct dependencies of the existing top-level packages to Drivers and MCU HALs, even the RTOS. This would give users the possibility to completely run and simulate the OBC SDK on a computer without the real HW.</p>"},{"location":"devguide/hldesign.html#middlewares","title":"Middlewares","text":"<p>Note</p> <p>These packages contain HW-independent code.</p>"},{"location":"devguide/hldesign.html#freertos","title":"FreeRTOS","text":"<p>This package represents the Operating System running on the CPU which provides task scheduling, task synchronization, SW timers and other useful services which enable the development of complex multi-task applications. This SDK ships with FreeRTOS but most modules can easily be ported to other RTOS flavors especially if they are CMSIS-RTOS-compliant.</p>"},{"location":"devguide/hldesign.html#3rd-party-middleware","title":"3<sup>rd</sup> party Middleware","text":"<p>This package contains externally provided software maintained separately from the OBC SDK and only integrated inside to enable more services for the end users. Currently, you can find the following software in this package:</p> <ul> <li>Cubesat Space Protocol (CSP)</li> <li>FATFS file system driver</li> </ul>"},{"location":"devguide/hldesign.html#platform-middleware","title":"Platform Middleware","text":"<p>This package currently contains the ES Communication Protocol Stack (ESPS I). This implementation is used in all EnduroSat platform modules.</p>"},{"location":"devguide/hldesign.html#drivers","title":"Drivers","text":"<p>This package contains:</p> <ul> <li>Drivers which make use of the on-board OBC sensors or communicate to other modules via the PC104 connector.</li> <li>ESPS I bus communication drivers.</li> <li>OBC peripheral drivers which provide more extended functionality not available as part of the MCU vendor HAL package.</li> </ul> <p>Note</p> <p>This package contains code specific to external HW modules.</p>"},{"location":"devguide/hldesign.html#libraries","title":"Libraries","text":"<p>Note</p> <p>This package contains HW-independent code. Libraries can be used anywhere in the system and they usually do not carry additional dependencies.</p> <p>This package has different stand-alone libraries that are used by different components in the OBC code, such as CRC calculation, date and time utilities, hierarchical state machine engine, timers, debug, compression, vetc.</p>"},{"location":"devguide/hldesign.html#services","title":"Services","text":"<p>Note</p> <p>This package contain HW-independent code.</p> <p>The package contains service-level implementations which can work stand-alone or be used from a user-OBC application.</p> <p>Here you can find:</p> <ul> <li>Telemetry reporting</li> <li>UHF telemetry beacon transmission</li> <li>SD card management</li> <li>Payload power control and scheduling</li> <li>Solar panel sensors acquisition and reporting</li> <li>Debug/trace service</li> <li>Non-volatile memory service</li> <li>...and others</li> </ul>"},{"location":"devguide/hldesign.html#application","title":"Application","text":"<p>The application package implements user-defined behavior on top of the existing OBC services. The OBC SDK comes with a pre-configured ConOps application which can be used as-is or modified by the users.</p> <p>Note</p> <p>This package contains HW-independent code.</p>"},{"location":"devguide/hldesign.html#packages-dependency-matrix","title":"Packages dependency matrix","text":"<p>The following matrix indicates the recommended dependency options between the SW packages in order to promote better feature encapsulation and to improve reusability of the individual components.</p> Application MW Libraries Services Drivers HAL RTOS Application MW Libraries Services Drivers HAL <p>The  symbol in a cell indicates that a dependency can exist between components hosted in the corresponding package on the same row/column where the symbol is placed. Some additional restrictions exist between components in the Application, MW, Drivers and HAL packages, though. They can have top-to-bottom direct vertical collaboration but bottom-to-top hard dependencies shall not exist. Such dependencies have to be modelled via API-configurable or weak callbacks only.</p> <p></p>"}]}